\nonstopmode{}
\documentclass[a4paper]{book}
\usepackage[times,inconsolata,hyper]{Rd}
\usepackage{makeidx}
\makeatletter\@ifl@t@r\fmtversion{2018/04/01}{}{\usepackage[utf8]{inputenc}}\makeatother
% \usepackage{graphicx} % @USE GRAPHICX@
\makeindex{}
\begin{document}
\chapter*{}
\begin{center}
{\textbf{\huge Package `ICESat2VegR'}}
\par\bigskip{\large \today}
\end{center}
\ifthenelse{\boolean{Rd@use@hyper}}{\hypersetup{pdftitle = {ICESat2VegR: NASA's Ice, Cloud, and Elevation Satellite (ICESat-2) Data Analysis for Land and Vegetation Applications}}}{}
\ifthenelse{\boolean{Rd@use@hyper}}{\hypersetup{pdfauthor = {Carlos Alberto Silva; Caio Hamamura}}}{}
\begin{description}
\raggedright{}
\item[Type]\AsIs{Package}
\item[Title]\AsIs{NASA's Ice, Cloud, and Elevation Satellite (ICESat-2) Data Analysis for Land and Vegetation
Applications}
\item[Version]\AsIs{0.0.1}
\item[Description]\AsIs{Set of tools for downloading, reading, visualizing, processing and exporting NASA's
ICESat-2 ATL03 (Global Geolocated Photon Data) and ATL08 (Land and Vegetation Height)
products for Land and Vegetation Applications.}
\item[License]\AsIs{GPL (>= 3)}
\item[Imports]\AsIs{curl, data.table, sf, fs, getPass, jsonlite, hdf5r, httr2, magrittr, methods, Rcpp, Rdpack, R6,
randomForest, reticulate, terra, xml2}
\item[Encoding]\AsIs{UTF-8}
\item[URL]\AsIs{}\url{https://github.com/carlos-alberto-silva/ICESat2VegR}\AsIs{}
\item[BugReports]\AsIs{}\url{https://github.com/carlos-alberto-silva/ICESat2VegR/issues}\AsIs{}
\item[LazyData]\AsIs{true}
\item[NeedsCompilation]\AsIs{yes}
\item[RoxygenNote]\AsIs{7.3.3}
\item[Roxygen]\AsIs{list(markdown = TRUE)}
\item[RdMacros]\AsIs{Rdpack}
\item[Suggests]\AsIs{chromote,  devtools,  ggplot2, grid, gridExtra, htmlwidgets, knitr, leaflet, leafsync,
lidR, lwgeom, mapview,  png, rmarkdown, rstudioapi, signal, stars, testthat (>= 3.0.0),
webshot, viridis}
\item[LinkingTo]\AsIs{Rcpp}
\item[Collate]\AsIs{'ANNIndex.R'
'lazy_applier.R'
'ATL03_ATL08_compute_seg_attributes_dt_segStat.R'
'utmTools.R'
'ATL03_ATL08_photons_attributes_dt_LAS.R'
'ATL03_ATL08_photons_attributes_dt_clipBox.R'
'ATL03_ATL08_photons_attributes_dt_clipGeometry.R'
'ATL03_ATL08_photons_attributes_dt_gridStat.R'
'ATL03_ATL08_photons_attributes_dt_join.R'
'ATL03_ATL08_photons_attributes_dt_polyStat.R'
'ATL03_ATL08_photons_seg_dt_fitground.R'
'ATL03_ATL08_photons_seg_dt_height_normalize.R'
'ATL03_ATL08_seg_attributes_dt_clip.R'
'ATL03_ATL08_seg_cover_dt_compute.R'
'ATL03_ATL08_segment_create.R'
'ATL03_h5_clip.R'
'clipTools.R'
'ATL03_h5_clipBox.R'
'ATL03_h5_clipGeometry.R'
'ATL03_photons_attributes_dt.R'
'lasTools.R'
'ATL03_photons_attributes_dt_LAS.R'
'ATL03_photons_attributes_dt_clipBox.R'
'ATL03_photons_attributes_dt_clipGeometry.R'
'class_tools.R'
'class.icesat2.R'
'zzz.R'
'ATL03_read.R'
'ATL03_seg_metadata_dt.R'
'ATL08_read.R'
'ATL08_h5_clip.R'
'ATL08_h5_clipBox.R'
'ATL08_photons_attributes_dt.R'
'ATL08_photons_attributes_dt_LAS.R'
'ATL08_seg_attributes_dt.R'
'ATL08_seg_attributes_dt_LAS.R'
'ATL08_seg_attributes_dt_clipBox.R'
'ATL08_seg_attributes_dt_clipGeometry.R'
'ATL08_seg_attributes_dt_gridStat.R'
'ATL08_seg_attributes_dt_polyStat.R'
'ATL08_seg_attributes_h5_gridStat.R'
'ATLAS_dataDownload.R'
'ATLAS_dataFinder.R'
'earthaccess.R'
'ATLAS_dataFinder_cloud.R'
'ATLAS_dataFinder_direct.R'
'ICESat2VegR-package.R'
'ICESat2VegR_configure.R'
'addEEImage.R'
'argParse.R'
'class.icesat2.h5ds_cloud.R'
'class.icesat2.h5_cloud.R'
'class.icesat2.h5ds_local.R'
'class.icesat2.h5_local.R'
'clip.R'
'ee_build_AlphaEarth_embedding_terrain_stack.R'
'ee_build_hls_s1c_terrain_stack.R'
'extract.R'
'fit_metrics.R'
'fit_model.R'
'gdalBindings.R'
'gee-base-feature.R'
'gee-base-list.R'
'gee-base-number.R'
'gee-base.R'
'gee-search.R'
'map_tools.R'
'model_tools.R'
'predict_h5.R'
'rasterize_h5.R'
'rgt_extract.R'
'sample.R'
'to_vect.R'
'varSel.R'
'vect_as_ee.R'}
\end{description}
\Rdcontents{Contents}
\HeaderA{ICESat2VegR-package}{ICESat2VegR: NASA ICESat-2 data for land \& vegetation}{ICESat2VegR.Rdash.package}
\aliasA{ICESat2VegR}{ICESat2VegR-package}{ICESat2VegR}
%
\begin{Description}
Tools to download, read, process, model, and visualize ICESat-2 ATL03/ATL08
for land and vegetation applications.
\end{Description}
%
\begin{Author}
\strong{Maintainer}: Caio Hamamura \email{caiohamamura@gmail.com} [copyright holder]

Authors:
\begin{itemize}

\item{} Carlos Alberto Silva \email{c.silva@ufl.edu} [copyright holder]

\end{itemize}


\end{Author}
%
\begin{SeeAlso}
Useful links:
\begin{itemize}

\item{} \url{https://github.com/carlos-alberto-silva/ICESat2VegR}
\item{} Report bugs at \url{https://github.com/carlos-alberto-silva/ICESat2VegR/issues}

\end{itemize}


\end{SeeAlso}
\HeaderA{.as\_ee\_geom}{Convert R geometry objects to an Earth Engine geometry}{.as.Rul.ee.Rul.geom}
%
\begin{Description}
\code{.as\_ee\_geom()} converts a variety of R geometry representations
(including \code{sf}, \code{sfc}, \code{terra} objects, bounding boxes, WKT/GeoJSON,
and even existing Earth Engine python objects) into a Python
\code{ee\$Geometry} suitable for use in Earth Engine workflows.

This helper is designed to be flexible and permissive: it accepts
most common spatial formats used in R and normalizes them into a
standard Earth Engine geometry. When a buffer distance is supplied,
the geometry is optionally buffered in meters on the Earth Engine side.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
.as_ee_geom(geom, xcol = "lon", ycol = "lat", crs = 4326, buffer_m = NULL)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{geom}] Geometry input. Supported types include:
\begin{itemize}

\item{} An Earth Engine python object (e.g. \code{ee\$Geometry}, \code{ee\$Feature},
\code{ee\$FeatureCollection}). Features/FeatureCollections are
reduced to their geometry via \AsIs{\texttt{\$geometry()}}.
\item{} An \code{sf} or \code{sfc} object.
\item{} A \code{terra::SpatVector}.
\item{} A \code{terra::SpatExtent} (or numeric vector of length 4 specifying
a bounding box as \code{c(xmin, ymin, xmax, ymax)}).
\item{} A \code{data.frame} with longitude/latitude columns (\code{xcol}, \code{ycol}).
\item{} A single-character WKT string.
\item{} A single-character GeoJSON string.
\item{} A parsed GeoJSON list with a non-\code{NULL} \code{type} element.

\end{itemize}


\item[\code{xcol}] Character. Name of the longitude column when \code{geom} is a
\code{data.frame}. Default is \code{"lon"}.

\item[\code{ycol}] Character. Name of the latitude column when \code{geom} is a
\code{data.frame}. Default is \code{"lat"}.

\item[\code{crs}] Coordinate reference system of the input geometry when \code{geom}
is an \code{sf}/\code{sfc} object or a \code{data.frame}. Can be any \code{sf}-compatible
CRS specification (default is EPSG 4326).

\item[\code{buffer\_m}] Optional numeric. Buffer distance in meters applied to
the resulting Earth Engine geometry. If \code{NULL} (default) no buffering
is applied. For sf/data.frame inputs, buffering is done on the EE side
using \code{ee\$Geometry\$buffer()}.
\end{ldescription}
\end{Arguments}
%
\begin{Details}
For \code{sf}/\code{sfc} and \code{data.frame} inputs, geometries are first transformed
to EPSG:4326 and written to a temporary GeoJSON file, which is then read
and wrapped into an \code{ee\$FeatureCollection(... )\$geometry()}. For
\code{terra::SpatVector} and \code{terra::SpatExtent} inputs, conversion proceeds
via \code{terra::writeVector()} / \code{terra::as.polygons()} and an EE rectangle
geometry, respectively.

Existing Earth Engine python objects are returned as-is, except that
\code{ee\$Feature} and \code{ee\$FeatureCollection} objects are coerced to their
underlying geometry via \AsIs{\texttt{\$geometry()}}.
\end{Details}
%
\begin{Value}
A Python \code{ee\$Geometry} object (or compatible geometry-like EE object)
suitable for use in Earth Engine operations.
\end{Value}
%
\begin{Examples}
\begin{ExampleCode}
## Not run: 
  ee <- reticulate::import("ee", delay_load = FALSE)

  # 1) From sf polygon
  library(sf)
  poly <- st_as_sfc(st_bbox(c(
    xmin = -82.4, xmax = -82.2,
    ymin =  29.6, ymax =  29.8
  ), crs = 4326))

  ee_geom1 <- .as_ee_geom(poly)


  # 2) From terra::SpatVector
  library(terra)
  v <- vect(system.file("extdata", "all_boundary.shp", package = "ICESat2VegR"))
  ee_geom2 <- .as_ee_geom(v, buffer_m = 30)


  # 3) From numeric extent (xmin, ymin, xmax, ymax)
  bbox_vec <- c(-82.4, 29.6, -82.2, 29.8)
  ee_geom3 <- .as_ee_geom(bbox_vec)


  # 4) From data.frame of points
  df <- data.frame(
    lon = c(-82.3, -82.25),
    lat = c(29.65, 29.7)
  )
  ee_geom4 <- .as_ee_geom(df, buffer_m = 1000)

## End(Not run)

\end{ExampleCode}
\end{Examples}
\HeaderA{.ee\_ping}{Check if Google Earth Engine is initialized}{.ee.Rul.ping}
%
\begin{Description}
\code{.ee\_ping()} verifies that the Earth Engine Python API is initialized and
responsive. It attempts to evaluate a trivial Earth Engine expression
(\code{ee\$Image\$constant(1)\$getInfo()}) and returns invisibly if successful.
If the call fails, an error is raised with a hint to authenticate and
initialize Earth Engine.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
.ee_ping(ee)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{ee}] The Earth Engine Python module as returned by
\code{reticulate::import("ee")}.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
Invisibly returns \code{TRUE} if Earth Engine is initialized and responsive.
Otherwise, an error is thrown indicating that Earth Engine must be
authenticated and initialized.
\end{Value}
%
\begin{Examples}
\begin{ExampleCode}
## Not run: 
  library(reticulate)
  ee <- import("ee", delay_load = FALSE)

  # Will error if EE is not authenticated/initialized
  .ee_ping(ee)

## End(Not run)

\end{ExampleCode}
\end{Examples}
\HeaderA{addEEImage}{Add an Earth Engine Image to a leaflet map}{addEEImage}
%
\begin{Description}
Add an Earth Engine Image to a leaflet map
\end{Description}
%
\begin{Usage}
\begin{verbatim}
addEEImage(
  map,
  img,
  bands = NULL,
  min_value = 0,
  max_value = 1,
  palette = c("#d55e00", "#cc79a7", "#f0e442", "#0072b2", "#009e73"),
  group = NULL,
  aoi = NULL,
  ...
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{map}] A \code{leaflet::leaflet} widget.

\item[\code{img}] An Earth Engine image (reticulate \code{python.builtin.object} with \AsIs{\texttt{\$visualize}}, \AsIs{\texttt{\$select}}).

\item[\code{bands}] Character or numeric vector (length 1 or 3). If \code{NULL}, uses all bands from the image.

\item[\code{min\_value}] max\_value Numeric visualization range. Aliases: \code{min}, \code{max}.

\item[\code{palette}] Character vector of colors for single-band rendering.

\item[\code{group}] Optional overlay group name.

\item[\code{aoi}] Optional EE geometry to clip before rendering.

\item[\code{...}] Passed to \code{leaflet::addTiles()} (e.g., \code{options = leaflet::tileOptions(opacity = 0.8)}).
\end{ldescription}
\end{Arguments}
%
\begin{Value}
The input \code{leaflet} map with the EE image layer added.
\end{Value}
\HeaderA{aspect}{Compute terrain aspect (degrees) from a DEM image}{aspect}
%
\begin{Description}
Computes the terrain \emph{aspect} in degrees for each pixel of an Earth Engine
\code{ee\$Image} representing a digital elevation model (DEM).

Aspect describes the downslope direction of the steepest gradient and is
expressed in degrees clockwise from north. The computation is performed
using Earth Engineâ€™s built-in \code{ee\$Terrain\$aspect()} function. As with slope,
Earth Engine uses the 4-connected neighborhood, so missing values may occur
near image edges.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
aspect(x)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] An \code{ee\$Image} representing a DEM from which aspect will be derived.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
An \code{ee\$Image} with one band named \code{"aspect"} containing aspect
values in degrees clockwise from north.
\end{Value}
%
\begin{Examples}
\begin{ExampleCode}
## Not run: 
  ee <- reticulate::import("ee")
  dem <- ee$Image("NASA/NASADEM_HGT/001")
  asp <- aspect(dem)

## End(Not run)

\end{ExampleCode}
\end{Examples}
\HeaderA{ATL03\_ATL08\_compute\_seg\_attributes\_dt\_segStat}{Statistics of ATL03 and ATL08 labeled photons at the segment level}{ATL03.Rul.ATL08.Rul.compute.Rul.seg.Rul.attributes.Rul.dt.Rul.segStat}
%
\begin{Description}
Computes a series of statistics from ATL03 and ATL08 labeled photons
within a given segment length.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
ATL03_ATL08_compute_seg_attributes_dt_segStat(
  atl03_atl08_seg_dt,
  list_expr,
  ph_class = c(0, 1, 2, 3),
  beam = c("gt1l", "gt1r", "gt2l", "gt2r", "gt3l", "gt3r"),
  quality_ph = NULL,
  night_flag = NULL
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{atl03\_atl08\_seg\_dt}] An S4 object of class \code{\LinkA{icesat2.atl03\_atl08\_seg\_dt}{icesat2.atl03.Rul.atl08.Rul.seg.Rul.dt.Rdash.class}} containing ATL03 and ATL08 data
(output of \code{\LinkA{ATL03\_ATL08\_photons\_attributes\_dt\_join()}{ATL03.Rul.ATL08.Rul.photons.Rul.attributes.Rul.dt.Rul.join}} function).

\item[\code{list\_expr}] The function to be applied for computing the defined statistics

\item[\code{ph\_class}] Character vector indicating photons to process based
on the classification (1=ground, 2=canopy, 3=top canopy),
Default is c(2,3)

\item[\code{beam}] Character vector indicating beams to process. Default is
c("gt1l", "gt1r", "gt2l", "gt2r", "gt3l", "gt3r")

\item[\code{quality\_ph}] Indicates the quality of the associated photon.
0 = nominal, 1 = possible\_afterpulse, 2 = possible\_impulse\_response\_
effect, 3=possible\_tep. Default is 0

\item[\code{night\_flag}] Flag indicating the data were acquired in night conditions: 0=day, 1=night. Default is 1
\end{ldescription}
\end{Arguments}
%
\begin{Value}
Returns an S4 object of class \code{\LinkA{icesat2.atl08\_dt}{icesat2.atl08.Rul.dt.Rdash.class}}
Containing Statistics of ATL03 and ATL08 labeled photons
\end{Value}
%
\begin{Examples}
\begin{ExampleCode}
# Specifying ATL03 and ATL08 file path
atl03_path <- system.file("extdata",
  "atl03_clip.h5",
  package = "ICESat2VegR"
)

atl08_path <- system.file("extdata",
  "atl08_clip.h5",
  package = "ICESat2VegR"
)

# Reading ATL03 data (h5 file)
atl03_h5 <- ATL03_read(atl03_path = atl03_path)

# Reading ATL08 data (h5 file)
atl08_h5 <- ATL08_read(atl08_path = atl08_path)

# Extracting ATL03 and ATL08 labeled photons
atl03_atl08_dt <- ATL03_ATL08_photons_attributes_dt_join(atl03_h5, atl08_h5)

# Computing the max canopy height at 30 m segments
atl03_atl08_dt_seg <- ATL03_ATL08_segment_create(atl03_atl08_dt, segment_length = 30)

max_canopy <- ATL03_ATL08_compute_seg_attributes_dt_segStat(atl03_atl08_dt_seg,
  list_expr = max(ph_h),
  ph_class = c(2, 3),
  beam = c("gt1l", "gt1r", "gt2l", "gt2r", "gt3l", "gt3r"),
  quality_ph = 0,
  night_flag = 0
)

head(max_canopy)

# Computing a series of canopy height statistics from customized list expressions
canopy_metrics <- ATL03_ATL08_compute_seg_attributes_dt_segStat(atl03_atl08_dt_seg,
  list_expr = list(
    max_ph_elevation = max(h_ph),
    h_canopy = quantile(ph_h, 0.98),
    n_canopy = sum(classed_pc_flag == 2),
    n_top_canopy = sum(classed_pc_flag == 3)
  ),
  ph_class = c(2, 3),
  beam = c("gt1l", "gt1r", "gt2l", "gt2r", "gt3l", "gt3r"),
  quality_ph = 0,
  night_flag = 0 # there are no night photons in this dataset
)

head(canopy_metrics)

close(atl03_h5)
close(atl08_h5)
\end{ExampleCode}
\end{Examples}
\HeaderA{ATL03\_ATL08\_photons\_attributes\_dt\_clipBox}{Clip joined ATL03 and ATL08 photons by Bounding Box}{ATL03.Rul.ATL08.Rul.photons.Rul.attributes.Rul.dt.Rul.clipBox}
%
\begin{Description}
This function clips joined ATL03 and ATL08 photon attributes within a given Bounding Box
\end{Description}
%
\begin{Usage}
\begin{verbatim}
ATL03_ATL08_photons_attributes_dt_clipBox(
  atl03_atl08_dt,
  lower_left_lon,
  upper_right_lon,
  upper_right_lat,
  lower_left_lat
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{atl03\_atl08\_dt}] An S4 object of class \code{\LinkA{icesat2.atl03atl08\_dt}{icesat2.atl03atl08.Rul.dt.Rdash.class}} containing ATL03 and ATL08 data
(output of \code{\LinkA{ATL03\_ATL08\_photons\_attributes\_dt\_join()}{ATL03.Rul.ATL08.Rul.photons.Rul.attributes.Rul.dt.Rul.join}} function).

\item[\code{lower\_left\_lon}] Numeric. West longitude (x) coordinate of bounding rectangle, in decimal degrees.

\item[\code{upper\_right\_lon}] Numeric. East longitude (x) coordinate of bounding rectangle, in decimal degrees.

\item[\code{upper\_right\_lat}] Numeric. North latitude (y) coordinate of bounding rectangle, in decimal degrees.

\item[\code{lower\_left\_lat}] Numeric. South latitude (y) coordinate of bounding rectangle, in decimal degrees.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
Returns an S4 object of class \code{\LinkA{icesat2.atl03atl08\_dt}{icesat2.atl03atl08.Rul.dt.Rdash.class}}
containing a subset of the ATL03 and ATL08 photon attributes.
\end{Value}
%
\begin{SeeAlso}
\url{https://icesat-2.gsfc.nasa.gov/sites/default/files/page_files/ICESat2_ATL03_ATBD_r006.pdf}

\url{https://icesat-2.gsfc.nasa.gov/sites/default/files/page_files/ICESat2_ATL08_ATBD_r006.pdf}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}
# Specifying the path to ATL03 and ATL08 file
atl03_path <- system.file("extdata",
  "atl03_clip.h5",
  package = "ICESat2VegR"
)

atl08_path <- system.file("extdata",
  "atl08_clip.h5",
  package = "ICESat2VegR"
)

# Reading ATL03 data (h5 file)
atl03_h5 <- ATL03_read(atl03_path = atl03_path)

# Reading ATL08 data (h5 file)
atl08_h5 <- ATL08_read(atl08_path = atl08_path)

# Joining ATL03 and ATL08 photons and heights
atl03_atl08_dt <- ATL03_ATL08_photons_attributes_dt_join(atl03_h5, atl08_h5)
head(atl03_atl08_dt)

# Bounding rectangle coordinates
lower_left_lon <- -103.7604
lower_left_lat <- 59.4672
upper_right_lon <- -103.7600
upper_right_lat <- 59.4680

# Clipping ATL08-derived canopy metrics by boundary box extent
atl03_atl08_dt_clip <- ATL03_ATL08_photons_attributes_dt_clipBox(
  atl03_atl08_dt,
  lower_left_lon,
  upper_right_lon,
  upper_right_lat,
  lower_left_lat
)
head(atl03_atl08_dt_clip)

close(atl03_h5)
close(atl08_h5)
\end{ExampleCode}
\end{Examples}
\HeaderA{ATL03\_ATL08\_photons\_attributes\_dt\_clipGeometry}{Clip Joined ATL03 and ATL08 by Geometry}{ATL03.Rul.ATL08.Rul.photons.Rul.attributes.Rul.dt.Rul.clipGeometry}
%
\begin{Description}
This function clips joined ATL03 and ATL08 photon attributes within a given geometry.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
ATL03_ATL08_photons_attributes_dt_clipGeometry(
  atl03_atl08_dt,
  clip_obj,
  split_by = NULL
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{atl03\_atl08\_dt}] An S4 object of class \code{\LinkA{icesat2.atl03atl08\_dt}{icesat2.atl03atl08.Rul.dt.Rdash.class}} containing ATL03 and ATL08 data
(output of \code{\LinkA{ATL03\_ATL08\_photons\_attributes\_dt\_join()}{ATL03.Rul.ATL08.Rul.photons.Rul.attributes.Rul.dt.Rul.join}} function).

\item[\code{clip\_obj}] An object of class \code{\LinkA{terra::SpatVector}{terra::SpatVector}}, which can be loaded as an ESRI shapefile using \LinkA{terra::vect}{terra::vect} function.

\item[\code{split\_by}] Optional. clip\_obj ID. If defined, the data will be clipped by each clip\_obj using
the clip\_obj ID from the attribute table.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
Returns an S4 object of class \code{\LinkA{icesat2.atl03atl08\_dt}{icesat2.atl03atl08.Rul.dt.Rdash.class}}
containing the clipped ATL08 attributes.
\end{Value}
%
\begin{Examples}
\begin{ExampleCode}
# Specifying the path to ATL03 and ATL08 files
atl03_path <- system.file("extdata", "atl03_clip.h5", package = "ICESat2VegR")
atl08_path <- system.file("extdata", "atl08_clip.h5", package = "ICESat2VegR")

# Reading ATL03 and ATL08 data (h5 files)
atl03_h5 <- ATL03_read(atl03_path)
atl08_h5 <- ATL08_read(atl08_path)

# Joining ATL03 and ATL08 photon attributes
atl03_atl08_dt <- ATL03_ATL08_photons_attributes_dt_join(atl03_h5, atl08_h5)
head(atl03_atl08_dt)

# Specifying the path to the shapefile
clip_obj_filepath <- system.file("extdata", "clip_geom.shp", package = "ICESat2VegR")

# Reading shapefile as a SpatVector object
clip_obj <- terra::vect(clip_obj_filepath)

# Clipping ATL08 terrain attributes by geometry
atl03_atl08_dt_clip <- ATL03_ATL08_photons_attributes_dt_clipGeometry(
  atl03_atl08_dt,
  clip_obj,
  split_by = "id"
)
head(atl03_atl08_dt_clip)

close(atl03_h5)
close(atl08_h5)
\end{ExampleCode}
\end{Examples}
\HeaderA{ATL03\_ATL08\_photons\_attributes\_dt\_gridStat}{Statistics of ATL03 and ATL08 photon attributes}{ATL03.Rul.ATL08.Rul.photons.Rul.attributes.Rul.dt.Rul.gridStat}
%
\begin{Description}
This function computes a series of user defined descriptive statistics within
each given grid cell for ATL03 and ATL08 photon attributes
\end{Description}
%
\begin{Usage}
\begin{verbatim}
ATL03_ATL08_photons_attributes_dt_gridStat(
  atl03_atl08_dt,
  func,
  res = 0.5,
  ph_class = c(2, 3),
  beam = c("gt1l", "gt1r", "gt2l", "gt2r", "gt3l", "gt3r"),
  quality_ph = 0,
  night_flag = 1
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{atl03\_atl08\_dt}] An S4 object of class \code{\LinkA{icesat2.atl03atl08\_dt}{icesat2.atl03atl08.Rul.dt.Rdash.class}}
containing ATL03 and ATL08 attributes
(output of the \code{\LinkA{ATL03\_ATL08\_photons\_attributes\_dt\_join()}{ATL03.Rul.ATL08.Rul.photons.Rul.attributes.Rul.dt.Rul.join}} function).

\item[\code{func}] The function to be applied for computing the defined statistics

\item[\code{res}] Spatial resolution in decimal degrees for the output SpatRast raster layer.
Default is 0.5.

\item[\code{ph\_class}] Character vector indicating photons to process based on the classification
(1=ground, 2=canopy, 3=top canopy), Default is c(2,3)

\item[\code{beam}] Character vector indicating beams to process. Default is c("gt1l", "gt1r", "gt2l",
"gt2r", "gt3l", "gt3r")

\item[\code{quality\_ph}] Indicates the quality of the associated photon. 0=nominal,
1=possible\_afterpulse, 2=possible\_impulse\_response\_effect, 3=possible\_tep. Default is 0

\item[\code{night\_flag}] Flag indicating the data were acquired in night conditions: 0=day, 1=night.
Default is 1
\end{ldescription}
\end{Arguments}
%
\begin{Value}
Return a SpatRast raster layer(s) of selected ATL03 and ATL08 photon attribute(s)
\end{Value}
%
\begin{Examples}
\begin{ExampleCode}
# ATL03 file path
atl03_path <- system.file("extdata",
  "atl03_clip.h5",
  package = "ICESat2VegR"
)

# ATL08 file path
atl08_path <- system.file("extdata",
  "atl08_clip.h5",
  package = "ICESat2VegR"
)
# Reading ATL03 data (h5 file)
atl03_h5 <- ATL03_read(atl03_path = atl03_path)

# Reading ATL08 data (h5 file)
atl08_h5 <- ATL08_read(atl08_path = atl08_path)

# # Extracting ATL03 and ATL08 photons and heights
atl03_atl08_dt <- ATL03_ATL08_photons_attributes_dt_join(atl03_h5, atl08_h5)

# Computing the mean of ph_h attribute at 0.0002 degree grid cell
mean_ph_h <- ATL03_ATL08_photons_attributes_dt_gridStat(atl03_atl08_dt,
  func = mean(ph_h),
  res = 0.0002
)

plot(mean_ph_h)

# Define your own function
mySetOfMetrics <- function(x) {
  metrics <- list(
    min = min(x), # Min of x
    max = max(x), # Max of x
    mean = mean(x), # Mean of x
    sd = sd(x) # Sd of x
  )
  return(metrics)
}

# Computing a series of ph_h stats at 0.0002 degree grid cell from customized function
ph_h_metrics <- ATL03_ATL08_photons_attributes_dt_gridStat(atl03_atl08_dt,
  func = mySetOfMetrics(ph_h), res = 0.0002
)

plot(ph_h_metrics)

close(atl03_h5)
close(atl08_h5)
\end{ExampleCode}
\end{Examples}
\HeaderA{ATL03\_ATL08\_photons\_attributes\_dt\_join}{Join ATL03 and ATL08 photons attributes}{ATL03.Rul.ATL08.Rul.photons.Rul.attributes.Rul.dt.Rul.join}
%
\begin{Description}
This function joins ATL03 and ATL08 computed photons attributes
\end{Description}
%
\begin{Usage}
\begin{verbatim}
ATL03_ATL08_photons_attributes_dt_join(
  atl03_h5,
  atl08_h5,
  beam = c("gt1l", "gt1r", "gt2l", "gt2r", "gt3l", "gt3r")
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{atl03\_h5}] A ICESat-2 ATL03 object (output of \code{\LinkA{ATL03\_read()}{ATL03.Rul.read}} function).
An S4 object of class \code{\LinkA{icesat2.atl03\_dt}{icesat2.atl03.Rul.dt.Rdash.class}}.

\item[\code{atl08\_h5}] A ICESat-2 ATL08 object (output of \code{\LinkA{ATL08\_read()}{ATL08.Rul.read}} function).
An S4 object of class \code{\LinkA{icesat2.atl08\_dt}{icesat2.atl08.Rul.dt.Rdash.class}}.

\item[\code{beam}] Character vector indicating beams to process
(e.g. "gt1l", "gt1r", "gt2l", "gt2r", "gt3l", "gt3r")
\end{ldescription}
\end{Arguments}
%
\begin{Details}
These are the photons attributes extracted by default:
\begin{itemize}

\item{} \code{ph\_segment\_id}: Georeferenced segment id (20-m) associated with each photon.
\item{} \code{lon\_ph}: Longitude of each received photon. Computed from the ECEF Cartesian coordinates
of the bounce point.
\item{} \code{lat\_ph}: Latitude of each received photon. Computed from the ECEF Cartesian coordinates
of the bounce point.
\item{} \code{h\_ph}: Height of each received photon, relative to the WGS-84 ellipsoid including the
geophysical corrections noted in section 6.0. Please note that neither the geoid,
ocean tide nor the dynamic atmospheric corrections (DAC) are applied to the
ellipsoidal heights.
\item{} \code{quality\_ph}: Indicates the quality of the associated photon. 0=nominal,
1=possible\_afterpulse, 2=possible\_impulse\_response\_effect, 3=possible\_tep.
Use this flag in conjunction with \code{signal\_conf\_ph} to identify those photons
that are likely noise or likely signal.
\item{} \code{solar\_elevation}: Elevation of the sun above the horizon at the photon bounce point.
\item{} \code{dist\_ph\_along}: Along-track distance of the photon from the beginning of the segment.
\item{} \code{dist\_ph\_across}: Across-track distance of the photon from the center of the segment.
\item{} \code{night\_flag}: Flag indicating the data were acquired in night conditions: 0=day, 1=night.
Night flag is set when solar elevation is below 0.0 degrees.
\item{} \code{classed\_pc\_indx}: Indices of photons tracking back to ATL03 that surface finding software
identified and used within the creation of the data products.
\item{} \code{classed\_pc\_flag}: The L2B algorithm is run if this flag is set to 1 indicating data have
sufficient waveform fidelity for L2B to run.
\item{} \code{ph\_h}: Height of photon above interpolated ground surface.
\item{} \code{d\_flag}: Flag indicating whether DRAGANN labeled the photon as noise or signal.
\item{} \code{delta\_time}: Mid-segment GPS time in seconds past an epoch. The epoch is provided in
the metadata at the file level.
\item{} \code{orbit\_number}: Orbit number identifier to identify data from different orbits.
\item{} \code{beam}: Beam identifier.
\item{} \code{strong\_beam}: Logical indicating if the beam is a strong beam.

\end{itemize}

\end{Details}
%
\begin{Value}
Returns an S4 object of class \code{\LinkA{icesat2.atl03atl08\_dt}{icesat2.atl03atl08.Rul.dt.Rdash.class}}
containing the ATL08 computed photons attributes.
\end{Value}
%
\begin{SeeAlso}
\url{https://icesat-2.gsfc.nasa.gov/sites/default/files/page_files/ICESat2_ATL08_ATBD_r006.pdf}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}
# Specifying the path to ATL03 file
atl03_path <- system.file("extdata",
  "atl03_clip.h5",
  package = "ICESat2VegR"
)

# Specifying the path to ATL08 file
atl08_path <- system.file("extdata",
  "atl08_clip.h5",
  package = "ICESat2VegR"
)

# Reading ATL03 data (h5 file)
atl03_h5 <- ATL03_read(atl03_path = atl03_path)

# Reading ATL08 data (h5 file)
atl08_h5 <- ATL08_read(atl08_path = atl08_path)

# # Extracting ATL03 and ATL08 photons and heights
atl03_atl08_dt <- ATL03_ATL08_photons_attributes_dt_join(atl03_h5, atl08_h5)
head(atl03_atl08_dt)

close(atl03_h5)
close(atl08_h5)
\end{ExampleCode}
\end{Examples}
\HeaderA{ATL03\_ATL08\_photons\_attributes\_dt\_LAS}{Converts ATL03/ATL08 classified photon cloud to LAS}{ATL03.Rul.ATL08.Rul.photons.Rul.attributes.Rul.dt.Rul.LAS}
%
\begin{Description}
Converts ATL03/ATL08 classified photon cloud to LAS
\end{Description}
%
\begin{Usage}
\begin{verbatim}
ATL03_ATL08_photons_attributes_dt_LAS(
  atl03_atl08_dt,
  output,
  normalized = TRUE
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{atl03\_atl08\_dt}] An S4 object of class \code{\LinkA{icesat2.atl08\_dt}{icesat2.atl08.Rul.dt.Rdash.class}}
containing ATL03 and ATL08 data (output of
\code{\LinkA{ATL03\_ATL08\_photons\_attributes\_dt\_join()}{ATL03.Rul.ATL08.Rul.photons.Rul.attributes.Rul.dt.Rul.join}} function).

\item[\code{output}] character. The output path of for the LAS(Z) file(s). The
function will create one LAS file per UTM Zone in WGS84 datum.

\item[\code{normalized}] logical, default TRUE. Whether the output should be
normalized LAS or raw altitude.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
Nothing, it just saves outputs as LAS file in disk
\end{Value}
%
\begin{Examples}
\begin{ExampleCode}
outdir <- tempdir()

# ATL03 file path
atl03_path <- system.file("extdata",
  "atl03_clip.h5",
  package = "ICESat2VegR"
)

# ATL08 file path
atl08_path <- system.file("extdata",
  "atl08_clip.h5",
  package = "ICESat2VegR"
)

# Reading ATL03 data (h5 file)
atl03_h5 <- ATL03_read(atl03_path = atl03_path)

# Reading ATL08 data (h5 file)
atl08_h5 <- ATL08_read(atl08_path = atl08_path)

# Extracting ATL03 and ATL08 photons and heights
atl03_atl08_dt <- ATL03_ATL08_photons_attributes_dt_join(atl03_h5, atl08_h5)

if (require("lidR")) {
  ATL03_ATL08_photons_attributes_dt_LAS(
    atl03_atl08_dt,
    output = file.path(outdir, "output.laz"),
    normalized = TRUE
  )
}

close(atl03_h5)
close(atl08_h5)
\end{ExampleCode}
\end{Examples}
\HeaderA{ATL03\_ATL08\_photons\_attributes\_dt\_polyStat}{Statistics of ATL03 and ATL08 joined photons attributes within a given area}{ATL03.Rul.ATL08.Rul.photons.Rul.attributes.Rul.dt.Rul.polyStat}
%
\begin{Description}
Computes a series of statistics ATL03 and ATL08 joined photons
attributes within area defined by a polygon
\end{Description}
%
\begin{Usage}
\begin{verbatim}
ATL03_ATL08_photons_attributes_dt_polyStat(
  atl03_atl08_dt,
  func,
  poly_id = NULL
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{atl03\_atl08\_dt}] An S4 object of class \code{\LinkA{icesat2.atl08\_dt}{icesat2.atl08.Rul.dt.Rdash.class}}
containing ATL03 and ATL08 data (output of \code{\LinkA{ATL03\_ATL08\_photons\_attributes\_dt\_join()}{ATL03.Rul.ATL08.Rul.photons.Rul.attributes.Rul.dt.Rul.join}}
function).

\item[\code{func}] The function to be applied for computing the defined statistics

\item[\code{poly\_id}] Polygon id. If defined, statistics will be computed for each polygon
\end{ldescription}
\end{Arguments}
%
\begin{Value}
Returns an S4 object of class \code{\LinkA{icesat2.atl08\_dt}{icesat2.atl08.Rul.dt.Rdash.class}}
Containing Statistics of ATL08 classified canopy photons
\end{Value}
%
\begin{Examples}
\begin{ExampleCode}
# Specifying the path to ATL03 and ATL08 files
# ATL03 file path
atl03_path <- system.file("extdata",
  "atl03_clip.h5",
  package = "ICESat2VegR"
)

# ATL08 file path
atl08_path <- system.file("extdata",
  "atl08_clip.h5",
  package = "ICESat2VegR"
)

# Reading ATL03 data (h5 file)
atl03_h5 <- ATL03_read(atl03_path = atl03_path)

# Reading ATL08 data (h5 file)
atl08_h5 <- ATL08_read(atl08_path = atl08_path)

# Extracting ATL03 and ATL08 photons and heights
atl03_atl08_dt <- ATL03_ATL08_photons_attributes_dt_join(atl03_h5, atl08_h5)
head(atl03_atl08_dt)

# Specifying the path to shapefile
polygon_filepath <- system.file("extdata", "clip_geom.shp", package = "ICESat2VegR")

# Reading shapefile as sf object
polygon <- terra::vect(polygon_filepath)

# Clipping ATL08 terrain attributes by Geometry
atl03_atl08_dt_clip <- ATL03_ATL08_photons_attributes_dt_clipGeometry(atl03_atl08_dt,
  polygon, split_by = "id")

# Computing the maximum ph_h by polygon id
max_ph_h <- ATL03_ATL08_photons_attributes_dt_polyStat(atl03_atl08_dt_clip,
  func = max(ph_h), poly_id = "poly_id")
head(max_ph_h)

# Define your own function
mySetOfMetrics <- function(x) {
  metrics <- list(
    min = min(x), # Min of x
    max = max(x), # Max of x
    mean = mean(x), # Mean of x
    sd = sd(x) # Sd of x
  )
  return(metrics)
}

# Computing a series of ph_h statistics from customized function
ph_h_metrics <- ATL03_ATL08_photons_attributes_dt_polyStat(
  atl03_atl08_dt_clip,
  func = mySetOfMetrics(ph_h),
  poly_id = "poly_id"
)

head(ph_h_metrics)

close(atl03_h5)
close(atl08_h5)
\end{ExampleCode}
\end{Examples}
\HeaderA{ATL03\_ATL08\_photons\_dt\_height\_normalize}{Fit and estimate ground elevation for photons or arbitrary distances from the track beginning.}{ATL03.Rul.ATL08.Rul.photons.Rul.dt.Rul.height.Rul.normalize}
%
\begin{Description}
Function to estimate ground elevation using smoothing and
interpolation functions
\end{Description}
%
\begin{Usage}
\begin{verbatim}
ATL03_ATL08_photons_dt_height_normalize(
  atl03_atl08_seg_dt,
  smoothing_window = NA,
  smoothing_func = median,
  interpolation_func = NA,
  xout_parameter_name = "xout",
  ...
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{atl03\_atl08\_seg\_dt}] An S4 object of class \code{\LinkA{icesat2.atl03\_atl08\_seg\_dt}{icesat2.atl03.Rul.atl08.Rul.seg.Rul.dt.Rdash.class}} containing ATL03 and ATL08 data
(output of \code{\LinkA{ATL03\_ATL08\_photons\_attributes\_dt\_join()}{ATL03.Rul.ATL08.Rul.photons.Rul.attributes.Rul.dt.Rul.join}} function).

\item[\code{smoothing\_window}] numeric. The smoothing window size in meters for smoothing the photon cloud.
Default is NA, see details for more information.

\item[\code{smoothing\_func}] function. The smoothing function to be applied on the smoothing window.

\item[\code{interpolation\_func}] function. The interpolation function to estimate the ground elevation.
Default \code{\LinkA{stats::approx()}{stats::approx()}}.

\item[\code{xout\_parameter\_name}] character. The parameter name used for the \code{interpolation\_func} to
which will be used to predict, default "xout".

\item[\code{...}] parameters to be passed forward to \code{\LinkA{ATL03\_ATL08\_photons\_seg\_dt\_fitground()}{ATL03.Rul.ATL08.Rul.photons.Rul.seg.Rul.dt.Rul.fitground}}.
\end{ldescription}
\end{Arguments}
%
\begin{Details}
The function for calculating the ground will first pass a smoothing
window with \code{smoothing\_window} size,
applying the \code{smoothing\_func} to aggregate the ground photons.

Then it will use an interpolation function between those
aggregated photons to calculate a smooth surface.

The \code{smoothing\_func} signature will depend on the function used.
It is assumed that the first two arguments are vectors of \code{x} (independent
variable) and \code{y} (the prediction to be interpolated). The remaining
arguments are passed through \code{...}.

The interpolation functions need a third parameter which is the
\code{x} vector to be interpolated. Functions from \code{stats} base package
\code{stats::approx()} and \code{stats::spline()} name this argument as \code{xout},
so you can use:

\begin{alltt}ATL03_ATL08_photons_fitground_seg_dt(
  dt,
  interpolation_func = approx,
  xout = 1:30
)
\end{alltt}


For example, to interpolate the values for the 1:30 vector. However, other
functions may name the parameter differently, such as \code{signal::pchip()},
which calls the parameter \code{xi} instead of \code{xout}.
The \code{pchip} algorithm (as implemented in the \strong{signal} package)
is the one used by the ATL08 ATBD.

The \code{smoothing\_window} can be left NA, which will use the ATBD algoritm
for calculating the window size:

\eqn{Sspan = ceil[5 + 46 * (1 - e^{-a * length})]}{}, where \emph{length}
is the number of photons within segment.

\deqn{a \approx 21x10^{-6}}{}

\deqn{window_size = \frac{2}{3} Sspan}{}

This is not the same algorithm as used in ATL08
but is an adapted version that uses the ATL08
pre-classification
\end{Details}
\HeaderA{ATL03\_ATL08\_photons\_seg\_dt\_fitground}{Fit and estimate ground elevation for photons or arbitrary distances from the track beginning.}{ATL03.Rul.ATL08.Rul.photons.Rul.seg.Rul.dt.Rul.fitground}
%
\begin{Description}
Function to estimate ground elevation using smoothing and
interpolation functions
\end{Description}
%
\begin{Usage}
\begin{verbatim}
ATL03_ATL08_photons_seg_dt_fitground(
  atl03_atl08_seg_dt,
  smoothing_window = NA,
  smoothing_func = median,
  interpolation_func = NA,
  xout_parameter_name = "xout",
  ...
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{atl03\_atl08\_seg\_dt}] An S4 object of class \code{\LinkA{icesat2.atl03\_atl08\_seg\_dt}{icesat2.atl03.Rul.atl08.Rul.seg.Rul.dt.Rdash.class}} containing ATL03 and ATL08 data
(output of \code{\LinkA{ATL03\_ATL08\_photons\_attributes\_dt\_join()}{ATL03.Rul.ATL08.Rul.photons.Rul.attributes.Rul.dt.Rul.join}} function).

\item[\code{smoothing\_window}] numeric. The smoothing window size in meters for smoothing the photon cloud.
Default is NA, see details for more information.

\item[\code{smoothing\_func}] function. The smoothing function to be applied on the smoothing window.

\item[\code{interpolation\_func}] function. The interpolation function to estimate the ground elevation.

\item[\code{xout\_parameter\_name}] character. Optional, can be used to inform the parameter name that the
interpolation\_func uses for passing the prediction vector and already use the photons for prediction.
Default NA will use the ...

\item[\code{...}] Optional parameters to pass to the interpolation\_func, see details for more information.
\end{ldescription}
\end{Arguments}
%
\begin{Details}
The function for calculating the ground will first pass a smoothing
window with \code{smoothing\_window} size,
applying the \code{smoothing\_func} to aggregate the ground photons.

Then it will use an interpolation function between those
aggregated photons to calculate a smooth surface.

The \code{smoothing\_func} signature will depend on the function used.
It is assumed that the first two arguments are vectors of \code{x} (independent
variable) and \code{y} (the prediction to be interpolated). The remaining
arguments are passed through \code{...}.

The interpolation functions need a third parameter which is the
\code{x} vector to be interpolated. Functions from \code{stats} base package
\code{stats::approx()} and \code{stats::spline()} name this argument as \code{xout},
so you can use:

\begin{alltt}ATL03_ATL08_photons_fitground_seg_dt(
  dt,
  interpolation_func = approx,
  xout = 1:30
)
\end{alltt}


For example, to interpolate the values for the 1:30 vector. However, other
functions may name the parameter differently, such as \code{signal::pchip()},
which calls the parameter \code{xi} instead of \code{xout}.
The \code{pchip} algorithm (as implemented in the \strong{signal} package)
is the one used by the ATL08 ATBD.

The \code{smoothing\_window} can be left NA, which will use the ATBD algoritm
for calculating the window size:

\eqn{Sspan = ceil[5 + 46 * (1 - e^{-a * length})]}{}, where \emph{length}
is the number of photons within segment.

\deqn{a \approx 21x10^{-6}}{}

\deqn{window_size = \frac{2}{3} Sspan}{}

This is not the same algorithm as used in ATL08
but is an adapted version that uses the ATL08
pre-classification
\end{Details}
\HeaderA{ATL03\_ATL08\_segment\_create}{Compute segments id for a given segment length}{ATL03.Rul.ATL08.Rul.segment.Rul.create}
%
\begin{Description}
This function reads the ICESat-2 Land and
Vegetation Along-Track Products (ATL08) as h5 file.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
ATL03_ATL08_segment_create(
  atl03_atl08_dt,
  segment_length,
  centroid = "mean",
  output = NA,
  overwrite = FALSE
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{atl03\_atl08\_dt}] \code{\LinkA{icesat2.atl03atl08\_dt}{icesat2.atl03atl08.Rul.dt.Rdash.class}}.
The output of the \code{\LinkA{ATL03\_ATL08\_photons\_attributes\_dt\_join()}{ATL03.Rul.ATL08.Rul.photons.Rul.attributes.Rul.dt.Rul.join}}.

\item[\code{segment\_length}] \code{\LinkA{numeric}{numeric.Rdash.class}}. The desired segment length to split the photons.

\item[\code{centroid}] character. Method used to calculate the segment centroid, either "mean" or "midpoint",
see details. Default 'mean'.

\item[\code{output}] Character vector. The output vector file. The GDAL vector format
will be inferred by the file extension using \code{\LinkA{terra::writeVector()}{terra::writeVector()}}

\item[\code{overwrite}] logical input to control if the output vector file should be overwritten.
Default FALSE.
\end{ldescription}
\end{Arguments}
%
\begin{Details}
The centroid will be computed using either the photons centroid or the approximate segment centroid.
\begin{itemize}

\item{} "mean": calculated using the average coordinates from all photons within the segment.
This approach will better represent the mean statistics location.
\item{} "mid-point": the minimum and maximum coordinates will be averaged to calculate a midpoint within
the segment. This will give a better representation of the segment true mid-point

\end{itemize}

\end{Details}
%
\begin{Value}
Returns an S4 object of class \code{\LinkA{icesat2.atl03atl08\_dt}{icesat2.atl03atl08.Rul.dt.Rdash.class}} containing ICESat-2 ATL08 data.
\end{Value}
%
\begin{SeeAlso}
\url{https://icesat-2.gsfc.nasa.gov/sites/default/files/page_files/ICESat2_ATL08_ATBD_r006.pdf}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}
# Specifying the path to ICESat-2 ATL03 and ATL08 data
atl03_path <- system.file("extdata",
  "atl03_clip.h5",
  package = "ICESat2VegR"
)

atl08_path <- system.file("extdata",
  "atl08_clip.h5",
  package = "ICESat2VegR"
)

# Reading ICESat-2 ATL08 data (h5 file)
atl03_h5 <- ATL03_read(atl03_path = atl03_path)
atl08_h5 <- ATL08_read(atl08_path = atl08_path)

atl03_atl08_dt <- ATL03_ATL08_photons_attributes_dt_join(atl03_h5, atl08_h5)

atl03_atl08_dt_seg <- ATL03_ATL08_segment_create(atl03_atl08_dt,
  segment_length = 30,
  centroid = "mean",
  output = NA,
  overwrite = FALSE
)

head(atl03_atl08_dt_seg)

close(atl03_h5)
close(atl08_h5)
\end{ExampleCode}
\end{Examples}
\HeaderA{ATL03\_ATL08\_seg\_cover\_dt\_compute}{Compute segments id for a given segment length}{ATL03.Rul.ATL08.Rul.seg.Rul.cover.Rul.dt.Rul.compute}
%
\begin{Description}
This function reads the ICESat-2 Land and
Vegetation Along-Track Products (ATL08) as h5 file.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
ATL03_ATL08_seg_cover_dt_compute(atl03_atl08_dt, reflectance_ratio = 1)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{atl03\_atl08\_dt}] \code{\LinkA{icesat2.atl03atl08\_dt}{icesat2.atl03atl08.Rul.dt.Rdash.class}}.
The output of the \code{\LinkA{ATL03\_ATL08\_photons\_attributes\_dt\_join()}{ATL03.Rul.ATL08.Rul.photons.Rul.attributes.Rul.dt.Rul.join}}.

\item[\code{reflectance\_ratio}] Numeric. The reflectance ratio to use to compute the coverage metric.
\eqn{\rho_v / \rho_g}{}, where \eqn{\rho_v}{} is the vegetation reflectance
and \eqn{\rho_v}{} is the ground reflectance. Default is 1 (same reflectance).
\end{ldescription}
\end{Arguments}
%
\begin{Details}
Coverage is calculated with the formula
\deqn{\frac{1}{1 + \frac{\rho_v N_g}{\rho_g N_v}}}{}
\end{Details}
%
\begin{Value}
Returns an S4 object of class \code{\LinkA{data.table::data.table}{data.table::data.table}} containing ICESat-2 ATL08 data.
\end{Value}
%
\begin{SeeAlso}
\url{https://icesat-2.gsfc.nasa.gov/sites/default/files/page_files/ICESat2_ATL08_ATBD_r006.pdf}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}
# ATL08 file path
atl08_path <- system.file("extdata",
  "atl08_clip.h5",
  package = "ICESat2VegR"
)

# Reading ICESat-2 ATL08 data (h5 file)
atl08 <- ATL08_read(atl08_path = atl08_path)

close(atl08)
\end{ExampleCode}
\end{Examples}
\HeaderA{ATL03\_h5\_clipBox}{Clips ICESat-2 ATL03 H5 data}{ATL03.Rul.h5.Rul.clipBox}
%
\begin{Description}
This function clips ATL03 HDF5 file within beam groups,
but keeps metada and ancillary data the same.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
ATL03_h5_clipBox(
  atl03,
  output,
  bbox,
  beam = c("gt1r", "gt2r", "gt3r", "gt1l", "gt2l", "gt3l"),
  additional_groups = c("orbit_info")
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{atl03}] \code{\LinkA{icesat2.atl03\_h5}{icesat2.atl03.Rul.h5.Rdash.class}} object,
obtained through \code{\LinkA{ATL03\_read()}{ATL03.Rul.read}} for clipping

\item[\code{output}] character. Path to the output h5 file.

\item[\code{bbox}] \code{\LinkA{numeric}{numeric.Rdash.class}} or \code{\LinkA{terra::SpatExtent}{terra::SpatExtent}} for clipping, the
order of the bbox is the default from NASA's ICESat-2 CMS searching:
(ul\_lat, ul\_lon, lr\_lat, lr\_lon).

\item[\code{beam}] \code{\LinkA{character}{character.Rdash.class}}. The vector of beams to include, default
all c("gt1l", "gt2l", "gt3l", "gt1r", "gt2r", "gt3r")

\item[\code{additional\_groups}] \code{\LinkA{character}{character.Rdash.class}}. Other addional groups that should be included, default
c("orbit\_info")
\end{ldescription}
\end{Arguments}
%
\begin{Value}
Returns the clipped S4 object of class \code{\LinkA{icesat2.atl03\_h5}{icesat2.atl03.Rul.h5.Rdash.class}}
\end{Value}
%
\begin{Examples}
\begin{ExampleCode}
# ATL03 file path
atl03_path <- system.file("extdata",
  "atl03_clip.h5",
  package = "ICESat2VegR"
)

# Reading ATL03 data (h5 file)
atl03_h5 <- ATL03_read(atl03_path = atl03_path)

# Bounding rectangle coordinates
xmin <- -106.5723
xmax <- -106.5693
ymin <- 41.533
ymax <- 41.537

# Clipping ATL03 photons by boundary box extent
output <- tempfile(fileext = ".h5")
atl03_photons_dt_clip <- ATL03_h5_clipBox(atl03_h5, output, c(ymax, xmin, ymin, xmax))

close(atl03_h5)
\end{ExampleCode}
\end{Examples}
\HeaderA{ATL03\_h5\_clipGeometry}{Clips ICESat-2 ATL03 H5 data}{ATL03.Rul.h5.Rul.clipGeometry}
%
\begin{Description}
This function clips ATL03 HDF5 file within beam groups,
but keeps metada and ancillary data the same.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
ATL03_h5_clipGeometry(
  atl03,
  output,
  vect,
  clip_obj_id = NULL,
  beam = c("gt1r", "gt2r", "gt3r", "gt1l", "gt2l", "gt3l"),
  additional_groups = c("orbit_info")
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{atl03}] \code{\LinkA{icesat2.atl03\_h5}{icesat2.atl03.Rul.h5.Rdash.class}} object,
obtained through \code{\LinkA{ATL03\_read()}{ATL03.Rul.read}} for clipping

\item[\code{output}] character. Path to the output h5 file, the attribute for clip\_objs
will be appended to the file name.

\item[\code{vect}] \code{\LinkA{terra::SpatVector}{terra::SpatVector}} for clipping

\item[\code{clip\_obj\_id}] \code{\LinkA{character}{character.Rdash.class}}. The attribute name used for identifying
the different clip\_objs. Default is "id"

\item[\code{beam}] \code{\LinkA{character}{character.Rdash.class}}. The vector of beams to include, default
all c("gt1l", "gt2l", "gt3l", "gt1r", "gt2r", "gt3r")

\item[\code{additional\_groups}] \code{\LinkA{character}{character.Rdash.class}}. Other addional groups that should be included, default
c("orbit\_info")
\end{ldescription}
\end{Arguments}
%
\begin{Value}
Returns a list of clipped S4 object of class \code{\LinkA{icesat2.atl03\_h5}{icesat2.atl03.Rul.h5.Rdash.class}}
\end{Value}
%
\begin{Examples}
\begin{ExampleCode}
# ATL03 file path
atl03_path <- system.file("extdata",
  "atl03_clip.h5",
  package = "ICESat2VegR"
)

# Reading ATL03 data (h5 file)
atl03_h5 <- ATL03_read(atl03_path = atl03_path)

output <- tempfile(fileext = ".h5")

vect_path <- system.file("extdata",
  "clip_objs.shp",
  package = "ICESat2VegR"
)

vect <- terra::vect()

# Clipping ATL03 photons  by boundary box extent
atl03_photons_dt_clip <- ATL03_h5_clipGeometry(
  atl03_h5,
  output,
  vect,
  clip_obj_id = "id"
)

close(atl03_h5)
\end{ExampleCode}
\end{Examples}
\HeaderA{ATL03\_photons\_attributes\_dt}{ATL03 photon attributes}{ATL03.Rul.photons.Rul.attributes.Rul.dt}
%
\begin{Description}
Extract photon-level attributes from ICESat-2 ATL03 data.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
ATL03_photons_attributes_dt(
  atl03_h5,
  beam = c("gt1l", "gt1r", "gt2l", "gt2r", "gt3l", "gt3r")
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{atl03\_h5}] An ICESat-2 ATL03 object (output of \code{\LinkA{ATL03\_read()}{ATL03.Rul.read}}), i.e.
an S4 object of class \code{\LinkA{icesat2.atl03\_h5}{icesat2.atl03.Rul.h5}}.

\item[\code{beam}] Character vector indicating beams to process
(e.g. "gt1l", "gt1r", "gt2l", "gt2r", "gt3l", "gt3r").
\end{ldescription}
\end{Arguments}
%
\begin{Details}
Attributes extracted include:
\begin{itemize}

\item{} \code{lon\_ph}: Longitude of each received photon, computed from ECEF
Cartesian coordinates of the bounce point.
\item{} \code{lat\_ph}: Latitude of each received photon, computed from ECEF
Cartesian coordinates of the bounce point.
\item{} \code{h\_ph}: Height of each received photon, relative to the WGS-84
ellipsoid, including the geophysical corrections noted in the
ATL03 ATBD. (Geoid, ocean tide and DAC are \emph{not} applied.)
\item{} \code{quality\_ph}: Photon quality flag
(0 = nominal, 1 = possible\_afterpulse, 2 = possible\_impulse\_response\_effect,
3 = possible\_tep). Use together with \code{signal\_conf\_ph} to identify
likely noise vs likely signal.
\item{} \code{solar\_elevation}: Solar elevation interpolated from segment-level
\code{geolocation/solar\_elevation} to each photon.
\item{} \code{dist\_ph\_along}: Along-track distance for each photon (segment
cumulative length + \code{heights/dist\_ph\_along} when available).
\item{} \code{beam}: Beam ID (e.g. "gt2l").
\item{} \code{strong\_beam}: Logical indicating whether the beam is classified as
strong for that orbit.

\end{itemize}

\end{Details}
%
\begin{Value}
An S4 object of class \code{\LinkA{data.table::data.table}{data.table::data.table}} (with class
\code{"icesat2.atl03\_dt"} prepended) containing photon-level ATL03
attributes.
\end{Value}
%
\begin{SeeAlso}
\url{https://icesat-2.gsfc.nasa.gov/sites/default/files/page_files/ICESat2_ATL03_ATBD_r006.pdf}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}
## Not run: 
atl03_path <- system.file(
  "extdata", "atl03_clip.h5",
  package = "ICESat2VegR"
)

atl03_h5 <- ATL03_read(atl03_path)

atl03_photons_dt <- ATL03_photons_attributes_dt(atl03_h5)
head(atl03_photons_dt)

close(atl03_h5)

## End(Not run)

\end{ExampleCode}
\end{Examples}
\HeaderA{ATL03\_photons\_attributes\_dt\_clipBox}{Clip ATL03 photons by Coordinates}{ATL03.Rul.photons.Rul.attributes.Rul.dt.Rul.clipBox}
%
\begin{Description}
This function clips ATL03 photons attributes within a given bounding coordinates
\end{Description}
%
\begin{Usage}
\begin{verbatim}
ATL03_photons_attributes_dt_clipBox(
  atl03_photons_dt,
  lower_left_lon,
  upper_right_lon,
  lower_left_lat,
  upper_right_lat
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{atl03\_photons\_dt}] A atl03\_photons\_dt object (output of \code{\LinkA{ATL03\_photons\_attributes\_dt()}{ATL03.Rul.photons.Rul.attributes.Rul.dt}} function).
An S4 object of class \code{\LinkA{icesat2.atl03\_dt}{icesat2.atl03.Rul.dt.Rdash.class}}

\item[\code{lower\_left\_lon}] Numeric. West longitude (x) coordinate of bounding rectangle, in decimal degrees.

\item[\code{upper\_right\_lon}] Numeric. East longitude (x) coordinate of bounding rectangle, in decimal degrees.

\item[\code{lower\_left\_lat}] Numeric. South latitude (y) coordinate of bounding rectangle, in decimal degrees.

\item[\code{upper\_right\_lat}] Numeric. North latitude (y) coordinate of bounding rectangle, in decimal degrees.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
Returns an S4 object of class \code{\LinkA{icesat2.atl03\_dt}{icesat2.atl03.Rul.dt.Rdash.class}}
containing the ATL03 photons attributes.
\end{Value}
%
\begin{SeeAlso}
\url{https://icesat-2.gsfc.nasa.gov/sites/default/files/page_files/ICESat2_ATL03_ATBD_r006.pdf}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}
# Specifying the path to ATL03 file
atl03_path <- system.file("extdata",
  "atl03_clip.h5",
  package = "ICESat2VegR"
)

# Reading ATL03 data (h5 file)
atl03_h5 <- ATL03_read(atl03_path = atl03_path)

# Extracting ATL03 photons attributes
atl03_photons_dt <- ATL03_photons_attributes_dt(atl03_h5 = atl03_h5)

# Bounding rectangle coordinates
lower_left_lon <- -106.57
lower_left_lat <- 41.53
upper_right_lon <- -106.5698
upper_right_lat <- 41.54

# Clipping ATL08-derived canopy metrics by boundary box extent
atl03_photons_dt_clip <- ATL03_photons_attributes_dt_clipBox(
  atl03_photons_dt,
  lower_left_lon,
  upper_right_lon,
  lower_left_lat,
  upper_right_lat
)

head(atl03_photons_dt_clip)

close(atl03_h5)
\end{ExampleCode}
\end{Examples}
\HeaderA{ATL03\_photons\_attributes\_dt\_clipGeometry}{Clip ATL03 photons by Coordinates}{ATL03.Rul.photons.Rul.attributes.Rul.dt.Rul.clipGeometry}
%
\begin{Description}
This function clips ATL03 photon attributes within given bounding coordinates.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
ATL03_photons_attributes_dt_clipGeometry(
  atl03_photons_dt,
  clip_obj,
  split_by = "id"
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{atl03\_photons\_dt}] An ATL03 photon data table. An S4 object of class \code{\LinkA{icesat2.atl03\_dt}{icesat2.atl03.Rul.dt.Rdash.class}}.

\item[\code{clip\_obj}] Spatial clip\_obj. An object of class \code{\LinkA{terra::SpatVector}{terra::SpatVector}},
which can be loaded as an ESRI shapefile using the \LinkA{terra::vect}{terra::vect} function in the
\emph{sf} package.

\item[\code{split\_by}] clip\_obj id. If defined, GEDI data will be clipped by each clip\_obj using
the clip\_obj id from the attribute table defined by the user.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
Returns an S4 object of class \code{\LinkA{icesat2.atl03\_dt}{icesat2.atl03.Rul.dt.Rdash.class}}
containing the ATL03 photon attributes.
\end{Value}
%
\begin{SeeAlso}
\url{https://icesat-2.gsfc.nasa.gov/sites/default/files/page_files/ICESat2_ATL03_ATBD_r006.pdf}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}
# ATL03 file path
atl03_path <- system.file("extdata",
  "atl03_clip.h5",
  package = "ICESat2VegR"
)

# Reading ATL03 data (h5 file)
atl03_h5 <- ATL03_read(atl03_path = atl03_path)

# Extracting ATL03 photon attributes
atl03_photons_dt <- ATL03_photons_attributes_dt(atl03_h5 = atl03_h5)

# Specifying the path to shapefile
clip_obj_filepath <-
  system.file(
    "extdata",
    "clip_geom.shp",
    package = "ICESat2VegR"
  )

# Reading shapefile as sf object
clip_obj <- terra::vect(clip_obj_filepath)

# Clipping ATL03 photon attributes by Geometry
atl03_photons_dt_clip <-
  ATL03_photons_attributes_dt_clipGeometry(atl03_photons_dt, clip_obj, split_by = "id")

head(atl03_photons_dt_clip)

close(atl03_h5)
\end{ExampleCode}
\end{Examples}
\HeaderA{ATL03\_photons\_attributes\_dt\_LAS}{Converts ATL03 photon cloud to LAS}{ATL03.Rul.photons.Rul.attributes.Rul.dt.Rul.LAS}
%
\begin{Description}
Converts ATL03 photon cloud to LAS
\end{Description}
%
\begin{Usage}
\begin{verbatim}
ATL03_photons_attributes_dt_LAS(atl03_dt, output)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{atl03\_dt}] An S4 object of class \code{\LinkA{icesat2.atl03\_dt}{icesat2.atl03.Rul.dt.Rdash.class}}
(output of \code{\LinkA{ATL03\_photons\_attributes\_dt()}{ATL03.Rul.photons.Rul.attributes.Rul.dt}} function).

\item[\code{output}] character. The output path of for the LAS(Z) file(s)
The function will create one LAS file per UTM Zone in WGS84 datum.
\end{ldescription}
\end{Arguments}
%
\begin{Details}
As the las format expects a metric coordinate reference system (CRS)
we use helper functions to define UTM zones to which the original
ICESat-2 data will be converted.

The function credits go to Chuck Gantz- chuck.gantz@globalstar.com.
\end{Details}
%
\begin{Value}
Nothing, it just saves outputs as LAS file in disk
\end{Value}
%
\begin{SeeAlso}
https://oceancolor.gsfc.nasa.gov/docs/ocssw/LatLong-UTMconversion\_8cpp\_source.html
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}

# ATL03 file path
atl03_path <- system.file("extdata",
  "atl03_clip.h5",
  package = "ICESat2VegR"
)

# Reading ATL03 data (h5 file)
atl03_h5 <- ATL03_read(atl03_path = atl03_path)

# Extracting ATL03 and ATL08 photons and heights
atl03_dt <- ATL03_photons_attributes_dt(atl03_h5, beam = "gt1r")

outdir <- tempdir()
ATL03_photons_attributes_dt_LAS(
  atl03_dt,
  file.path(outdir, "output.laz")
)

close(atl03_h5)
\end{ExampleCode}
\end{Examples}
\HeaderA{ATL03\_read}{Read ICESat-2 ATL03 data}{ATL03.Rul.read}
%
\begin{Description}
This function reads the ICESat-2 Global Geolocated Photons (ATL03) Product (ATL03) as h5 file.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
ATL03_read(atl03_path)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{atl03\_path}] Either file path pointing to ICESat-2 ATL03 h5 data
or a granule resulting from \code{\LinkA{ATLAS\_dataFinder()}{ATLAS.Rul.dataFinder}} with \code{cloud\_computing = TRUE}.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
Returns an S4 object of class \code{\LinkA{icesat2.atl03\_dt}{icesat2.atl03.Rul.dt.Rdash.class}} containing ICESat-2 ATL03 data.
\end{Value}
%
\begin{SeeAlso}
\url{https://icesat-2.gsfc.nasa.gov/sites/default/files/page_files/ICESat2_ATL03_ATBD_r006.pdf}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}
# Specifying the path to ATL03 file
atl03_path <- system.file("extdata",
  "atl03_clip.h5",
  package = "ICESat2VegR"
)

# Reading ICESat-2 ATL03 data (h5 file)
ATL03 <- ATL03_read(atl03_path = atl03_path)
close(ATL03)
\end{ExampleCode}
\end{Examples}
\HeaderA{ATL03\_seg\_metadata\_dt}{ATL03 geolocation segment metadata}{ATL03.Rul.seg.Rul.metadata.Rul.dt}
%
\begin{Description}
Extract geolocation segmentâ€“level metadata from ICESat-2 ATL03 data.
Each row in the output corresponds to a single \strong{20 m geolocation segment}
along track, not to individual photons.

In addition to variables from the ATL03 \code{geolocation} group, this
function derives a segment-level reference photon height (\code{h\_ph}) using
the reference photon index and the photon-height array in the
\code{heights} group.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
ATL03_seg_metadata_dt(
  atl03_h5,
  beam = c("gt1l", "gt1r", "gt2l", "gt2r", "gt3l", "gt3r"),
  attributes = c("h_ph", "altitude_sc", "bounce_time_offset", "delta_time",
    "full_sat_fract", "near_sat_fract", "neutat_delay_derivative", "neutat_delay_total",
    "neutat_ht", "ph_index_beg", "pitch", "podppd_flag", "range_bias_corr",
    "ref_azimuth", "ref_elev", "reference_photon_index", "roll", "segment_dist_x",
    "segment_id", "segment_length", "segment_ph_cnt", "sigma_across", "sigma_along",
    "sigma_h", "sigma_lat", "sigma_lon", "solar_azimuth", "solar_elevation", "surf_type",
    "tx_pulse_energy", "tx_pulse_skew_est", 
     "tx_pulse_width_lower",
    "tx_pulse_width_upper", "yaw")
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{atl03\_h5}] An ICESat-2 ATL03 object (output of \code{\LinkA{ATL03\_read()}{ATL03.Rul.read}}),
i.e. an S4 object of class
\code{\LinkA{icesat2.atl03\_h5}{icesat2.atl03.Rul.h5}}.

\item[\code{beam}] Character vector indicating beams to process
(e.g. \code{"gt1l"}, \code{"gt1r"}, \code{"gt2l"}, \code{"gt2r"}, \code{"gt3l"}, \code{"gt3r"}).
Only beams present in \code{atl03\_h5\$beams} are used.

\item[\code{attributes}] Character vector naming the segment-level variables to extract.
By default, a broad set of geolocation and quality variables is used,
including a derived reference-photon height (\code{h\_ph}).
\end{ldescription}
\end{Arguments}
%
\begin{Details}
The following variables may be requested via \code{attributes}:
\begin{itemize}

\item{} \code{h\_ph}: Height of the \strong{reference photon} above the WGS84 ellipsoid
for each geolocation segment. This is derived from
\code{geolocation/ph\_index\_beg}, \code{geolocation/reference\_photon\_index},
and \code{heights/h\_ph}.
\item{} \code{altitude\_sc}: Height of the spacecraft above the WGS84 ellipsoid.
\item{} \code{bounce\_time\_offset}: Difference between the transmit time and the
ground-bounce time of the reference photon.
\item{} \code{delta\_time}: Transmit time of the reference photon, measured in
seconds from \code{atlas\_sdp\_gps\_epoch}.
\item{} \code{full\_sat\_fract}: Fraction of pulses within the segment that are
fully saturated.
\item{} \code{near\_sat\_fract}: Fraction of pulses within the segment that are
nearly saturated.
\item{} \code{neutat\_delay\_derivative}: Change in neutral atmospheric delay per
unit height change.
\item{} \code{neutat\_delay\_total}: Total neutral atmosphere delay correction
(wet + dry).
\item{} \code{neutat\_ht}: Reference height of the neutral atmosphere range
correction.
\item{} \code{ph\_index\_beg}: 1-based index of the first photon in this segment
within the photon-rate data.
\item{} \code{pitch}: Spacecraft pitch (degrees), 3â€“2â€“1 Euler sequence.
\item{} \code{podppd\_flag}: Composite flag describing the quality of input
geolocation products for the segment.
\item{} \code{range\_bias\_corr}: Estimated range bias from geolocation analysis.
\item{} \code{ref\_azimuth}: Azimuth (radians) of the unit pointing vector for the
reference photon in the local ENU frame.
\item{} \code{ref\_elev}: Elevation (radians) of the unit pointing vector for the
reference photon in the local ENU frame.
\item{} \code{reference\_photon\_index}: Index of the reference photon within the
photon set for a segment.
\item{} \code{reference\_photon\_lat}: Latitude of the reference photon.
\item{} \code{reference\_photon\_lon}: Longitude of the reference photon.
\item{} \code{roll}: Spacecraft roll (degrees), 3â€“2â€“1 Euler sequence.
\item{} \code{segment\_dist\_x}: Along-track distance from the equator crossing to
the start of the 20 m geolocation segment.
\item{} \code{segment\_id}: 7-digit along-track geolocation segment identifier.
\item{} \code{segment\_length}: Along-track length of the geolocation segment
(typically 20 m).
\item{} \code{segment\_ph\_cnt}: Number of photons in the segment.
\item{} \code{sigma\_across}: Estimated Cartesian across-track uncertainty
(1-sigma) for the reference photon.
\item{} \code{sigma\_along}: Estimated Cartesian along-track uncertainty (1-sigma)
for the reference photon.
\item{} \code{sigma\_h}: Estimated height uncertainty (1-sigma) for the reference
photon bounce point.
\item{} \code{sigma\_lat}: Estimated geodetic latitude uncertainty (1-sigma) for
the reference photon.
\item{} \code{sigma\_lon}: Estimated geodetic longitude uncertainty (1-sigma) for
the reference photon.
\item{} \code{solar\_azimuth}: Azimuth (degrees east) of the sun position vector
from the reference photon bounce point in the local ENU frame.
\item{} \code{solar\_elevation}: Elevation (degrees) of the sun position vector
from the reference photon bounce point in the local ENU frame.
\item{} \code{surf\_type}: Flags describing which surface types the segment is
associated with (land, ocean, sea ice, land ice, inland water).
\item{} \code{tx\_pulse\_energy}: Average transmit pulse energy per beam.
\item{} \code{tx\_pulse\_skew\_est}: Difference between the averages of the lower and
upper threshold crossing times, estimating transmit pulse skew.
\item{} \code{tx\_pulse\_width\_lower}: Average distance between lower threshold
crossing times measured by the Start Pulse Detector.
\item{} \code{tx\_pulse\_width\_upper}: Average distance between upper threshold
crossing times measured by the Start Pulse Detector.
\item{} \code{yaw}: Spacecraft yaw (degrees), 3â€“2â€“1 Euler sequence.

\end{itemize}

\end{Details}
%
\begin{Value}
A \code{\LinkA{data.table::data.table}{data.table::data.table}} with one row per ATL03 geolocation segment,
with class \code{"icesat2.atl03\_seg\_dt"} prepended. Columns include:

\begin{itemize}

\item{} \code{beam} â€“ beam ID (e.g., \code{"gt2l"}).
\item{} \code{strong\_beam} â€“ logical flag indicating whether the beam is
classified as strong for the orbit.
\item{} selected geolocation fields (see below).
\item{} a derived \code{h\_ph} column: height of the reference photon
for each segment (one value per segment).

\end{itemize}

\end{Value}
%
\begin{SeeAlso}
\url{https://icesat-2.gsfc.nasa.gov/sites/default/files/page_files/ICESat2_ATL03_ATBD_r006.pdf}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}
## Not run: 
atl03_path <- system.file(
  "extdata", "atl03_clip.h5",
  package = "ICESat2VegR"
)

atl03_h5 <- ATL03_read(atl03_path)

# Extract ATL03 geolocation segment metadata
atl03_segment_dt <- ATL03_seg_metadata_dt(atl03_h5)

head(atl03_segment_dt)
close(atl03_h5)

## End(Not run)

\end{ExampleCode}
\end{Examples}
\HeaderA{ATL08\_attributes\_dt\_LAS}{Read ICESat-2 ATL08 data}{ATL08.Rul.attributes.Rul.dt.Rul.LAS}
%
\begin{Description}
This function reads the ICESat-2 Land and
Vegetation Along-Track Products (ATL08) as h5 file.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
ATL08_attributes_dt_LAS(atl08_path)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{atl08\_path}] File path pointing to ICESat-2 ATL08 data. Data in HDF5 Hierarchical Data Format (.h5).
\end{ldescription}
\end{Arguments}
%
\begin{Value}
Returns an S4 object of class \code{\LinkA{icesat2.atl08\_dt}{icesat2.atl08.Rul.dt.Rdash.class}} containing ICESat-2 ATL08 data.
\end{Value}
%
\begin{SeeAlso}
\url{https://icesat-2.gsfc.nasa.gov/sites/default/files/page_files/ICESat2_ATL08_ATBD_r006.pdf}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}
# ATL08 file path
atl08_path <- system.file("extdata",
  "atl08_clip.h5",
  package = "ICESat2VegR"
)

# Reading ICESat-2 ATL08 data (h5 file)
atl08 <- ATL08_read(atl08_path = atl08_path)

close(atl08)
\end{ExampleCode}
\end{Examples}
\HeaderA{ATL08\_h5\_clipBox}{Clips ICESat-2 ATL08 data}{ATL08.Rul.h5.Rul.clipBox}
%
\begin{Description}
This function clips the ATl08 HDF5 file. This function
will only clip the beam groups within hdf5, it won't change metadata
or ancillary data.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
ATL08_h5_clipBox(
  atl08,
  output,
  bbox,
  beam = c("gt1r", "gt2r", "gt3r", "gt1l", "gt2l", "gt3l"),
  additional_groups = c("orbit_info")
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{atl08}] \code{\LinkA{icesat2.atl08\_h5}{icesat2.atl08.Rul.h5.Rdash.class}} object, obtained through \code{\LinkA{ATL08\_read()}{ATL08.Rul.read}}
for clipping

\item[\code{output}] character. Path to the output h5 file.

\item[\code{bbox}] \code{\LinkA{numeric}{numeric.Rdash.class}} or \code{\LinkA{terra::SpatExtent}{terra::SpatExtent}} for clipping, the
order of the bbox is the default from NASA's ICESat-2 CMS searching:
(ul\_lat, ul\_lon, lr\_lat, lr\_lon).

\item[\code{beam}] \code{\LinkA{character}{character.Rdash.class}}. The vector of beams to include, default
all c("gt1l", "gt2l", "gt3l", "gt1r", "gt2r", "gt3r")

\item[\code{additional\_groups}] \code{\LinkA{character}{character.Rdash.class}}. Other addional groups that should be included, default
c("orbit\_info")
\end{ldescription}
\end{Arguments}
%
\begin{Value}
Returns the clipped S4 object of class \code{\LinkA{icesat2.atl08\_h5}{icesat2.atl08.Rul.h5.Rdash.class}}
\end{Value}
%
\begin{Examples}
\begin{ExampleCode}
# ATL08 file path
atl08_path <- system.file("extdata",
  "atl08_clip.h5",
  package = "ICESat2VegR"
)

# Reading ATL08 data (h5 file)
atl08_h5 <- ATL08_read(atl08_path = atl08_path)

# Bounding rectangle coordinates
ul_lon <- -106.5723
lr_lon <- -106.5693
lr_lat <- 41.533
ul_lat <- 41.537

# Clipping ATL08 terrain and canopy attributes by boundary box
atl08_seg_att_dt_clip <- ATL08_h5_clipBox(
  atl08_h5,
  output = tempfile(fileext = ".h5"),
  c(ul_lat, ul_lon, lr_lat, lr_lon)
)

close(atl08_h5)
close(atl08_seg_att_dt_clip)
\end{ExampleCode}
\end{Examples}
\HeaderA{ATL08\_h5\_clipGeometry}{Clips ICESat-2 ATL08 data}{ATL08.Rul.h5.Rul.clipGeometry}
%
\begin{Description}
This function clips ATL08 HDF5 file within beam groups,
but keeps metada and ancillary data the same.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
ATL08_h5_clipGeometry(
  atl08,
  output,
  vect,
  clip_obj_id = "id",
  beam = c("gt1r", "gt2r", "gt3r", "gt1l", "gt2l", "gt3l"),
  additional_groups = c("orbit_info")
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{atl08}] \code{\LinkA{icesat2.atl08\_h5}{icesat2.atl08.Rul.h5.Rdash.class}} object, obtained through \code{\LinkA{ATL08\_read()}{ATL08.Rul.read}}
for clipping

\item[\code{output}] character. Path to the output h5 file.

\item[\code{vect}] \code{\LinkA{terra::SpatVector}{terra::SpatVector}} for clipping

\item[\code{clip\_obj\_id}] \code{\LinkA{character}{character.Rdash.class}}. The attribute name used for identifying
the different clip\_objs. Default is "id"

\item[\code{beam}] \code{\LinkA{character}{character.Rdash.class}}. The vector of beams to include, default
all c("gt1l", "gt2l", "gt3l", "gt1r", "gt2r", "gt3r")

\item[\code{additional\_groups}] \code{\LinkA{character}{character.Rdash.class}}. Other addional groups that should be included, default
c("orbit\_info")
\end{ldescription}
\end{Arguments}
%
\begin{Value}
Returns a list of clipped S4 object of class \code{\LinkA{icesat2.atl08\_h5}{icesat2.atl08.Rul.h5.Rdash.class}}
\end{Value}
%
\begin{Examples}
\begin{ExampleCode}
# ATL08 file path
atl08_path <- system.file("extdata",
  "atl08_clip.h5",
  package = "ICESat2VegR"
)

# Reading ATL08 data (h5 file)
atl08_h5 <- ATL08_read(atl08_path = atl08_path)

output <- tempfile(fileext = ".h5")

vect_path <- system.file("extdata",
  "clip_geom.shp",
  package = "ICESat2VegR"
)

vect <- terra::vect(vect_path)

# Clipping ATL08 photons by boundary box extent
atl08_photons_dt_clip <- ATL08_h5_clipGeometry(
  atl08_h5,
  output,
  vect,
  clip_obj_id = "id"
)

close(atl08_h5)
\end{ExampleCode}
\end{Examples}
\HeaderA{ATL08\_photons\_attributes\_dt}{ATL08 computed photons attributes}{ATL08.Rul.photons.Rul.attributes.Rul.dt}
%
\begin{Description}
This function extracts computed photons attributes from ICESat-2 ATL08 data
\end{Description}
%
\begin{Usage}
\begin{verbatim}
ATL08_photons_attributes_dt(
  atl08_h5,
  beam = c("gt1l", "gt1r", "gt2l", "gt2r", "gt3l", "gt3r"),
  photon_attributes = c("ph_segment_id", "classed_pc_indx", "classed_pc_flag", "ph_h",
    "d_flag", "delta_time")
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{atl08\_h5}] A ICESat-2 ATL08 object (output of \code{\LinkA{ATL08\_read()}{ATL08.Rul.read}} function).
An S4 object of class \code{\LinkA{icesat2.atl08\_dt}{icesat2.atl08.Rul.dt.Rdash.class}}.

\item[\code{beam}] Character vector indicating beams to process (e.g. "gt1l", "gt1r", "gt2l", "gt2r", "gt3l", "gt3r")

\item[\code{photon\_attributes}] \LinkA{character}{character.Rdash.class} vector indicating the attributes to extract from the ATL08 photons.
Default all \code{c("ph\_segment\_id", "classed\_pc\_indx", "classed\_pc\_flag", "ph\_h", "d\_flag", "delta\_time")}.
\end{ldescription}
\end{Arguments}
%
\begin{Details}
These are the photons attributes extracted by default:
\begin{itemize}

\item{} \strong{ph\_segment\_id}: Georeferenced bin number (20-m) associated with each photon
\item{} \strong{classed\_pc\_indx}: Indices of photons tracking back to ATL03 that surface finding
software identified and used within the creation of the data products.
\item{} \strong{classed\_pc\_flag}: The L2B algorithm is run if this flag is set to 1 indicating data have sufficient waveform fidelity for L2B to run
\item{} \strong{ph\_h}: Height of photon above interpolated ground surface
\item{} \strong{d\_flag}: Flag indicating whether DRAGANN labeled the photon as noise or signal
\item{} \strong{delta\_time}: Mid-segment GPS time in seconds past an epoch. The epoch is provided in the metadata at the file level

\end{itemize}

\end{Details}
%
\begin{Value}
Returns an S4 object of class \LinkA{data.table::data.table}{data.table::data.table}
containing the ATL08 computed photons attributes.
\end{Value}
%
\begin{SeeAlso}
\url{https://icesat-2.gsfc.nasa.gov/sites/default/files/page_files/ICESat2_ATL08_ATBD_r006.pdf}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}
# Specifying the path to ATL08 file
atl08_path <- system.file("extdata",
  "atl08_clip.h5",
  package = "ICESat2VegR"
)

# Reading ATL08 data (h5 file)
atl08_h5 <- ATL08_read(atl08_path)

# Extracting ATL08 classified photons and heights
atl08_photons <- ATL08_photons_attributes_dt(atl08_h5 = atl08_h5)

head(atl08_photons)
close(atl08_h5)
\end{ExampleCode}
\end{Examples}
\HeaderA{ATL08\_read}{Read ICESat-2 ATL08 data}{ATL08.Rul.read}
%
\begin{Description}
This function reads the ICESat-2 Land and
Vegetation Along-Track Products (ATL08) as h5 file.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
ATL08_read(atl08_path)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{atl08\_path}] File path pointing to ICESat-2 ATL08 data. Data in HDF5 Hierarchical Data Format (.h5).
\end{ldescription}
\end{Arguments}
%
\begin{Value}
Returns an S4 object of class \code{\LinkA{icesat2.atl08\_h5}{icesat2.atl08.Rul.h5.Rdash.class}} containing ICESat-2 ATL08 data.
\end{Value}
%
\begin{SeeAlso}
\url{https://icesat-2.gsfc.nasa.gov/sites/default/files/page_files/ICESat2_ATL08_ATBD_r006.pdf}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}
# Specifying the path to ATL08 file
atl08_path <- system.file("extdata",
  "atl08_clip.h5",
  package = "ICESat2VegR"
)

# Reading ICESat-2 ATL08 data (h5 file)
atl08 <- ATL08_read(atl08_path = atl08_path)
close(atl08)
\end{ExampleCode}
\end{Examples}
\HeaderA{ATL08\_seg\_attributes\_dt}{ATL08 Terrain and Canopy Attributes}{ATL08.Rul.seg.Rul.attributes.Rul.dt}
%
\begin{Description}
This function extracts terrain and canopy attributes by segments from ICESat-2 ATL08 data
\end{Description}
%
\begin{Usage}
\begin{verbatim}
ATL08_seg_attributes_dt(
  atl08_h5,
  beam = c("gt1l", "gt1r", "gt2l", "gt2r", "gt3l", "gt3r"),
  attributes = c("delta_time", "h_canopy", "canopy_openness", "h_te_mean",
    "terrain_slope")
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{atl08\_h5}] A ICESat-2 ATL08 object (output of \code{\LinkA{ATL08\_read()}{ATL08.Rul.read}} function).
An S4 object of class \code{\LinkA{icesat2.atl08\_dt}{icesat2.atl08.Rul.dt.Rdash.class}}.

\item[\code{beam}] Character vector indicating beams to process (e.g. "gt1l", "gt1r", "gt2l", "gt2r", "gt3l", "gt3r")

\item[\code{attributes}] A character vector containing the list of terrain and canopy attributes to be extracted.
Default is attribute = c("h\_canopy","canopy\_h\_metrics","canopy\_openness","h\_te\_mean","h\_te\_median","terrain\_slope")
\end{ldescription}
\end{Arguments}
%
\begin{Details}
ATL08 canopy attributes:
\begin{itemize}

\item{} \emph{"h\_canopy"}
\item{} \emph{"canopy\_rh\_conf"}
\item{} \emph{"h\_median\_canopy\_abs"}
\item{} \emph{"h\_min\_canopy"}
\item{} \emph{"h\_mean\_canopy\_abs"}
\item{} \emph{"h\_median\_canopy"}
\item{} \emph{"h\_canopy\_abs"}
\item{} \emph{"toc\_roughness"}
\item{} \emph{"h\_min\_canopy\_abs"}
\item{} \emph{"h\_dif\_canopy"}
\item{} \emph{"h\_canopy\_quad"}
\item{} \emph{"h\_canopy\_20m"}
\item{} \emph{"n\_ca\_photons"}
\item{} \emph{"photon\_rate\_can"}
\item{} \emph{"centroid\_height"}
\item{} \emph{"canopy\_h\_metrics\_abs"}
\item{} \emph{"h\_mean\_canopy"}
\item{} \emph{"subset\_can\_flag"}
\item{} \emph{"canopy\_h\_metrics"}
\item{} \emph{"n\_toc\_photons"}
\item{} \emph{"h\_max\_canopy\_abs"}
\item{} \emph{"h\_canopy\_uncertainty"}
\item{} \emph{"canopy\_openness"}
\item{} \emph{"h\_max\_canopy"}
\item{} \emph{"segment\_cover"}

\end{itemize}


ATL08 terrain attributes:
\begin{itemize}

\item{} \emph{"h\_te\_best\_fit"}
\item{} \emph{"h\_te\_best\_fit\_20m"}
\item{} \emph{"h\_te\_interp"}
\item{} \emph{"h\_te\_max"}
\item{} \emph{"h\_te\_mean"}
\item{} \emph{"h\_te\_median"}
\item{} \emph{"h\_te\_mode"}
\item{} \emph{"h\_te\_rh25"}
\item{} \emph{"h\_te\_skew"}
\item{} \emph{"h\_te\_std"}
\item{} \emph{"h\_te\_uncertainty"}
\item{} \emph{"n\_te\_photons"}
\item{} \emph{"photon\_rate\_te"}
\item{} \emph{"subset\_te\_flag"}
\item{} \emph{"terrain\_slope"}

\end{itemize}

\end{Details}
%
\begin{Value}
Returns an S4 object of class \code{\LinkA{icesat2.atl08\_dt}{icesat2.atl08.Rul.dt.Rdash.class}}
containing the ATL08-derived terrain and canopy attributes by segments.
\end{Value}
%
\begin{SeeAlso}
\url{https://icesat-2.gsfc.nasa.gov/sites/default/files/page_files/ICESat2_ATL08_ATBD_r006.pdf}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}
# Specifying the path to ATL08 file
atl08_path <- system.file("extdata",
  "atl08_clip.h5",
  package = "ICESat2VegR"
)

# Reading ATL08 data (h5 file)
atl08_h5 <- ATL08_read(atl08_path = atl08_path)

# Extracting ATL08-derived terrain and canopy attributes
atl08_seg_att_dt <- ATL08_seg_attributes_dt(atl08_h5 = atl08_h5)
head(atl08_seg_att_dt)

close(atl08_h5)
\end{ExampleCode}
\end{Examples}
\HeaderA{ATL08\_seg\_attributes\_dt\_clipBox}{Clip ATL08 Terrain and Canopy Attributes by Bounding Box}{ATL08.Rul.seg.Rul.attributes.Rul.dt.Rul.clipBox}
%
\begin{Description}
This function clips ATL08 Terrain and Canopy Attributes within a
given bounding box coordinates
\end{Description}
%
\begin{Usage}
\begin{verbatim}
ATL08_seg_attributes_dt_clipBox(
  atl08_seg_att_dt,
  lower_left_lon,
  upper_right_lon,
  lower_left_lat,
  upper_right_lat
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{atl08\_seg\_att\_dt}] A atl08\_seg\_att\_dt object (output of
\code{\LinkA{ATL08\_seg\_attributes\_dt()}{ATL08.Rul.seg.Rul.attributes.Rul.dt}} function).
An S4 object of class \code{\LinkA{icesat2.atl08\_dt}{icesat2.atl08.Rul.dt.Rdash.class}}

\item[\code{lower\_left\_lon}] Numeric. West longitude (x) coordinate of bounding rectangle,
in decimal degrees.

\item[\code{upper\_right\_lon}] Numeric. East longitude (x) coordinate of bounding rectangle,
in decimal degrees.

\item[\code{lower\_left\_lat}] Numeric. South latitude (y) coordinate of bounding rectangle,
in decimal degrees.

\item[\code{upper\_right\_lat}] Numeric. North latitude (y) coordinate of bounding rectangle,
in decimal degrees.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
Returns an S4 object of class \code{\LinkA{icesat2.atl08\_dt}{icesat2.atl08.Rul.dt.Rdash.class}}
containing the clipped ATL08 terrain and canopy attributes.
\end{Value}
%
\begin{Examples}
\begin{ExampleCode}
# Specifying the path to ATL08 file
atl08_path <- system.file("extdata",
  "atl08_clip.h5",
  package = "ICESat2VegR"
)

# Reading ATL08 data (h5 file)
atl08_h5 <- ATL08_read(atl08_path)

# Extracting ATL08-derived Canopy Metrics
atl08_seg_att_dt <- ATL08_seg_attributes_dt(atl08_h5 = atl08_h5)

# Bounding rectangle coordinates
lower_left_lon <- -103.7604
lower_left_lat <- 59.4672
upper_right_lon <- -103.7600
upper_right_lat <- 59.4680

# Clipping ATL08 terrain and canopy attributes by boundary box
atl08_seg_att_dt_clip <- ATL08_seg_attributes_dt_clipBox(
  atl08_seg_att_dt,
  lower_left_lon,
  upper_right_lon,
  lower_left_lat,
  upper_right_lat
)

close(atl08_h5)
\end{ExampleCode}
\end{Examples}
\HeaderA{ATL08\_seg\_attributes\_dt\_clipGeometry}{Clip ATL08 Terrain and Canopy Attributes by Geometry}{ATL08.Rul.seg.Rul.attributes.Rul.dt.Rul.clipGeometry}
%
\begin{Description}
This function clips ATL08 Terrain and Canopy Attributes within a given geometry
\end{Description}
%
\begin{Usage}
\begin{verbatim}
ATL08_seg_attributes_dt_clipGeometry(
  atl08_seg_att_dt,
  clip_obj,
  split_by = NULL
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{atl08\_seg\_att\_dt}] A atl08\_seg\_att\_dt object (output of
\code{\LinkA{ATL08\_seg\_attributes\_dt()}{ATL08.Rul.seg.Rul.attributes.Rul.dt}} function). An S4 object of class
\code{\LinkA{icesat2.atl08\_dt}{icesat2.atl08.Rul.dt.Rdash.class}}

\item[\code{clip\_obj}] clip\_obj. An object of class \code{\LinkA{terra::SpatVector}{terra::SpatVector}},
which can be loaded as an ESRI shapefile using \LinkA{terra::vect}{terra::vect} function in the
\emph{sf} package.

\item[\code{split\_by}] clip\_obj id. If defined, ATL08 data will be clipped by each clip\_obj using
the clip\_obj id from table of attribute defined by the user
\end{ldescription}
\end{Arguments}
%
\begin{Value}
Returns an S4 object of class \code{\LinkA{icesat2.atl08\_dt}{icesat2.atl08.Rul.dt.Rdash.class}}
containing the clipped ATL08 Terrain and Canopy Attributes.
\end{Value}
%
\begin{Examples}
\begin{ExampleCode}
# Specifying the path to ATL08 file
atl08_path <- system.file("extdata",
  "atl08_clip.h5",
  package = "ICESat2VegR"
)

# Reading ATL08 data (h5 file)
atl08_h5 <- ATL08_read(atl08_path = atl08_path)

# Extracting ATL08-derived terrain and canopy attributes
atl08_seg_att_dt <- ATL08_seg_attributes_dt(atl08_h5 = atl08_h5)

clip_obj_path <- system.file("extdata",
  "clip_geom.shp",
  package = "ICESat2VegR"
)

if (require(terra)) {
  clip_obj <- terra::vect(clip_obj_path)

  head(atl08_seg_att_dt)
  # Clipping ATL08 Terrain and Canopy Attributes by Geometry
  atl08_seg_att_dt_clip <- ATL08_seg_attributes_dt_clipGeometry(atl08_seg_att_dt, 
      clip_obj, split_by = "id")

  hasLeaflet <- require(leaflet)

  if (hasLeaflet) {
    leaflet() %>%
      addCircleMarkers(atl08_seg_att_dt_clip$longitude,
        atl08_seg_att_dt_clip$latitude,
        radius = 1,
        opacity = 1,
        color = "red"
      ) %>%
      addScaleBar(options = list(imperial = FALSE)) %>%
      addclip_objs(
        data = clip_obj, weight = 1, col = "white",
        opacity = 1, fillOpacity = 0
      ) %>%
      addProviderTiles(providers$Esri.WorldImagery,
        options = providerTileOptions(minZoom = 3, maxZoom = 17)
      )
  }
}
close(atl08_h5)
\end{ExampleCode}
\end{Examples}
\HeaderA{ATL08\_seg\_attributes\_dt\_gridStat}{Statistics of ATL08 Terrain and Canopy Attributes at grid level}{ATL08.Rul.seg.Rul.attributes.Rul.dt.Rul.gridStat}
%
\begin{Description}
This function computes a series of user defined descriptive statistics within
each grid cell for ATL08 Terrain and Canopy Attributes
\end{Description}
%
\begin{Usage}
\begin{verbatim}
ATL08_seg_attributes_dt_gridStat(atl08_seg_att_dt, func, res = 0.5)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{atl08\_seg\_att\_dt}] An S4 object of class
\code{\LinkA{icesat2.atl08\_dt}{icesat2.atl08.Rul.dt.Rdash.class}} containing ATL08 data
(output of \code{\LinkA{ATL08\_seg\_attributes\_dt()}{ATL08.Rul.seg.Rul.attributes.Rul.dt}} functions).

\item[\code{func}] The function to be applied for computing the defined statistics

\item[\code{res}] Spatial resolution in decimal degrees for the output SpatRast raster layer.
Default is 0.5.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
Return a SpatRast raster layer(s) of selected ATL08 terrain and canopy attribute(s)
\end{Value}
%
\begin{Examples}
\begin{ExampleCode}
# Specifying the path to ATL08 file
atl08_path <- system.file("extdata",
  "atl08_clip.h5",
  package = "ICESat2VegR"
)

# Reading ATL08 data (h5 file)
atl08_h5 <- ATL08_read(atl08_path = atl08_path)

# Extracting ATL08-derived terrain and canopy attributes
atl08_seg_att_dt <- ATL08_seg_attributes_dt(atl08_h5 = atl08_h5)

# Computing the top h_canopy at 0.05 degree grid cell
res <- 0.0001
mean_h_canopy <- ATL08_seg_attributes_dt_gridStat(
  atl08_seg_att_dt,
  func = mean(h_canopy),
  res = res
)

plot(mean_h_canopy)

# Define your own function
mySetOfMetrics <- function(x) {
  metrics <- list(
    min = min(x, na.rm = TRUE), # Min of x
    max = max(x, na.rm = TRUE), # Max of x
    mean = mean(x, na.rm = TRUE), # Mean of x
    sd = sd(x, na.rm = TRUE) # Sd of x
  )
  return(metrics)
}

res <- 0.05
# Computing h_canopy statistics at 0.05 degree grid cell from user-defined function
h_canopy_metrics <- ATL08_seg_attributes_dt_gridStat(
  atl08_seg_att_dt,
  func = mySetOfMetrics(h_canopy),
  res = res
)

plot(h_canopy_metrics)

close(atl08_h5)
\end{ExampleCode}
\end{Examples}
\HeaderA{ATL08\_seg\_attributes\_dt\_LAS}{Converts ATL08 segments to LAS}{ATL08.Rul.seg.Rul.attributes.Rul.dt.Rul.LAS}
%
\begin{Description}
Converts ATL08 segments to LAS
\end{Description}
%
\begin{Usage}
\begin{verbatim}
ATL08_seg_attributes_dt_LAS(atl08_dt, output)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{atl08\_dt}] An S4 object of class \code{\LinkA{icesat2.atl08\_dt}{icesat2.atl08.Rul.dt.Rdash.class}} containing ATL03 and ATL08 data
(output of \code{\LinkA{ATL03\_ATL08\_photons\_attributes\_dt\_join()}{ATL03.Rul.ATL08.Rul.photons.Rul.attributes.Rul.dt.Rul.join}} function).

\item[\code{output}] character. The output path of for the LAS(Z) file(s)
The function will create one LAS file per UTM Zone in WGS84 datum.
\end{ldescription}
\end{Arguments}
%
\begin{Details}
As the las format expects a metric coordinate reference system (CRS)
we use helper functions to define UTM zones to which the original
ICESat-2 data will be converted.

The function credits go to Chuck Gantz- chuck.gantz@globalstar.com.
\end{Details}
%
\begin{Value}
Nothing, it just saves outputs as LAS file in disk
\end{Value}
%
\begin{SeeAlso}
https://oceancolor.gsfc.nasa.gov/docs/ocssw/LatLong-UTMconversion\_8cpp\_source.html
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}
# Specifying the path to ATL08 file
atl08_path <- system.file("extdata",
  "atl08_clip.h5",
  package = "ICESat2VegR"
)

# Reading ATL08 data (h5 file)
atl08_h5 <- ATL08_read(atl08_path = atl08_path)

# # Extracting ATL03 and ATL08 photons and heights
atl08_dt <- ATL08_seg_attributes_dt(atl08_h5)

outputLaz <- tempfile(fileext = ".laz")
ATL08_seg_attributes_dt_LAS(
  atl08_dt,
  outputLaz
)

close(atl08_h5)
\end{ExampleCode}
\end{Examples}
\HeaderA{ATL08\_seg\_attributes\_dt\_polyStat}{Statistics of ATL08 Terrain and Canopy Attributes by Geometry}{ATL08.Rul.seg.Rul.attributes.Rul.dt.Rul.polyStat}
%
\begin{Description}
Computes a series of statistics of ATL08 terrain and canopy attributes within
area defined by a polygon
\end{Description}
%
\begin{Usage}
\begin{verbatim}
ATL08_seg_attributes_dt_polyStat(atl08_seg_att_dt, func, poly_id = NULL)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{atl08\_seg\_att\_dt}] An S4 object of class
\code{\LinkA{icesat2.atl08\_dt}{icesat2.atl08.Rul.dt.Rdash.class}} containing
ATL08 terrain and canopy attributes (output of
\code{\LinkA{ATL08\_seg\_attributes\_dt()}{ATL08.Rul.seg.Rul.attributes.Rul.dt}} function).

\item[\code{func}] The function to be applied for computing the defined statistics

\item[\code{poly\_id}] Polygon id. If defined, statistics will be computed for each polygon
\end{ldescription}
\end{Arguments}
%
\begin{Value}
Returns an S4 object of class \code{\LinkA{icesat2.atl08\_dt}{icesat2.atl08.Rul.dt.Rdash.class}}
Containing Statistics of ATL08 terrain and canopy attributes
\end{Value}
%
\begin{Examples}
\begin{ExampleCode}
# Specifying the path to ATL08 file
atl08_path <- system.file(
  "extdata",
  "atl08_clip.h5",
  package = "ICESat2VegR"
)

# Reading ATL08 data (h5 file)
atl08_h5 <- ATL08_read(atl08_path = atl08_path)

# Extracting ATL08 terrain and canopy attributes
atl08_seg_att_dt <- ATL08_seg_attributes_dt(atl08_h5 = atl08_h5)

# Specifying the path to shapefile
polygon_filepath <- system.file(
  "extdata",
  "clip_geom.shp",
  package = "ICESat2VegR"
)

# Reading shapefile as sf object
polygon <- terra::vect(polygon_filepath)

# Clipping ATL08 terrain and canopy attributes by Geometry
atl08_seg_att_dt_clip <- ATL08_seg_attributes_dt_clipGeometry(
  atl08_seg_att_dt,
  polygon,
  split_by = "id"
)

# Computing the max h_canopy by polygon id
max_h_canopy <- ATL08_seg_attributes_dt_polyStat(
  atl08_seg_att_dt_clip,
  func = max(h_canopy),
  poly_id = "poly_id"
)
head(max_h_canopy)

# Define your own function
mySetOfMetrics <- function(x) {
  metrics <- list(
    min = min(x), # Min of x
    max = max(x), # Max of x
    mean = mean(x), # Mean of x
    sd = sd(x) # Sd of x
  )
  return(metrics)
}

# Computing a series of canopy statistics from customized function
h_canopy_metrics <- ATL08_seg_attributes_dt_polyStat(
  atl08_seg_att_dt_clip,
  func = mySetOfMetrics(h_canopy),
  poly_id = "poly_id"
)

head(h_canopy_metrics)

close(atl08_h5)
\end{ExampleCode}
\end{Examples}
\HeaderA{ATL08\_seg\_attributes\_h5\_gridStat}{Rasterize ATL08 canopy attributes from h5 files at large scale}{ATL08.Rul.seg.Rul.attributes.Rul.h5.Rul.gridStat}
%
\begin{Description}
This function will read multiple ATL08 H5 files and create a stack of raster layers: count, and 1st, 2nd, 3rd and 4th moments (count, m1, m2, m3 and m4) for each metric selected, from which we can calculate statistics such as Mean, SD, Skewness and Kurtosis.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
ATL08_seg_attributes_h5_gridStat(
  atl08_dir,
  metrics = c("h_canopy", "canopy_rh_conf", "h_median_canopy_abs", "h_min_canopy",
    "h_mean_canopy_abs", "h_median_canopy", "h_canopy_abs", "toc_roughness",
    "h_min_canopy_abs", "h_dif_canopy", "h_canopy_quad", "h_canopy_20m", "n_ca_photons",
    "photon_rate_can", "centroid_height", "canopy_h_metrics_abs", "h_mean_canopy",
    "subset_can_flag", "canopy_h_metrics", "n_toc_photons", "h_max_canopy_abs",
    "h_canopy_uncertainty", "canopy_openness", "h_max_canopy", "segment_cover"),
  beam = c("gt1l", "gt1r", "gt2l", "gt2r", "gt3l", "gt3r"),
  out_root,
  ul_lat,
  ul_lon,
  lr_lat,
  lr_lon,
  res,
  creation_options = def_co,
  agg_function = default_agg_function,
  agg_join = default_agg_join,
  finalizer = default_finalizer
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{atl08\_dir}] CharacterVector. The directory paths where the ATL08 H5 files are stored;

\item[\code{metrics}] CharacterVector. A vector of canopy attributes available from ATL08 product (e.g. "h\_canopy")

\item[\code{beam}] Character vector indicating beams to process (e.g. "gt1l", "gt1r", "gt2l", "gt2r", "gt3l", "gt3r")

\item[\code{out\_root}] Character. The root name for the raster output files, the pattern is
\{out\_root\}\emph{\{metric\}}\{count/m1/m2\}.tif. This should include the full path for the file.

\item[\code{ul\_lat}] Numeric. Upper left latitude for the bounding box

\item[\code{ul\_lon}] Numeric. Upper left longitude for the bounding box

\item[\code{lr\_lat}] Numeric. Lower right latitude for the bounding box

\item[\code{lr\_lon}] Numeric. Lower right longitude for the bounding box

\item[\code{res}] NumericVector. Resolution lon lat for the output raster in coordinates decimal degrees

\item[\code{creation\_options}] CharacterVector. The GDAL creation options for the tif file. Default c("COMPRESS=PACKBITS", "BIGTIFF=IF\_SAFER", "TILED=YES", "BLOCKXSIZE=512", "BLOCKYSIZE=512") will create BIGTIFF if needed, with DEFLATE compression and tiled by 512x512 pixels.

\item[\code{agg\_function}] Formula function-like. An aggregate function which should return a data.table with the aggregate statistics

\item[\code{agg\_join}] Function. A function to merge two different agg objects.

\item[\code{finalizer}] List<name, formula>. A list with the final raster names and the formula which uses the base statistics.
\end{ldescription}
\end{Arguments}
%
\begin{Details}
This function will create five different aggregate statistics
(n, mean, variance, min, max).
One can calculate mean and standard deviation with the following
formulas according to Terriberry (2007) and
Joanes and Gill (1998):

The \code{agg\_function} is a formula which return a data.table with the
aggregate function to perform over the data.
The default is:

\begin{alltt}~data.table(
    n = length(x),
    mean = mean(x,na.rm = TRUE),
    var = var(x) * (length(x) - 1),
    min = min(x, na.rm=T),
    max = max(x, na.rm=T)
  )
\end{alltt}


The \code{agg\_join} is a function to merge two data.table aggregates
from the \code{agg\_function}. Since the h5 files will be aggregated
one by one, the statistics from the different h5 files should
have a function to merge them. The default function is:

\begin{alltt}function(x1, x2) \{
    combined = data.table()
    x1$n[is.na(x1$n)] = 0
    x1$mean[is.na(x1$mean)] = 0
    x1$variance[is.na(x1$variance)] = 0
    x1$max[is.na(x1$max)] = -Inf
    x1$min[is.na(x1$min)] = Inf

    combined$n = x1$n + x2$n

    delta = x2$mean - x1$mean
    delta2 = delta * delta

    combined$mean = (x1$n * x1$mean + x2$n * x2$mean) / combined$n
    combined$variance = x1$variance + x2$variance +
      delta2 * x1$n * x2$n / combined$n

    combined$min = pmin(x1$min, x2$min, na.rm=F)
    combined$max = pmax(x1$max, x2$max, na.rm=F)
    return(combined)
\}
\end{alltt}


The \code{finalizer} is a list of formulas to generate the final
rasters based on the intermediate statistics from the previous
functions. The default \code{finalizer} will calculate the \code{sd},
\code{skewness} and \code{kurtosis} based on the \code{variance}, \code{M3}, \code{M4} and \code{n}
values. It is defined as:

\begin{alltt}list(
  sd = ~sqrt(variance/(n - 1)),
)
\end{alltt}

\end{Details}
%
\begin{Value}
Nothing. It outputs multiple raster tif files to the out\_root specified path.
\end{Value}
%
\begin{References}
Joanes DN, Gill CA (1998).
``Comparing measures of sample skewness and kurtosis.''
\emph{Journal of the Royal Statistical Society: Series D (The Statistician)}, \bold{47}(1), 183--189.
\Rhref{https://doi.org/10.1111/1467-9884.00122}{doi:10.1111\slash{}1467\-9884.00122}.

Terriberry, Timothy B. (2007), Computing Higher-Order Moments Online, archived from the original on 23 April 2014, retrieved 5 May 2008
\end{References}
%
\begin{Examples}
\begin{ExampleCode}
# Specifying the path to GEDI leveatl08_canopy_dt data (zip file)
library(ICESat2VegR)
library(data.table)

# Specifying the path to ATL08 file
atl08_path <- system.file("extdata",
  "atl08_clip.h5",
  package = "ICESat2VegR"
)

# Reading ATL08 data (h5 file)
atl08_h5 <- ATL08_read(atl08_path = atl08_path)

# Bounding rectangle coordinates
ul_lat <- 41.5386848449707031
ul_lon <- -106.5708541870117188
lr_lat <- 41.5314979553222656
lr_lon <- -106.5699081420898438

res <- 100 # meters
lat_to_met_factor <- 1 / 110540
lon_to_met_factor <- 1 / 111320
xres <- lon_to_met_factor * res
yres <- lat_to_met_factor * res

agg_function <- ~ data.table(
  min = min(x),
  max = max(x),
  sum = sum(x),
  n = length(x)
)

agg_join <- function(agg1, agg2) {
  agg1[is.na(agg1)] <- 0
  data.table(
    min = pmin(agg1$min, agg2$min),
    max = pmax(agg1$max, agg2$max),
    sum = agg1$sum + agg2$sum,
    n = agg1$n + agg2$n
  )
}

finalizer <- list(
  mean = "sum/n",
  range = "max-min"
)

outdir <- tempdir()


gc()
file.remove(list.files(outdir, "*.tif"))
close(atl08_h5)

\end{ExampleCode}
\end{Examples}
\HeaderA{ATLAS\_dataDownload}{Download ICESat-2 ATL03/ATL08 data}{ATLAS.Rul.dataDownload}
%
\begin{Description}
Download ICESat-2 ATL03 and ATL08 data from the LP DAAC / NSIDC endpoints.
Handles connection drops by resuming partial files and retrying with
exponential backoff. Authentication is handled via a \code{.netrc} file:
if it does not exist, the user is prompted for Earthdata Login credentials.
If authentication fails (e.g., wrong username/password), the user is
informed and can choose to re-enter credentials or cancel.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
ATLAS_dataDownload(
  url,
  outdir = NULL,
  overwrite = FALSE,
  buffer_size = 512,
  timeout = 10,
  retries = 3,
  backoff = 2,
  quiet = FALSE,
  use_home_netrc = TRUE
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{url}] Character vector; URLs to ATL03/ATL08 files
(e.g., returned by \code{ATLAS\_dataFinder()}).

\item[\code{outdir}] Character; output directory (default: \code{\LinkA{tempdir()}{tempdir}}).

\item[\code{overwrite}] Logical; overwrite existing files? Default \code{FALSE}.

\item[\code{buffer\_size}] Integer; chunk size in KB per \code{readBin} call
(default 512).

\item[\code{timeout}] Numeric; connection timeout (seconds) for establishing
the connection (default 10).

\item[\code{retries}] Integer; maximum attempts per file (default 3).

\item[\code{backoff}] Numeric; exponential backoff base used as
\code{sleep = backoff\textasciicircum{}(attempt - 1)} (default 2).

\item[\code{quiet}] Logical; suppress per-file messages (default \code{FALSE}).

\item[\code{use\_home\_netrc}] Logical; if \code{TRUE} (default), use a single
\file{\textasciitilde{}/.netrc} file in the user's home directory for Earthdata
credentials so they can be reused across projects. If \code{FALSE},
a \file{.netrc} file is created in \code{outdir}.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
(invisibly) a \code{data.frame} with columns:
\begin{itemize}

\item{} \code{file}: file name
\item{} \code{dest}: full destination path
\item{} \code{status}: one of \code{"ok"}, \code{"failed"}, \code{"skipped"}
\item{} \code{attempts}: number of attempts used
\item{} \code{error}: error message (if any)

\end{itemize}

\end{Value}
%
\begin{References}
Credits to Cole Krehbiel. Code adapted from:
\url{https://git.earthdata.nasa.gov/projects/LPDUR/repos/daac_data_download_r/browse/DAACDataDownload.R}
\end{References}
%
\begin{Examples}
\begin{ExampleCode}
## Not run: 
urls <- c(
  "https://example.com/path/to/ATL03_001.h5",
  "https://example.com/path/to/ATL08_001.h5"
)
status <- ATLAS_dataDownload(urls,
                             outdir        = "data",
                             retries       = 5,
                             backoff       = 2,
                             use_home_netrc = TRUE)
subset(status, status == "failed")

## End(Not run)

\end{ExampleCode}
\end{Examples}
\HeaderA{ATLAS\_dataFinder}{ICESat-2 ATL03 and ATL08 data finder for either direct download or cloud computing}{ATLAS.Rul.dataFinder}
%
\begin{Description}
This function finds the exact granule(s) that contain ICESat-2 ATLAS data
for a given region of interest and date range
\end{Description}
%
\begin{Usage}
\begin{verbatim}
ATLAS_dataFinder(
  short_name,
  lower_left_lon,
  lower_left_lat,
  upper_right_lon,
  upper_right_lat,
  version = "006",
  daterange = NULL,
  persist = TRUE,
  cloud_hosted = TRUE,
  cloud_computing = FALSE
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{short\_name}] ICESat-2 ATLAS data level short\_name; Options: "ATL03", "ATL08",

\item[\code{lower\_left\_lon}] Numeric. Minimum longitude in
(decimal degrees) for the bounding box of the area of interest.

\item[\code{lower\_left\_lat}] Numeric. Minimum latitude in
(decimal degrees) for the bounding box of the area of interest.

\item[\code{upper\_right\_lon}] Numeric. Maximum longitude in lon
(decimal degrees) for the bounding box of the area of interest.

\item[\code{upper\_right\_lat}] Numeric. Maximum latitude in
(decimal degrees) for the bounding box of the area of interest.

\item[\code{version}] Character. The version of the ICESat-2 ATLAS product files to be
returned (only V005 or V006). Default "006".

\item[\code{daterange}] Vector. Date range. Specify your start and end dates
using ISO 8601 [YYYY]-[MM]-[DD]T[hh]:[mm]:[ss]Z. Ex.:
c("2019-07-01T00:00:00Z","2020-05-22T23:59:59Z"). If NULL (default),
the date range filter will be not applied.

\item[\code{persist}] Logical. If TRUE, it will create the .netrc

\item[\code{cloud\_hosted}] Logical. Flag to indicate use of cloud hosted collections.To be used when the cloud computing
parameter is FALSE.

\item[\code{cloud\_computing}] Logical. If TRUE, it will return granules for cloud computing directly, otherwise
it will return links to be passed in the function \LinkA{ATLAS\_dataDownload}{ATLAS.Rul.dataDownload} for data download.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
Return either a vector object pointing out the path to
ICESat-2 ATLAS data found within the boundary box coordinates provided for data download or a vector
object containing the granules hosted on the cloud for cloud computing directly.
\end{Value}
%
\begin{SeeAlso}
bbox: Defined by the upper left and lower right corner coordinates,
in lat,lon ordering, for the bounding box of the area of interest
(e.g. lower\_left\_lon,lower\_left\_lat,upper\_right\_lon,upper\_right\_lat)

This function relies on the existing CMR tool:
\url{https://cmr.earthdata.nasa.gov/search/site/docs/search/api.html}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}
# ICESat-2 data finder is a web service provided by NASA
# usually the request takes more than 5 seconds

# Specifying bounding box coordinates
lower_left_lon <- -96.0
lower_left_lat <- 40.0
upper_right_lon <- -96.5
upper_right_lat <- 40.5

# Specifying the date range
daterange <- c("2022-05-01", "2022-05-02")

# Extracting the path to ICESat-2 ATLAS data for the specified boundary box coordinates
# for data download

# Shouldn't be tested because it relies on a web service which might be down

ATLAS02b_list <- ATLAS_dataFinder(
  short_name = "ATL08",
  lower_left_lon,
  lower_left_lat,
  upper_right_lon,
  upper_right_lat,
  version = "006",
  daterange = daterange
)

\end{ExampleCode}
\end{Examples}
\HeaderA{clip}{Clip ICESat-2 data (h5, attributes, or ATL03â€“ATL08 join) by box or geometry}{clip}
\aliasA{clip,icesat2.atl03atl08\_dt,ANY-method}{clip}{clip,icesat2.atl03atl08.Rul.dt,ANY.Rdash.method}
\aliasA{clip,icesat2.atl03atl08\_dt,numeric-method}{clip}{clip,icesat2.atl03atl08.Rul.dt,numeric.Rdash.method}
\aliasA{clip,icesat2.atl03\_dt,ANY-method}{clip}{clip,icesat2.atl03.Rul.dt,ANY.Rdash.method}
\aliasA{clip,icesat2.atl03\_dt,numeric-method}{clip}{clip,icesat2.atl03.Rul.dt,numeric.Rdash.method}
\aliasA{clip,icesat2.atl03\_h5,ANY-method}{clip}{clip,icesat2.atl03.Rul.h5,ANY.Rdash.method}
\aliasA{clip,icesat2.atl03\_h5,numeric-method}{clip}{clip,icesat2.atl03.Rul.h5,numeric.Rdash.method}
\aliasA{clip,icesat2.atl08\_dt,ANY-method}{clip}{clip,icesat2.atl08.Rul.dt,ANY.Rdash.method}
\aliasA{clip,icesat2.atl08\_dt,numeric-method}{clip}{clip,icesat2.atl08.Rul.dt,numeric.Rdash.method}
\aliasA{clip,icesat2.atl08\_h5,ANY-method}{clip}{clip,icesat2.atl08.Rul.h5,ANY.Rdash.method}
\aliasA{clip,icesat2.atl08\_h5,numeric-method}{clip}{clip,icesat2.atl08.Rul.h5,numeric.Rdash.method}
%
\begin{Description}
Unified clipping interface for ICESat-2 ATL03/ATL08 data. The generic
\code{clip()} dispatches on the class of \code{x} and internally calls the
appropriate helper:

\begin{itemize}

\item{} \code{\LinkA{ATL03\_h5\_clipBox}{ATL03.Rul.h5.Rul.clipBox}}, \code{\LinkA{ATL03\_h5\_clipGeometry}{ATL03.Rul.h5.Rul.clipGeometry}}
\item{} \code{\LinkA{ATL03\_photon\_attributes\_dt\_clipBox}{ATL03.Rul.photon.Rul.attributes.Rul.dt.Rul.clipBox}},
\code{\LinkA{ATL03\_photon\_attributes\_dt\_clipGeometry}{ATL03.Rul.photon.Rul.attributes.Rul.dt.Rul.clipGeometry}}
\item{} \code{\LinkA{ATL08\_h5\_clipBox}{ATL08.Rul.h5.Rul.clipBox}}, \code{\LinkA{ATL08\_h5\_clipGeometry}{ATL08.Rul.h5.Rul.clipGeometry}}
\item{} \code{\LinkA{ATL08\_seg\_attributes\_dt\_clipBox}{ATL08.Rul.seg.Rul.attributes.Rul.dt.Rul.clipBox}},
\code{\LinkA{ATL08\_seg\_attributes\_dt\_clipGeometry}{ATL08.Rul.seg.Rul.attributes.Rul.dt.Rul.clipGeometry}}
\item{} \code{\LinkA{ATL03\_ATL08\_photons\_attributes\_dt\_join\_clipBox}{ATL03.Rul.ATL08.Rul.photons.Rul.attributes.Rul.dt.Rul.join.Rul.clipBox}},
\code{\LinkA{ATL03\_ATL08\_photons\_attributes\_dt\_join\_clipGeometry}{ATL03.Rul.ATL08.Rul.photons.Rul.attributes.Rul.dt.Rul.join.Rul.clipGeometry}}

\end{itemize}

\end{Description}
%
\begin{Usage}
\begin{verbatim}
clip(x, clip_obj, ...)

## S4 method for signature 'icesat2.atl03_h5,numeric'
clip(x, clip_obj, ...)

## S4 method for signature 'icesat2.atl03_h5,ANY'
clip(x, clip_obj, ...)

## S4 method for signature 'icesat2.atl08_h5,numeric'
clip(x, clip_obj, ...)

## S4 method for signature 'icesat2.atl08_h5,ANY'
clip(x, clip_obj, ...)

## S4 method for signature 'icesat2.atl03_dt,numeric'
clip(x, clip_obj, ...)

## S4 method for signature 'icesat2.atl03_dt,ANY'
clip(x, clip_obj, ...)

## S4 method for signature 'icesat2.atl08_dt,numeric'
clip(x, clip_obj, ...)

## S4 method for signature 'icesat2.atl08_dt,ANY'
clip(x, clip_obj, ...)

## S4 method for signature 'icesat2.atl03atl08_dt,numeric'
clip(x, clip_obj, ...)

## S4 method for signature 'icesat2.atl03atl08_dt,ANY'
clip(x, clip_obj, ...)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] An ICESat-2 object to be clipped. Supported classes:
\begin{itemize}

\item{} \code{"icesat2.atl03\_h5"} â€” ATL03 HDF5 handle.
\item{} \code{"icesat2.atl08\_h5"} â€” ATL08 HDF5 handle.
\item{} \code{"icesat2.atl03\_seg\_dt"} â€” ATL03 photon/segment attributes.
\item{} \code{"icesat2.atl08\_dt"} â€” ATL08 segment attributes.
\item{} \code{"icesat2.atl03\_atl08\_join\_spec"} â€” specification bundling
ATL03 + ATL08 attributes for join+clip operations.

\end{itemize}


\item[\code{clip\_obj}] A clipping object:
\begin{itemize}

\item{} Numeric bounding box (e.g., \code{c(xmin, xmax, ymin, ymax)}).
\item{} \code{terra::SpatExtent}, \code{terra::SpatVector}, \pkg{sf}
geometry, or similar.

\end{itemize}

Bounding boxes are usually routed to \code{*\_clipBox()} helpers, and
geometries to \code{*\_clipGeometry()} helpers.

\item[\code{...}] Additional arguments passed down to the underlying helper
functions.
\end{ldescription}
\end{Arguments}
%
\begin{Section}{Methods (by class)}
\begin{itemize}

\item{} \code{clip(x = icesat2.atl03\_h5, clip\_obj = numeric)}: Clip ATL03 HDF5 by bounding box (delegates to ATL03\_h5\_clipBox()).

\item{} \code{clip(x = icesat2.atl03\_h5, clip\_obj = ANY)}: Clip ATL03 HDF5 by geometry (delegates to ATL03\_h5\_clipGeometry()).

\item{} \code{clip(x = icesat2.atl08\_h5, clip\_obj = numeric)}: Clip ATL08 HDF5 by bounding box (delegates to ATL08\_h5\_clipBox()).

\item{} \code{clip(x = icesat2.atl08\_h5, clip\_obj = ANY)}: Clip ATL08 HDF5 by geometry (delegates to ATL08\_h5\_clipGeometry()).

\item{} \code{clip(x = icesat2.atl03\_dt, clip\_obj = numeric)}: Clip ATL03 photon attributes by bounding box
(delegates to ATL03\_photon\_attributes\_dt\_clipBox()).

\item{} \code{clip(x = icesat2.atl03\_dt, clip\_obj = ANY)}: Clip ATL03 photon attributes by geometry
(delegates to ATL03\_photon\_attributes\_dt\_clipGeometry()).

\item{} \code{clip(x = icesat2.atl08\_dt, clip\_obj = numeric)}: Clip ATL08 segment attributes by bounding box
(delegates to ATL08\_seg\_attributes\_dt\_clipBox()).

\item{} \code{clip(x = icesat2.atl08\_dt, clip\_obj = ANY)}: Clip ATL08 segment attributes by geometry
(delegates to ATL08\_seg\_attributes\_dt\_clipGeometry()).

\item{} \code{clip(x = icesat2.atl03atl08\_dt, clip\_obj = numeric)}: Join ATL03 photons and ATL08 segments, then clip by bounding box.

This method delegates to
\code{\LinkA{ATL03\_ATL08\_photons\_attributes\_dt\_join\_clipBox}{ATL03.Rul.ATL08.Rul.photons.Rul.attributes.Rul.dt.Rul.join.Rul.clipBox}()}.

\item{} \code{clip(x = icesat2.atl03atl08\_dt, clip\_obj = ANY)}: Join ATL03 photons and ATL08 segments, then clip by geometry.

This method delegates to
\code{\LinkA{ATL03\_ATL08\_photons\_attributes\_dt\_join\_clipGeometry}{ATL03.Rul.ATL08.Rul.photons.Rul.attributes.Rul.dt.Rul.join.Rul.clipGeometry}()}.


\end{itemize}
\end{Section}
%
\begin{Section}{Related clipping helpers}

\begin{enumerate}

\item{} \code{\LinkA{ATL03\_h5\_clipBox}{ATL03.Rul.h5.Rul.clipBox}}
\item{} \code{\LinkA{ATL03\_h5\_clipGeometry}{ATL03.Rul.h5.Rul.clipGeometry}}
\item{} \code{\LinkA{ATL03\_photon\_attributes\_dt\_clipBox}{ATL03.Rul.photon.Rul.attributes.Rul.dt.Rul.clipBox}}
\item{} \code{\LinkA{ATL03\_photon\_attributes\_dt\_clipGeometry}{ATL03.Rul.photon.Rul.attributes.Rul.dt.Rul.clipGeometry}}
\item{} \code{\LinkA{ATL08\_h5\_clipBox}{ATL08.Rul.h5.Rul.clipBox}}
\item{} \code{\LinkA{ATL08\_h5\_clipGeometry}{ATL08.Rul.h5.Rul.clipGeometry}}
\item{} \code{\LinkA{ATL08\_seg\_attributes\_dt\_clipBox}{ATL08.Rul.seg.Rul.attributes.Rul.dt.Rul.clipBox}}
\item{} \code{\LinkA{ATL08\_seg\_attributes\_dt\_clipGeometry}{ATL08.Rul.seg.Rul.attributes.Rul.dt.Rul.clipGeometry}}
\item{} \code{\LinkA{ATL03\_ATL08\_photons\_attributes\_dt\_join\_clipBox}{ATL03.Rul.ATL08.Rul.photons.Rul.attributes.Rul.dt.Rul.join.Rul.clipBox}}
\item{} \code{\LinkA{ATL03\_ATL08\_photons\_attributes\_dt\_join\_clipGeometry}{ATL03.Rul.ATL08.Rul.photons.Rul.attributes.Rul.dt.Rul.join.Rul.clipGeometry}}

\end{enumerate}

\end{Section}
%
\begin{SeeAlso}
\code{\LinkA{ATL03\_h5\_clipBox}{ATL03.Rul.h5.Rul.clipBox}},
\code{\LinkA{ATL03\_h5\_clipGeometry}{ATL03.Rul.h5.Rul.clipGeometry}},
\code{\LinkA{ATL03\_photon\_attributes\_dt\_clipBox}{ATL03.Rul.photon.Rul.attributes.Rul.dt.Rul.clipBox}},
\code{\LinkA{ATL03\_photon\_attributes\_dt\_clipGeometry}{ATL03.Rul.photon.Rul.attributes.Rul.dt.Rul.clipGeometry}},
\code{\LinkA{ATL08\_h5\_clipBox}{ATL08.Rul.h5.Rul.clipBox}},
\code{\LinkA{ATL08\_h5\_clipGeometry}{ATL08.Rul.h5.Rul.clipGeometry}},
\code{\LinkA{ATL08\_seg\_attributes\_dt\_clipBox}{ATL08.Rul.seg.Rul.attributes.Rul.dt.Rul.clipBox}},
\code{\LinkA{ATL08\_seg\_attributes\_dt\_clipGeometry}{ATL08.Rul.seg.Rul.attributes.Rul.dt.Rul.clipGeometry}},
\code{\LinkA{ATL03\_ATL08\_photons\_attributes\_dt\_join\_clipBox}{ATL03.Rul.ATL08.Rul.photons.Rul.attributes.Rul.dt.Rul.join.Rul.clipBox}},
\code{\LinkA{ATL03\_ATL08\_photons\_attributes\_dt\_join\_clipGeometry}{ATL03.Rul.ATL08.Rul.photons.Rul.attributes.Rul.dt.Rul.join.Rul.clipGeometry}}
\end{SeeAlso}
\HeaderA{ee\_build\_AlphaEarth\_embedding\_terrain\_stack}{Stack Alpha Earth embedding and terrain ancillary layers}{ee.Rul.build.Rul.AlphaEarth.Rul.embedding.Rul.terrain.Rul.stack}
%
\begin{Description}
Creates a Google Earth Engine image stack that combines:

\begin{itemize}

\item{} Annual satellite embeddings from
\code{"GOOGLE/SATELLITE\_EMBEDDING/V1/ANNUAL"} (AlphaEarth).
\item{} Terrain derivatives (elevation, slope, aspect) from USGS 3DEP or
NASADEM as fallbacks.
\item{} Optional longitude/latitude bands from \code{ee\$Image\$pixelLonLat()}.

\end{itemize}


The embedding collection is filtered to the specified year range and AOI,
reduced using a pixel-wise median, and clipped to the AOI. Terrain data are
reprojected to a target scale (default \code{30} m).
\end{Description}
%
\begin{Usage}
\begin{verbatim}
ee_build_AlphaEarth_embedding_terrain_stack(
  geom,
  start_year,
  end_year,
  mask_outside = TRUE,
  terrain_scale = 30,
  multiply_slope_aspect_by10 = TRUE,
  add_lonlat = TRUE
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{geom}] AOI geometry. Can be:
\begin{itemize}

\item{} an \pkg{sf} object (\code{sf} or \code{sfc}),
\item{} a \code{terra::SpatVector},
\item{} or an Earth Engine geometry (Python object) already in geographic
coordinates.

\end{itemize}

The geometry is internally converted to an Earth Engine geometry via an
internal helper.

\item[\code{start\_year}, \code{end\_year}] Integer (or coercible to integer). Inclusive year
range used to filter the AlphaEarth annual embedding collection.

\item[\code{mask\_outside}] Logical. If \code{TRUE} (default), pixels outside the
AOI are masked out using a binary mask image clipped to \code{geom}.

\item[\code{terrain\_scale}] Numeric. Target scale (in meters) used to reproject
the terrain data (default \code{30}).

\item[\code{multiply\_slope\_aspect\_by10}] Logical. If \code{TRUE} (default), slope
and aspect are multiplied by 10 to preserve conventions used elsewhere in
the package and avoid small floating-point values.

\item[\code{add\_lonlat}] Logical. If \code{TRUE} (default), add longitude and
latitude bands named \code{"lon"} and \code{"lat"} derived from
\code{ee\$Image\$pixelLonLat()}.
\end{ldescription}
\end{Arguments}
%
\begin{Details}
The terrain source is chosen in the following order:

\begin{enumerate}

\item{} USGS 3DEP 1 m (\code{"USGS/3DEP/1m"}), if available for the AOI.
\item{} USGS 3DEP 10 m (\code{"USGS/3DEP/10m"}).
\item{} NASADEM (\code{"NASA/NASADEM\_HGT/001"}) as a global fallback.

\end{enumerate}


All terrain layers are clipped to the AOI and reprojected to
\code{"EPSG:4326"} with the requested \code{terrain\_scale}.
\end{Details}
%
\begin{Value}
A Python \code{ee\$Image} object that contains:
\begin{itemize}

\item{} The median annual embedding bands.
\item{} \code{"elevation"}, \code{"slope"}, and \code{"aspect"} bands.
\item{} Optional \code{"lon"} and \code{"lat"} bands.

\end{itemize}

\end{Value}
%
\begin{Examples}
\begin{ExampleCode}
## Not run: 
  library(sf)

  # -------------------------------------------------------------
  # Example 1 - Using the function
  # -------------------------------------------------------------

  # Simple AOI polygon (WGS84)
  aoi <- st_as_sfc(st_bbox(c(
    xmin = -82.4, xmax = -82.2,
    ymin =  29.6, ymax =  29.8
  ), crs = 4326))

  img <- ee_build_AlphaEarth_embedding_terrain_stack(
    geom       = aoi,
    start_year = 2018,
    end_year   = 2020
  )


  # -------------------------------------------------------------
  # Example 2 - Full standalone script (no function)
  # -------------------------------------------------------------

  library(reticulate)
  ee <- import("ee")
  ICESat2VegR:::.ee_ping(ee)

  # AOI geometry (sf â†’ EE geometry)
  library(sf)
  aoi <- st_as_sfc(
    st_bbox(c(
      xmin = -82.4,
      xmax = -82.2,
      ymin = 29.6,
      ymax = 29.8
    ), crs = 4326)
  )

  ee_geom <- ICESat2VegR:::.as_ee_geom(aoi)

  # -------------------------------------------------------------
  # AlphaEarth annual embedding
  # -------------------------------------------------------------
  start_year <- 2018
  end_year   <- 2020

  emb_ic <- ee$ImageCollection("GOOGLE/SATELLITE_EMBEDDING/V1/ANNUAL")$
    filterDate(
      sprintf("%04d-01-01", start_year),
      sprintf("%04d-12-31", end_year)
    )$
    filterBounds(ee_geom)

  embedding <- emb_ic$median()$clip(ee_geom)


  # -------------------------------------------------------------
  # Terrain DEM via ICESat2VegR dataset search (NASA DEM)
  # -------------------------------------------------------------
  dem_search   <- search_datasets("nasa", "dem")
  dem_id       <- get_catalog_id(dem_search)
  elevation    <- ee$Image(dem_id)$clip(ee_geom)

  # Compute slope and aspect using package helpers
  terrain_scale <- 30

  # Reproject elevation to target scale (if desired)
  elev_proj <- elevation$reproject("EPSG:4326", scale = terrain_scale)

  slp <- slope(elev_proj)    # returns ee.Image with band "slope"
  asp <- aspect(elev_proj)   # returns ee.Image with band "aspect"

  # Optional scaling by 10
  slp <- slp$multiply(10)
  asp <- asp$multiply(10)

  slp <- slp$clip(ee_geom)
  asp <- asp$clip(ee_geom)


  # -------------------------------------------------------------
  # Lon/lat bands
  # -------------------------------------------------------------
  lonlat <- ee$Image$pixelLonLat()$clip(ee_geom)
  lon    <- lonlat$select("longitude")$rename("lon")
  lat    <- lonlat$select("latitude")$rename("lat")


  # -------------------------------------------------------------
  # Final stack: embeddings + terrain + lon/lat
  # -------------------------------------------------------------
  stack <- embedding$
    addBands(elevation$rename("elevation"))$
    addBands(slp)$
    addBands(asp)$
    addBands(lon)$
    addBands(lat)

  # Optional mask outside AOI
  mask  <- ee$Image$constant(1)$clip(ee_geom)
  stack <- stack$updateMask(mask)

  print(stack)

## End(Not run)

\end{ExampleCode}
\end{Examples}
\HeaderA{ee\_build\_hls\_s1c\_terrain\_stack}{Build HLS, Sentinel-1C and terrain ancillary stack in Earth Engine}{ee.Rul.build.Rul.hls.Rul.s1c.Rul.terrain.Rul.stack}
%
\begin{Description}
Constructs a multi-source ancillary stack in Earth Engine composed of:
(1) optical features from the Harmonized Landsat and Sentinel-2 (HLS) product,
including several vegetation indices and spectral unmixing fractions;
(2) C-band SAR backscatter and radar-based indices from Sentinel-1C GRD; and
(3) terrain variables (elevation, slope, aspect) from a DEM.

The user must provide a temporal window via \code{start\_date} and \code{end\_date}.
The HLS image collection is filtered to this period and mosaicked using
\code{median()}. Sentinel-1C is filtered to the same period and reduced using
\code{ee\$Reducer\$firstNonNull()}, following the original workflow. The final
stack includes neighborhood statistics and GLCM texture features.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
ee_build_hls_s1c_terrain_stack(
  x,
  start_date,
  end_date,
  cloud_max = 10,
  buffer_m = 30
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] Spatial input defining the area of interest. Can be:
\begin{itemize}

\item{} a character path to a vector file readable by \code{\LinkA{terra::vect()}{terra::vect()}} (e.g., SHP, GPKG),
\item{} a \LinkA{terra::SpatVector}{terra::SpatVector},
\item{} a \LinkA{terra::SpatRaster}{terra::SpatRaster} (its extent will be used),
\item{} an \LinkA{sf::sf}{sf::sf} or \LinkA{sf::sfc}{sf::sfc} object,
\item{} a \LinkA{terra::SpatExtent}{terra::SpatExtent} object (e.g., from \code{\LinkA{terra::ext()}{terra::ext()}}),
\item{} a numeric vector of length 4 giving an extent as
\code{c(xmin, xmax, ymin, ymax)}.

\end{itemize}


\item[\code{start\_date}] Character. Start date of the temporal filter
(\code{"YYYY-MM-DD"}). \strong{Required.}

\item[\code{end\_date}] Character. End date of the temporal filter
(\code{"YYYY-MM-DD"}). \strong{Required.}

\item[\code{cloud\_max}] Numeric. Maximum allowed cloud coverage percentage for HLS
scenes (used in the \code{"CLOUD\_COVERAGE < cloud\_max"} filter). Default is 10.

\item[\code{buffer\_m}] Numeric. Buffer distance in meters applied to the AOI
bounding box before filtering and clipping. Default is 30.
\end{ldescription}
\end{Arguments}
%
\begin{Details}
This function assumes that:
\begin{itemize}

\item{} Earth Engine access is provided via the \pkg{ICESat2VegR} internal
\code{ee} handle.
\item{} Dataset search and catalog ID retrieval are performed by
\code{\LinkA{search\_datasets()}{search.Rul.datasets}} and \code{\LinkA{get\_catalog\_id()}{get.Rul.catalog.Rul.id}} from \pkg{ICESat2VegR}.

\end{itemize}


The HLS component follows the original workflow: the collection is filtered
by AOI and date, filtered by cloud coverage, cloud and water masks are
applied, and a \code{median()} mosaic is computed. Reflectance bands are renamed
(blue, green, red, nir, swir1, swir2) and a set of vegetation indices and
linear spectral unmixing fractions are added.

Sentinel-1C (COPERNICUS/S1\_GRD) is filtered by AOI, date, polarization
(VV/VH), and instrument mode ("IW"), sorted by time, and reduced using
\code{ee\$Reducer\$firstNonNull()}. VV and VH are scaled, and RVI and
co-polarization indices are derived.

A DEM is retrieved from the NASA catalog via \code{\LinkA{search\_datasets()}{search.Rul.datasets}} and
\code{\LinkA{get\_catalog\_id()}{get.Rul.catalog.Rul.id}}, and slope and aspect are derived following the original
code pattern. Neighborhood statistics (mean, min, max, stdDev) are computed
for the HLS and DEM components using a fixed 3Ã—3 kernel, and GLCM texture
metrics are computed from scaled HLS reflectance bands.

\#' @examples
## Not run: 
\# ================================================================
\# Example 1 â€” Using the function
\# ================================================================
res <- ee\_build\_hls\_s1c\_terrain\_stack(
  x          = system.file("extdata", "all\_boundary.shp", package = "ICESat2VegR"),
  start\_date = "2019-04-01",
  end\_date   = "2019-05-31"
)

full\_stack <- res\$stack


\# ================================================================
\# Example 2 â€” FULL SCRIPT (no function)
\# Users may copy/paste and modify as needed
\# ================================================================

library(ICESat2VegR)
library(terra)

\# AOI
geom <- terra::vect(system.file("extdata", "all\_boundary.shp", package="ICESat2VegR"))
bbox <- terra::ext(geom)

aoi <- ee\$Geometry\$BBox(
  west  = bbox\$xmin,
  south = bbox\$ymin,
  east  = bbox\$xmax,
  north = bbox\$ymax
)\$buffer(30)

\# ---------------------------------------------------------------
\# HLS
\# ---------------------------------------------------------------
search <- search\_datasets("hls")
id     <- get\_catalog\_id(search)

cloudMask <- 2\textasciicircum{}1 + 2\textasciicircum{}2 + 2\textasciicircum{}3

hlsMask <- function(image) image\$updateMask(!(image[["Fmask"]] \& cloudMask))
waterMask <- function(image) image\$updateMask(image[["B5"]] >= 0.2)

hls <- ee\$ImageCollection(id)\$
  filterBounds(aoi)\$
  filterDate("2019-04-01", "2019-05-31")\$
  filter("CLOUD\_COVERAGE < 10")\$
  map(hlsMask)\$
  map(waterMask)\$
  median()\$
  clip(aoi)

hls <- hls[["B2","B3","B4","B5","B6","B7"]]
names(hls) <- c("blue","green","red","nir","swir1","swir2")

\# Vegetation indices
nir     <- hls[["nir"]]
red     <- hls[["red"]]
blue    <- hls[["blue"]]
green   <- hls[["green"]]
swir1   <- hls[["swir1"]]
swir2   <- hls[["swir2"]]
nir\_red <- nir - red

hls[["ndvi"]] <- (nir - red) / (nir + red)

sigma <- 1
knr <- exp((nir\_red)\textasciicircum{}2 / (2*sigma\textasciicircum{}2))
hls[["kndvi"]] <- (1 - knr) / (1 + knr)

hls[["evi"]]  <- 2.5 * nir\_red / (nir + 6*red - 7.5*blue + 1)
hls[["savi"]] <- 1.5 * nir\_red / (nir + red + 0.5)

p1 <- 2*nir + 1
hls[["msavi"]] <- p1 - sqrt(p1\textasciicircum{}2 - 8*nir\_red)/2

\# Spectral unmixing
soil  <- c(0.14, 0.16, 0.22, 0.39, 0.45, 0.27)
veg   <- c(0.086,0.062,0.043,0.247,0.109,0.039)
water <- c(0.07,0.039,0.023,0.031,0.011,0.007)

img <- hls[[c("blue","green","red","nir","swir1","swir2")]]
unmixing <- img\$unmix(list(soil,veg,water))
names(unmixing) <- c("f\_soil","f\_veg","f\_water")

hls <- c(hls, unmixing)

\# More indices
hls[["sri"]]  <- nir / red
hls[["ndwi"]] <- (green - nir)/(green + nir)
hls[["gci"]]  <- nir/green - 1
hls[["wdrvi"]] <- ((0.1*nir) - red)/((0.1*nir) + red)
hls[["gvmi"]]  <- ((nir+0.1)-(swir1+0.02))/((nir+0.1)+(swir1+0.02))
hls[["cvi"]]   <- nir * (red/(green\textasciicircum{}2))
hls[["cmr"]]   <- swir1/swir2


\# ---------------------------------------------------------------
\# DEM (NASA)
\# ---------------------------------------------------------------
dem\_search <- search\_datasets("nasa","dem")
dem\_id     <- get\_catalog\_id(dem\_search)

elevation <- ee\$Image(dem\_id)
the\_slope  <- as.integer(slope(as.integer(elevation)) * 1000)
the\_aspect <- aspect(elevation)

stackDem <- c(elevation, the\_slope, the\_aspect)\$clip(aoi)


\# ---------------------------------------------------------------
\# Sentinel-1C
\# ---------------------------------------------------------------
s1c <- ee\$ImageCollection("COPERNICUS/S1\_GRD")\$
  filterBounds(aoi)\$
  filterDate("2019-04-01","2019-05-31")\$
  filter(ee\$Filter\$listContains("transmitterReceiverPolarisation","VV"))\$
  filter(ee\$Filter\$listContains("transmitterReceiverPolarisation","VH"))\$
  filter(ee\$Filter\$eq("instrumentMode","IW"))

s1c <- s1c\$sort("system:time\_start", FALSE)
s1c <- s1c\$reduce(ee\$Reducer\$firstNonNull())
s1c <- s1c[["VV\_first","VH\_first"]]
names(s1c) <- c("vv","vh")

s1c <- as.integer(s1c * 100)
vv <- s1c[["vv"]]
vh <- s1c[["vh"]]

s1c[["rvi"]]   <- as.integer(sqrt(vv/(vv+vh)) * (vv/vh) * 10000)
s1c[["copol"]] <- as.integer((vv/vh) * 10000)
s1c[["copol2"]] <- as.integer(((vv - vh)/(vv + vh)) * 10000)
s1c[["copol3"]] <- as.integer((vh/vv) * 10000)


\# ---------------------------------------------------------------
\# Final stack + neighborhood + texture
\# ---------------------------------------------------------------
fullStack <- c(hls, s1c, stackDem)

kernel <- ee\$Kernel\$fixed(
  3, 3,
  list(c(1,1,1), c(1,1,1), c(1,1,1)),
  3, 3, FALSE
)

for (nm in c("mean","min","max","stdDev")) \{
  reducer <- ee\$Reducer[[nm]]()

  fullStack <- c(
    fullStack,
    hls\$reduceNeighborhood(reducer, kernel),
    stackDem\$reduceNeighborhood(reducer, kernel)
  )
\}

img\_tex <- as.integer(
  (hls[[c("blue","green","red","nir","swir1","swir2")]]) * 1e4
)

tex <- img\_tex\$glcmTexture(size=3)

fullStack <- c(fullStack, tex)

\# fullStack is the ancillary layers image
fullStack

## End(Not run)
\end{Details}
%
\begin{Value}
A named list with the following Earth Engine objects:
\begin{description}

\item[aoi] EE geometry representing the buffered AOI bounding box.
\item[hls] HLS image with reflectance bands, vegetation indices, and
spectral unmixing fractions.
\item[s1c] Sentinel-1C image with VV/VH backscatter and radar indices.
\item[dem] Terrain stack including elevation, slope, and aspect.
\item[stack] Full ancillary stack combining HLS, Sentinel-1C, and terrain,
including neighborhood statistics and texture metrics.

\end{description}

\end{Value}
\HeaderA{ee\_initialize}{Initializes the Google Earth Engine API Initialize Earth Engine for this R session}{ee.Rul.initialize}
%
\begin{Description}
Initializes the Google Earth Engine API
Initialize Earth Engine for this R session
\end{Description}
%
\begin{Usage}
\begin{verbatim}
ee_initialize(
  project = Sys.getenv("EE_PROJECT", unset = NA),
  service_account = NULL,
  keyfile = NULL,
  quiet = FALSE,
  force_auth = FALSE
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{project}] Character. \strong{GCP Project ID} (e.g., "ice-map-2025") or a numeric project \strong{number}.
If NULL/NA, falls back to Sys.getenv("EE\_PROJECT").

\item[\code{service\_account}] Optional service account email (use with \code{keyfile}).

\item[\code{keyfile}] Path to service-account JSON key (required if \code{service\_account} is set).

\item[\code{quiet}] Logical. Suppress messages.

\item[\code{force\_auth}] Logical. If TRUE, perform OAuth before Initialize().
\end{ldescription}
\end{Arguments}
%
\begin{Value}
TRUE on success; FALSE otherwise (invisibly).
\end{Value}
\HeaderA{ee\_rect\_to\_sf}{Convert an EE Rectangle to an sf polygon (EPSG:4326)}{ee.Rul.rect.Rul.to.Rul.sf}
%
\begin{Description}
Convert an EE Rectangle to an sf polygon (EPSG:4326)
\end{Description}
%
\begin{Usage}
\begin{verbatim}
ee_rect_to_sf(aoi)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{aoi}] An \code{ee\$Geometry\$Rectangle}.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
An \code{sf} polygon with CRS EPSG:4326.
\end{Value}
\HeaderA{ext\_to\_ee}{Convert a terra extent or spatial object to an Earth Engine Rectangle}{ext.Rul.to.Rul.ee}
%
\begin{Description}
Converts a \code{terra::ext}, \code{terra::SpatVector}, or \code{terra::SpatRaster}
into a Google Earth Engine geometry of type \code{ee\$Geometry\$Rectangle}.
The resulting rectangle is always expressed in geographic coordinates
(EPSG:4326), regardless of the input object's projection.

This function is mainly used internally to standardize spatial inputs
before Earth Engine requests (e.g., filtering, clipping, or exporting data).
\end{Description}
%
\begin{Usage}
\begin{verbatim}
ext_to_ee(x)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] A spatial object of class \code{terra::ext}, \code{terra::SpatVector}, or
\code{terra::SpatRaster}. Its extent is extracted and converted into an
Earth Engine bounding box.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
A Python object representing \code{ee\$Geometry\$Rectangle}, suitable for use
with Earth Engine Python API functions accessed via \code{reticulate}.
\end{Value}
%
\begin{Examples}
\begin{ExampleCode}
## Not run: 
library(terra)

# Create an extent over Gainesville, FL
bb <- ext(c(-82.4, -82.2, 29.6, 29.8))

# Convert to EE geometry
aoi <- ext_to_ee(bb)

## End(Not run)

\end{ExampleCode}
\end{Examples}
\HeaderA{fit\_metrics}{Model fit metrics}{fit.Rul.metrics}
%
\begin{Description}
Computes RMSE (absolute and relative), MAE (absolute and relative),
bias (absolute and relative), Pearson correlation (r), and adjusted RÂ² from a
linear fit between predicted and observed values. Optionally draws a 1:1 plot
with the regression line.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
fit_metrics(
  observed,
  predicted,
  plotstat = FALSE,
  legend = "topleft",
  unit = "",
  ...
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{observed}] Numeric vector of observed values.

\item[\code{predicted}] Numeric vector of predicted values (same length/order as \code{observed}).

\item[\code{plotstat}] Logical; if TRUE, draws a 1:1 plot with the regression line. Default: FALSE.

\item[\code{legend}] Character position for the plot legend (e.g., "topleft"). Default: "topleft".

\item[\code{unit}] Character indicating the unit for RMSE/MAE/Bias (e.g., "Mg/ha"). Default: "".

\item[\code{...}] Additional arguments passed to \code{\LinkA{graphics::plot()}{graphics::plot()}}.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
A data.frame with rows for \code{rmse}, \code{rmseR} (\%), \code{mae}, \code{maeR} (\%),
\code{bias}, \code{biasR} (\%), \code{r}, and \code{adj\_r2}.
\end{Value}
%
\begin{Examples}
\begin{ExampleCode}
observed  <- c(178, 33, 60, 80, 104, 204, 146)
predicted <- c(184, 28.5, 55, 85, 105, 210, 155)
fit_metrics(observed, predicted,
            plotstat = TRUE, legend = "topleft", unit = "Mg/ha",
            xlab = "Observed AGBD (Mg/ha)", ylab = "Predicted AGBD (Mg/ha)", pch = 16)
\end{ExampleCode}
\end{Examples}
\HeaderA{fit\_model}{Fit a Random Forest with optional resampling, tuning, and progress bars}{fit.Rul.model}
%
\begin{Description}
\code{fit\_model()} trains a Random Forest regression model and optionally
evaluates it via LOOCV, K-fold CV, a train/test split, or bootstrap OOB
estimation. It can also tune core RF hyperparameters and shows progress
bars for long-running loops.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
fit_model(
  x,
  y,
  rf_args = list(ntree = 500, mtry = NULL, nodesize = 5, sampsize = NULL),
  test = list(method = "none", k = 5, test_size = 0.3, seed = NULL, folds = NULL,
    iterations = 200, correction = FALSE),
  tune = list(enable = FALSE, search = "grid", grid = NULL, n_random = 20, seed = NULL),
  verbose = TRUE,
  list_test_models = TRUE
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] A data.frame of predictors (rows = samples, cols = features).

\item[\code{y}] A numeric vector of responses, \code{length(y) == nrow(x)}.

\item[\code{rf\_args}] A named list of base Random Forest arguments used for all
fits (full-data fit and each resample). Elements:
\begin{itemize}

\item{} \code{ntree} (integer, default \code{500}): number of trees.
\item{} \code{mtry} (integer or \code{NULL}): number of variables sampled at each split.
If \code{NULL}, a safe default \code{floor(sqrt(p))} is used.
\item{} \code{nodesize} (integer, default \code{5}): minimum terminal node size.
\item{} \code{sampsize} (integer, fraction in \AsIs{\texttt{(0,1]}}, or \code{NULL}):
sample size per tree. If a single fraction, it is multiplied by the
current training size and rounded. If \code{NULL}, the package default is used.

\end{itemize}


\item[\code{test}] A named list configuring evaluation:
\begin{itemize}

\item{} \code{method} (character): one of \code{"none"}, \code{"loocv"}, \code{"k-fold"} (also accepts \code{"kfold"}/\code{"k fold"}),
\code{"split"}, or \code{"bootstrap"}.
\item{} \code{k} (integer, default \code{5}): number of folds for K-fold CV.
\item{} \code{folds} (list or \code{NULL}): custom index list of test-fold indices.
If supplied, overrides \code{k}.
\item{} \code{test\_size} (numeric in \AsIs{\texttt{(0,1)}}, default \code{0.3}): test fraction for
train/test split.
\item{} \code{iterations} (integer, default \code{200}): number of bootstrap resamples.
\item{} \code{correction} (logical, default \code{FALSE}): if \code{TRUE}, apply the
.632 correction to the RMSE for the bootstrap estimate.
\item{} \code{seed} (integer or \code{NULL}): RNG seed for reproducibility (folds,
split, random tuning).

\end{itemize}


\item[\code{tune}] A named list configuring hyperparameter search on the \emph{training}
subset for each fit:
\begin{itemize}

\item{} \code{enable} (logical, default \code{FALSE}): turn tuning on/off.
\item{} \code{search} (character, default \code{"grid"}): \code{"grid"} or \code{"random"}.
\item{} \code{grid} (data.frame or \code{NULL}): explicit grid with columns
\code{mtry}, \code{ntree}, \code{nodesize}, \code{sampsize}. If \code{NULL}, a sensible
default grid is generated from \code{p = ncol(x)}.
\item{} \code{n\_random} (integer, default \code{20}): number of random draws from
the grid when \code{search = "random"}.
\item{} \code{seed} (integer or \code{NULL}): RNG seed for the tuning subset draw order.

\end{itemize}


\item[\code{verbose}] Logical (default \code{TRUE}): show progress bars/messages for
tuning, LOOCV, K-fold, and bootstrap loops. Set \code{FALSE} to silence.

\item[\code{list\_test\_models}] Logical (default \code{TRUE}): if \code{TRUE}, save the
\emph{per-resample} fitted model objects as a list in \code{models\_test}.
This can be large, especially for \code{bootstrap} with many iterations.
\end{ldescription}
\end{Arguments}
%
\begin{Details}
Tuning minimizes OOB MSE for each candidate configuration on the current
training subset and then refits the model using the best settings.
When \code{test\$method = "bootstrap"} and \code{correction = TRUE}, the .632 corrected
RMSE is reported while keeping other OOB statistics unchanged.
\end{Details}
%
\begin{Value}
A list with:
\begin{description}

\item[method] \code{"rf"}
\item[rf\_args] Final RF arguments used for the full-data fit (after tuning).
\item[tune\_table] (data.frame or \code{NULL}) tuning results sorted by OOB MSE.
\item[test] Echo of \code{test} configuration (with resolved values).
\item[model] \code{randomForest} object fit on the full dataset (or train subset for \code{split}).
\item[fitted\_full] Numeric vector of in-sample predictions from the full-data fit.
\item[stats\_train] data.frame of training statistics (RMSE, Bias, \%RMSE, \%Bias, r, r2).
\item[stats\_test] (data.frame or \code{NULL}) test-set or OOF statistics depending on method.
\item[loocv\_pred] (numeric) LOOCV predictions (for \code{method = "loocv"}).
\item[cv\_pred] (numeric) K-fold OOF predictions (for \code{method = "k-fold"}).
\item[train\_index,test\_index] (integer) indices for \code{method = "split"}.
\item[pred\_train,pred\_test] (numeric) predictions for train/test in \code{split}.
\item[oob\_pred] (numeric) OOB mean prediction per observation in \code{bootstrap}.
\item[models\_test] (list or \code{NULL}) models fitted per resample/fold/iteration when \code{list\_test\_models=TRUE}.

\end{description}

\end{Value}
%
\begin{Section}{Workflow}

\begin{enumerate}

\item{} Optionally tune RF hyperparameters on the \emph{current training subset}
(or on full data when \code{test\$method = "none"}).
\item{} Always fit a model on the full dataset (\code{model} and \code{fitted\_full}).
\item{} If a testing method is requested, refit on resampled training folds and
compute out-of-fold predictions to summarize generalization performance.

\end{enumerate}

\end{Section}
%
\begin{Section}{Progress Bars}

Uses \code{utils::txtProgressBar()}; disable with \code{verbose = FALSE}. The internal
helper is lightweight and has no external dependencies.
\end{Section}
%
\begin{SeeAlso}
\code{\LinkA{randomForest::randomForest()}{randomForest::randomForest()}}, \code{\LinkA{stats::lm()}{stats::lm()}}, \code{\LinkA{stats::cor()}{stats::cor()}}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}
set.seed(1)
n <- 200
x <- data.frame(NDVI = runif(n, 0.2, 0.9),
                EVI  = runif(n, 0.1, 0.8),
                NBR  = runif(n, -0.5, 0.9),
                SLP  = runif(n, 0, 30))
y <- with(x, 5 + 20*NDVI + 10*EVI^1.5 - 0.05*SLP + rnorm(n, 0, 2))

# Full-data fit (no resampling)
fit_none <- fit_model(x, y, rf_args = list(ntree = 400, mtry = 2))
fit_none$stats_train

# LOOCV
fit_loocv <- fit_model(x, y, test = list(method = "loocv"))
fit_loocv$stats_test

# 5-fold CV
fit_k-fold <- fit_model(x, y, test = list(method = "k-fold", k = 5, seed = 42))
fit_k-fold$stats_test

# Train/Test split
fit_split <- fit_model(x, y, test = list(method = "split", test_size = 0.25, seed = 42))
fit_split$stats_test

# Bootstrap (with tuning and .632 correction)
fit_boot <- fit_model(
  x, y,
  rf_args = list(ntree = 400),
  test    = list(method = "bootstrap", iterations = 300, correction = TRUE),
  tune    = list(enable = TRUE, search = "random", n_random = 12)
)

# K-fold CV with saved models
fit_k <- fit_model(x, y, test = list(method = "k-fold", k = 5, seed = 42), list_test_models = TRUE)
length(fit_k$models_test)  # one model per fold

\end{ExampleCode}
\end{Examples}
\HeaderA{geomSampling}{Get observations given a minimum radius distance between samples}{geomSampling}
%
\begin{Description}
Get observations given a minimum radius distance between samples
\end{Description}
%
\begin{Usage}
\begin{verbatim}
geomSampling(size, geom, split_id = NULL, chainSampling = NULL)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{size}] the sample size. Either an integer of absolute number of samples or
if it is between (0, 1) it will sample a percentage relative to the number of
available observations within the group.

\item[\code{geom}] a \code{\LinkA{terra::SpatVector}{terra::SpatVector}} object opened with \code{\LinkA{terra::vect()}{terra::vect()}}

\item[\code{split\_id}] character. The variable name of the geometry to use as split factor
for sampling

\item[\code{chainSampling}] chains different methods of sampling by providing the result
of another samplingMethod \code{\LinkA{randomSampling()}{randomSampling}}, \code{\LinkA{spacedSampling()}{spacedSampling}}, \code{\LinkA{stratifiedSampling()}{stratifiedSampling}}.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
A \code{\LinkA{icesat2\_sampling\_method}{icesat2.Rul.sampling.Rul.method.Rdash.class}} for defining the method used in \code{\LinkA{sample()}{sample}}
\end{Value}
\HeaderA{get\_catalog\_id}{Retrieve the Google Earth Engine image catalog id}{get.Rul.catalog.Rul.id}
%
\begin{Description}
Retrieve the Google Earth Engine image catalog id
\end{Description}
%
\begin{Usage}
\begin{verbatim}
get_catalog_id(id)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{id}] character. The id retrieved from the data.table resulting from \code{\LinkA{search\_datasets()}{search.Rul.datasets}}.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
The catalog id to open within Google Earth Engine.
\end{Value}
\HeaderA{gridSampling}{Get samples stratified by grid cells of specified size}{gridSampling}
%
\begin{Description}
Get samples stratified by grid cells of specified size
\end{Description}
%
\begin{Usage}
\begin{verbatim}
gridSampling(size, grid_size, chainSampling = NULL)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{size}] the sample size. Either an integer of absolute number of samples or
if it is between (0, 1) it will sample a percentage relative to the number of
available observations within the group.

\item[\code{grid\_size}] generic params. The \code{\LinkA{gridSampling()}{gridSampling}} will take a \code{grid\_size} parameter
defining the grid size for the sampling

\item[\code{chainSampling}] chains different methods of sampling by providing the result
of another samplingMethod \code{\LinkA{randomSampling()}{randomSampling}}, \code{\LinkA{spacedSampling()}{spacedSampling}}, \code{\LinkA{stratifiedSampling()}{stratifiedSampling}}.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
A \code{\LinkA{icesat2\_sampling\_method}{icesat2.Rul.sampling.Rul.method.Rdash.class}} for defining the method used in \code{\LinkA{sample()}{sample}}
\end{Value}
\HeaderA{ICESat2VegR\_configure}{Configure Python environment for ICESat2VegR cloud features}{ICESat2VegR.Rul.configure}
%
\begin{Description}
This function sets up a robust, persistent Python environment for the
cloud-related features of \strong{ICESat2VegR}, including:
\end{Description}
%
\begin{Usage}
\begin{verbatim}
ICESat2VegR_configure(
  envname = "icesat2-env",
  py_ver = "3.10",
  prefer_conda = TRUE,
  force_conda_forge = TRUE,
  allow_session_installs = TRUE,
  manage_aiobotocore = TRUE,
  auto_restart = TRUE,
  verbose = TRUE,
  quick_probe = c("h5py", "earthaccess", "ee")
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{envname}] Character. Name of the conda/virtualenv environment to use or
create. Default is \code{"icesat2-env"}. If this is the default value and
the environment variable \code{CONDA\_DEFAULT\_ENV} is set, that value is
used instead (useful when running inside an existing conda environment).

\item[\code{py\_ver}] Character. Python version to request when creating a new env
(default \code{"3.10"}).

\item[\code{prefer\_conda}] Logical. If \code{TRUE} (default), use conda/Miniconda.
If \code{FALSE}, a \code{virtualenv} is used instead.

\item[\code{force\_conda\_forge}] Logical. If \code{TRUE} (default), configure conda
to use \code{conda-forge} with strict channel priority (recommended).

\item[\code{allow\_session\_installs}] Logical. If \code{TRUE} (default) and Python
is already initialized in the current R session, attempt session-only
installs first via \code{reticulate::py\_require()} and, if needed, a
pip call from the active interpreter. If that fails, a persistent env
is prepared instead.

\item[\code{manage\_aiobotocore}] Logical. If \code{TRUE} (default), attempt to
detect and resolve common \code{aiobotocore}/\code{botocore}/\code{boto3}
version conflicts by pinning compatible versions and optionally
uninstalling \code{aiobotocore} (which is not required for ICESat2VegR).

\item[\code{auto\_restart}] Logical. If \code{TRUE} (default), attempts to restart
the R session in RStudio via \code{rstudioapi::restartSession()} after
preparing the conda environment, so that the new Python binding is cleanly
established.

\item[\code{verbose}] Logical. If \code{TRUE} (default), print progress messages.

\item[\code{quick\_probe}] Character vector of Python import names to test for a
fast early exit (default: \code{c("h5py", "earthaccess", "ee")}).
\end{ldescription}
\end{Arguments}
%
\begin{Details}
\begin{itemize}

\item{} Downloading ICESat-2 data via \code{earthaccess}
\item{} Interfacing with Google Earth Engine via \code{earthengine-api}
\item{} Handling S3 access via \code{boto3}/\code{botocore}

\end{itemize}


The function:

\begin{itemize}

\item{} Detects whether Python is already initialized in the R session.
\item{} Performs a fast "quick probe" to see if required modules are present
(\code{h5py}, \code{earthaccess}, \code{ee} by default).
\item{} If everything is already available, it returns immediately.
\item{} Otherwise, it:
\begin{itemize}

\item{} Ensures Miniconda is installed (if \code{prefer\_conda = TRUE}).
\item{} Creates or reuses a conda environment (default: \code{"icesat2-env"}).
\item{} Installs required Python modules using conda-forge (and pip fallback).
\item{} Optionally tries in-session installs if Python is already initialized.
\item{} Optionally resolves common \code{aiobotocore}/\code{botocore} conflicts.
\item{} Optionally restarts the R session in RStudio to bind the new env.

\end{itemize}


\end{itemize}


Typical usage is simply:

\begin{alltt}
  ICESat2VegR_configure()
\end{alltt}


You usually only need to run this:
\begin{itemize}

\item{} Once per machine, or
\item{} After major Python / Miniconda changes, or
\item{} If the package reports missing Python modules.

\end{itemize}

\end{Details}
%
\begin{Value}
Logical \code{TRUE} on success, \code{FALSE} otherwise.
\end{Value}
%
\begin{Section}{Checked/installed Python modules}


The function checks for the following import names and installs the
corresponding packages when missing:


\Tabular{ll}{
\strong{Import name}      & \strong{Install name}           \\{}
\code{numpy}              & \code{numpy}                    \\{}
\code{h5py}               & \code{h5py}                     \\{}
\code{packaging}          & \code{packaging}                \\{}
\code{ee}                 & \code{earthengine-api}          \\{}
\code{earthaccess}        & \code{earthaccess}              \\{}
\code{googleapiclient}    & \code{google-api-python-client} \\{}
\code{boto3}              & \code{boto3}                    \\{}
\code{botocore}           & \code{botocore}                 \\{}
\code{s3transfer}         & \code{s3transfer}               \\{}
}
\end{Section}
%
\begin{Examples}
\begin{ExampleCode}
## Not run: 
  # Basic configuration using defaults
  ICESat2VegR_configure()

  # Use existing conda env named "icesat2"
  ICESat2VegR_configure(envname = "icesat2")

## End(Not run)
\end{ExampleCode}
\end{Examples}
\HeaderA{map\_create}{Create a Prediction Map in Google Earth Engine Using a Fitted Random Forest Model}{map.Rul.create}
%
\begin{Description}
Applies a fitted Random Forest model (from R's \code{randomForest} package)
to a Google Earth Engine (\strong{EE}) image or image collection and returns
an EE image containing predicted values.

The model is converted to an Earth Engine estimator using
\code{\LinkA{build\_ee\_forest}{build.Rul.ee.Rul.forest}}, which internally serializes the R forest
through the ICESat2VegR C++ module (\code{icesat2\_module}) and constructs an
EE \code{Classifier} via \code{ee\$Classifier\$decisionTreeEnsemble()}.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
map_create(
  model,
  stack,
  aoi = NULL,
  reducer = c("mosaic", "median"),
  mode = c("auto", "classifier"),
  to_float = TRUE
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{model}] A fitted \code{randomForest::randomForest} model, or a wrapper
object containing an element named \code{model}.

\item[\code{stack}] An \code{ee\$Image} or \code{ee\$ImageCollection} providing the
predictor variables (bands) matching those used to train the model.

\item[\code{aoi}] Optional EE geometry. If provided, the output map is clipped to it.

\item[\code{reducer}] Aggregation method when \code{stack} is an image collection.
One of: \code{"mosaic"} (default) or \code{"median"}.

\item[\code{mode}] Controls how the estimator is applied. Currently supported:
\begin{itemize}

\item{} \code{"auto"}       â€” (default) applies the classifier with
\code{img\$classify()}.
\item{} \code{"classifier"} â€” explicitly applies \code{img\$classify()}.

\end{itemize}

The \code{"regressor"} option is not supported, as the current
implementation only builds an Earth Engine classifier.

\item[\code{to\_float}] Logical; if \code{TRUE} (default) converts the output band to
32-bit float.
\end{ldescription}
\end{Arguments}
%
\begin{Details}
This function works for both:
\begin{itemize}

\item{} EE images: predictors already merged into one raster.
\item{} EE image collections: predictions computed for each image and reduced
using mosaic or median.

\end{itemize}


The output band is always named \code{"prediction\_layer"}.

Properties from a zero-pixel placeholder image are copied to preserve band
metadata.
\end{Details}
%
\begin{Value}
An Earth Engine \code{ee\$Image} containing model predictions.
\end{Value}
%
\begin{SeeAlso}
\code{\LinkA{build\_ee\_forest}{build.Rul.ee.Rul.forest}}
\code{randomForest::randomForest}
Earth Engine API reference: \url{https://developers.google.com/earth-engine}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}
## Not run: 
  library(ICESat2VegR)
  library(randomForest)

  # Fit a model in R
  data(airquality)
  air <- na.omit(airquality)

  rf_model <- randomForest(
    x = air[, 2:6],
    y = air[, 1],
    ntree = 100,
    importance = TRUE
  )

  # Suppose 'stack_ee' is an Earth Engine image with matching bands
  pred <- map_create(
    model = rf_model,
    stack = stack_ee,
    aoi   = NULL,
    mode  = "auto"
  )

  # Now pred is: ee$Image with one band ("prediction_layer")

## End(Not run)

\end{ExampleCode}
\end{Examples}
\HeaderA{map\_download}{map\_download: create task â†’ start â†’ (monitor) â†’ download/return id}{map.Rul.download}
%
\begin{Description}
One function to export an EE image to Drive, Cloud Storage, or
Asset; optionally monitor the task; and, for Drive/GCS, download the result
locally. Returns a local file (or \code{SpatRaster} if \code{terra} is available) for
Drive/GCS, or the \code{asset\_id} (invisible) for Asset exports.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
map_download(
  ee_image,
  method = c("drive", "gcs", "asset"),
  region,
  scale = NULL,
  file_name_prefix,
  dsn = NULL,
  drive_folder = NULL,
  gcs_bucket = NULL,
  asset_id = NULL,
  monitor = TRUE,
  task_time = 5,
  ...
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{ee\_image}] An \code{ee\$Image} to export.

\item[\code{method}] One of \code{"drive"}, \code{"gcs"}, or \code{"asset"}.

\item[\code{region}] EE geometry/feature collection defining the export region.

\item[\code{scale}] Numeric pixel size in meters.

\item[\code{file\_name\_prefix}] Export file prefix (used to search/download).

\item[\code{dsn}] Destination path on disk (Drive/GCS methods).

\item[\code{drive\_folder}] Drive folder name for Drive exports.

\item[\code{gcs\_bucket}] Cloud Storage bucket name for GCS exports.

\item[\code{asset\_id}] Destination asset id for Asset exports.

\item[\code{monitor}] Logical; if \code{TRUE}, poll the task until completion.

\item[\code{task\_time}] Seconds between polls when monitoring.

\item[\code{...}] Additional arguments forwarded to the corresponding export helper
(\code{ee\_image\_to\_drive()}, \code{ee\_image\_to\_gcs()}, or \code{ee\_image\_to\_asset()}), e.g.,
CRS, pyramiding policy, \code{maxPixels}, etc.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
For \code{"drive"}/\code{"gcs"}, a local path or a \code{SpatRaster} if \code{terra} is installed.
For \code{"asset"}, returns \code{invisible(asset\_id)}.
\end{Value}
%
\begin{Examples}
\begin{ExampleCode}
## Not run: 
out <- map_download(
  ee_image = img, method = "drive", region = aoi, scale = 10,
  file_name_prefix = "my_pred", dsn = "pred.tif",
  drive_folder = "EE_Exports", monitor = TRUE
)

## End(Not run)
\end{ExampleCode}
\end{Examples}
\HeaderA{map\_view}{Compose a leaflet map from multiple layers (EE rasters and/or vectors)}{map.Rul.view}
%
\begin{Description}
High-level map composer capable of adding Earth Engine raster
tiles (optionally tiled by AOI grid) and vector overlays (\code{sf}/\code{SpatVector}),
with layer control, legends, and per-group opacity sliders.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
map_view(
  layers,
  base_tiles = c("OSM", "Carto.Light", "Carto.Dark"),
  add_layers_control = TRUE,
  add_opacity_controls = TRUE,
  fit_to = NULL
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{layers}] A list of layer specs. For rasters: \AsIs{\texttt{list(type="ee\_image", x, bands, aoi=NULL, group=NULL, min\_value=0, max\_value=1, palette=NULL, is\_class=FALSE, scale\_to\_int=TRUE, int\_factor=1000L, tile=FALSE, nx=NULL, ny=NULL, legend=list(title=NULL, position=\bsl{}"bottomright\bsl{}", opacity=1, auto=NULL, probs=c(2,98), scale=NULL))}}.
For vectors: \code{list(type="vector", vect, group=NULL, border\_color, border\_weight, fill, fill\_color, fill\_opacity, color\_field, palette, legend\_title)}.

\item[\code{base\_tiles}] One of \code{"OSM"}, \code{"Carto.Light"}, \code{"Carto.Dark"}.

\item[\code{add\_layers\_control}] Logical; add layers control panel.

\item[\code{add\_opacity\_controls}] Logical; add per-group opacity sliders.

\item[\code{fit\_to}] Optional EE Rectangle to fit the initial view.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
A \code{leaflet} htmlwidget.
\end{Value}
%
\begin{Examples}
\begin{ExampleCode}
## Not run: 
m <- map_view(list(
  list(type="ee_image", x=img, bands="prediction_layer", aoi=aoi,
       group="Prediction", min_value=0, max_value=30,
       legend=list(title="Height (m)", auto="quantile")),
  list(type="vector", vect=polys_sf, group="Sites", color_field="site")
))

## End(Not run)
\end{ExampleCode}
\end{Examples}
\HeaderA{plot.varSel}{Plot variable importance for \code{varSel} objects}{plot.varSel}
%
\begin{Description}
Plot scaled variable importance for a \code{varSel} object using a horizontal
barplot. Variables are ordered so that the most important metrics appear at
the \strong{top} (largest bars).

When \code{which = "importance"} all variables are shown, and those selected
by \code{\LinkA{varSel}{varSel}} are highlighted in a different color. An optional
color palette (e.g., \code{viridis::inferno}) can be supplied to color the
bars by importance.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
## S3 method for class 'varSel'
plot(
  x,
  which = c("sel.importance", "importance"),
  main = "Random Forest variable importance",
  xlab = "Scaled importance",
  col.selected = "steelblue",
  col.other = "grey80",
  palette = NULL,
  legend.loc = "bottomright",
  ...
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] An object of class \code{"varSel"}.

\item[\code{which}] Character; either \code{"sel.importance"} (default) to plot the
importance of selected variables only, or \code{"importance"} to plot the
full-model importance (all predictors).

\item[\code{main}] Plot title.

\item[\code{xlab}] Label for the x-axis (importance scale).

\item[\code{col.selected}] Base color for selected variables when no palette is given.

\item[\code{col.other}] Base color for non-selected variables when no palette is given.

\item[\code{palette}] Optional color palette. Can be:
\begin{itemize}

\item{} a function \code{f(n)} returning \code{n} colors
(e.g., \code{viridis::inferno}),
\item{} or a character vector of colors used to build a gradient via
\code{\LinkA{colorRampPalette}{colorRampPalette}}.

\end{itemize}

The palette is applied to all bars and then the color of selected variables
is overridden by \code{col.selected} when \code{which = "importance"}.

\item[\code{legend.loc}] Legend location, e.g. "bottomright"

\item[\code{...}] Additional graphical arguments passed to
\code{\LinkA{barplot}{barplot}}.
\end{ldescription}
\end{Arguments}
%
\begin{Examples}
\begin{ExampleCode}

  require(randomForest)

  data(airquality)
  airquality <- na.omit(airquality)

  xdata <- airquality[, 2:6]
  ydata <- airquality[, 1]

  vs <- varSel(xdata, ydata, ntree = 200, min.imp = 0.2)

  ## Selected variables only
  plot(vs, which = "sel.importance")

  ## All variables, highlighting selected ones, with inferno palette
  if (requireNamespace("viridis", quietly = TRUE)) {
    plot(vs, which = "importance", palette = viridis::inferno)
  }


\end{ExampleCode}
\end{Examples}
\HeaderA{predict\_h5}{Model prediction over data.tables using HDF5 file as output}{predict.Rul.h5}
%
\begin{Description}
Model prediction over a data.table from ATL03 or ATL08 data
containing geolocation data.
It can both append results to an existing HDF5 file or
create a new file, allowing to incrementally add predictions
to the file to avoid memory issues.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
predict_h5(model, dt, output)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{model}] The trained model object

\item[\code{dt}] The input data.table to run the model

\item[\code{output}] The output HDF5 file path
\end{ldescription}
\end{Arguments}
%
\begin{Value}
An \code{\LinkA{icesat2.predict\_h5}{icesat2.predict.Rul.h5.Rdash.class}}, which is an
h5 file with latitude, longitude and prediction datasets.
\end{Value}
%
\begin{Examples}
\begin{ExampleCode}
atl03_path <- system.file(
  "extdata",
  "atl03_clip.h5",
  package = "ICESat2VegR"
)

atl03_h5 <- ATL03_read(atl03_path = atl03_path)
atl03_seg_dt <- ATL03_seg_metadata_dt(atl03_h5)

linear_model <- stats::lm(h_ph ~ segment_ph_cnt, data = atl03_seg_dt)
output_h5 <- tempfile(fileext = ".h5")
predicted_h5 <- predict_h5(linear_model, atl03_seg_dt, output_h5)

# List datasets
predicted_h5$ls()$name

# See predicted values
head(predicted_h5[["prediction"]][])

# Close the file
close(predicted_h5)

\end{ExampleCode}
\end{Examples}
\HeaderA{prepend\_class}{Prepend a class to an object's list of classes}{prepend.Rul.class}
%
\begin{Description}
Prepend a class to an object's list of classes
\end{Description}
%
\begin{Usage}
\begin{verbatim}
prepend_class(obj, className)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{obj}] The object to which prepend the class.

\item[\code{className}] \code{\LinkA{character}{character.Rdash.class}} with the name of the class to prepend.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
Nothing, it replaces the class attribute in place
\end{Value}
\HeaderA{randomSampling}{Pure random sampling method}{randomSampling}
%
\begin{Description}
Pure random sampling method
\end{Description}
%
\begin{Usage}
\begin{verbatim}
randomSampling(size)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{size}] the sample size. Either an integer of absolute number of samples or
if it is between (0, 1) it will sample a percentage relative to the number of
available observations within the group.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
A \code{\LinkA{icesat2\_sampling\_method}{icesat2.Rul.sampling.Rul.method.Rdash.class}} for defining the method used in \code{\LinkA{sample()}{sample}}
\end{Value}
\HeaderA{rasterize\_h5}{Rasterizes the model prediction saved in the HDF5 file}{rasterize.Rul.h5}
%
\begin{Description}
This is used after running the prediction using \code{\LinkA{predict\_h5()}{predict.Rul.h5}}
function to rasterize and aggregate the prediction within raster cells.
By default it will calculate (n, mean, variance * (n - 1), min, max, sd)
in a single raster file with those 6 bands in that order.
You can modify this behavior by changing the \code{agg\_function}, \code{agg\_join}
and \code{finalizer} parameters, see details section.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
rasterize_h5(h5_input, output, bbox, res, ...)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{h5\_input}] The input HDF5 file path

\item[\code{output}] The output raster file path

\item[\code{bbox}] The bounding box of the raster

\item[\code{res}] The resolution of the raster

\item[\code{...}] Additional parameters (see details section)
\end{ldescription}
\end{Arguments}
%
\begin{Details}
This function will create five different aggregate statistics
(n, mean, variance, min, max).

Within \code{...} additional parameters we can use:

\code{agg\_function}: is a formula which return a data.table with the
aggregate function to perform over the data.
The default is:

\begin{alltt}~data.table(
    n = length(x),
    mean = mean(x,na.rm = TRUE),
    variance = var(x) * (length(x) - 1),
    min = min(x, na.rm=T),
    max = max(x, na.rm=T)
  )
\end{alltt}


\code{agg\_join}:  is a function to merge two data.table aggregates
from the \code{agg\_function}. Since the h5 files will be aggregated
in chunks to avoid memory overflow, the statistics from the
different chunks should have a function to merge them.

The default function is:

\begin{alltt}function(x1, x2) \{
    combined = data.table()
    x1$n[is.na(x1$n)] = 0
    x1$mean[is.na(x1$mean)] = 0
    x1$variance[is.na(x1$variance)] = 0
    x1$max[is.na(x1$max)] = -Inf
    x1$min[is.na(x1$min)] = Inf

    combined$n = x1$n + x2$n

    delta = x2$mean - x1$mean
    delta2 = delta * delta

    combined$mean = (x1$n * x1$mean + x2$n * x2$mean) / combined$n
    combined$variance = x1$variance + x2$variance +
      delta2 * x1$n * x2$n / combined$n

    combined$min = pmin(x1$min, x2$min, na.rm=F)
    combined$max = pmax(x1$max, x2$max, na.rm=F)
    return(combined)
\}
\end{alltt}


\code{finalizer}: is a list of formulas to generate the final
rasters based on the intermediate statistics from the previous
functions. The default \code{finalizer} will calculate the \code{sd},
based on the \code{variance} and \code{n} values. It is defined as:

\begin{alltt}list(
  sd = ~sqrt(variance/(n - 1)),
)
\end{alltt}

\end{Details}
%
\begin{Examples}
\begin{ExampleCode}
atl08_path <- system.file(
  "extdata",
  "atl08_clip.h5",
  package = "ICESat2VegR"
)

atl08_h5 <- ATL08_read(atl08_path = atl08_path)
atl08_dt <- ATL08_seg_attributes_dt(atl08_h5)

xmin <- min(atl08_dt$longitude)
xmax <- max(atl08_dt$longitude)
ymin <- min(atl08_dt$latitude)
ymax <- max(atl08_dt$latitude)

linear_model <- stats::lm(h_canopy ~ canopy_openness, data = atl08_dt)
output_h5 <- tempfile(fileext = ".h5")
predicted_h5 <- predict_h5(linear_model, atl08_dt, output_h5)
output_raster <- tempfile(fileext = ".tif")

rasterize_h5(
  predicted_h5,
  output = output_raster,
  bbox = terra::ext(xmin, xmax, ymin, ymax),
  res = 0.003
)

\end{ExampleCode}
\end{Examples}
\HeaderA{rasterSampling}{Get observations given a minimum radius distance between samples}{rasterSampling}
%
\begin{Description}
Get observations given a minimum radius distance between samples
\end{Description}
%
\begin{Usage}
\begin{verbatim}
rasterSampling(size, raster, chainSampling = NULL)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{size}] the sample size. Either an integer of absolute number of samples or
if it is between (0, 1) it will sample a percentage relative to the number of
available observations within the group.

\item[\code{raster}] a \code{\LinkA{terra::SpatRaster}{terra::SpatRaster}} object opened with \code{\LinkA{terra::rast()}{terra::rast()}}

\item[\code{chainSampling}] chains different methods of sampling by providing the result
of another samplingMethod \code{\LinkA{randomSampling()}{randomSampling}}, \code{\LinkA{spacedSampling()}{spacedSampling}}, \code{\LinkA{stratifiedSampling()}{stratifiedSampling}}.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
A \code{\LinkA{icesat2\_sampling\_method}{icesat2.Rul.sampling.Rul.method.Rdash.class}} for defining the method used in \code{\LinkA{sample()}{sample}}
\end{Value}
\HeaderA{rgt\_extract}{Extract reference ground track from ATL03 segments}{rgt.Rul.extract}
%
\begin{Description}
This function extracts reference ground track from ICESat-2 ATL03 data
and writes it as a GDAL vector format.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
rgt_extract(h5)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{h5}] A ICESat-2 ATL03 object (output of \code{\LinkA{ATL03\_read()}{ATL03.Rul.read}} or \code{\LinkA{ATL08\_read()}{ATL08.Rul.read}} function).
An S4 object of class \code{\LinkA{icesat2.atl03\_dt}{icesat2.atl03.Rul.dt.Rdash.class}} or \code{\LinkA{icesat2.atl08\_dt}{icesat2.atl08.Rul.dt.Rdash.class}}.
\end{ldescription}
\end{Arguments}
%
\begin{Details}
This function will use the reference photons from the segments as reference
for deriving the ground tracks. The begining and end of the lines are interpolated from
the information regarding the position of the reference photon within the segment and the
segment length.
\end{Details}
%
\begin{Value}
Returns the ground track boundaries as \code{\LinkA{terra::SpatVector}{terra::SpatVector}} extracted from "orbit\_info",
along with other orbit information.
\end{Value}
%
\begin{SeeAlso}
\url{https://icesat-2.gsfc.nasa.gov/sites/default/files/page_files/ICESat2_ATL03_ATBD_r006.pdf}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}

# Specifying the path to ATL03 H5 file
atl03_path <- system.file("extdata",
  "atl03_clip.h5",
  package = "ICESat2VegR"
)

# Reading ATL03 data (h5 file)
atl03_h5 <- ATL03_read(atl03_path = atl03_path)

# Extracting ATL03 photons attributes
rgt <- rgt_extract(h5 = atl03_h5)
head(rgt)

terra::plet(rgt)

close(atl03_h5)
\end{ExampleCode}
\end{Examples}
\HeaderA{sample}{Sample method for applying multiple sampling methods}{sample}
%
\begin{Description}
Sample method for applying multiple sampling methods
\end{Description}
%
\begin{Usage}
\begin{verbatim}
sample(x, ..., method)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] the generic input data to be sampled

\item[\code{...}] generic params to pass ahead to the specific sampling function

\item[\code{method}] the sampling method to use.
\end{ldescription}
\end{Arguments}
%
\begin{Details}
It is expected that the user pass a \code{method} parameter within \code{...}
\end{Details}
%
\begin{SeeAlso}
\code{\LinkA{randomSampling()}{randomSampling}}, \code{\LinkA{spacedSampling()}{spacedSampling}}, \code{\LinkA{gridSampling()}{gridSampling}},
\code{\LinkA{stratifiedSampling()}{stratifiedSampling}}, \code{\LinkA{geomSampling()}{geomSampling}}, \code{\LinkA{rasterSampling()}{rasterSampling}}
\end{SeeAlso}
\HeaderA{sample\_ATL\_granules\_by\_year}{Sample ICESat-2 ATL granule URLs by year}{sample.Rul.ATL.Rul.granules.Rul.by.Rul.year}
%
\begin{Description}
Given a vector (or first column of a matrix/data frame) of ICESat-2 ATL03/ATL08
granule URLs or file paths, this function:

\begin{itemize}

\item{} Attempts to parse the acquisition year from each URL/path.
\item{} Groups granules by year.
\item{} Samples up to \code{n\_per\_year} unique URLs per year.

\end{itemize}


This is useful for creating manageable subsets of ATL granules for testing,
model fitting, or cross-validation.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
sample_ATL_granules_by_year(urls, n_per_year = 5, seed = NULL)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{urls}] Character vector, matrix, or data frame containing granule URLs
or file paths. If a matrix or data frame is provided, the first column is
used.

\item[\code{n\_per\_year}] Integer. Maximum number of URLs to sample per year
(default \code{5}).

\item[\code{seed}] Optional integer seed passed to \code{set.seed()} to make the
sampling reproducible. If \code{NULL} (default), the random state is
left unchanged.
\end{ldescription}
\end{Arguments}
%
\begin{Details}
The year is extracted using the following heuristics:

\begin{enumerate}

\item{} A path component of the form \code{/YYYY/} (e.g., \code{".../2020/..."}).
\item{} A filename pattern of the form \code{"ATL0[38]\_YYYYMMDD..."}.

\end{enumerate}


URLs for which no year can be detected are dropped with a warning.
\end{Details}
%
\begin{Value}
A data frame with columns:
\begin{itemize}

\item{} \code{year}: integer acquisition year.
\item{} \code{url}: the sampled URL or file path.

\end{itemize}

Rows are ordered by \code{year} and then \code{url}.
\end{Value}
%
\begin{Examples}
\begin{ExampleCode}
## Not run: 
  urls <- c(
    "https://example.org/ATL03_20200101000000_001.h5",
    "https://example.org/ATL03_20200102000000_002.h5",
    "https://example.org/ATL03_20210101000000_003.h5"
  )

  sample_df <- ee_sample_atl_granules_by_year(urls, n_per_year = 1, seed = 123)
  sample_df

## End(Not run)

\end{ExampleCode}
\end{Examples}
\HeaderA{search\_datasets}{Search for Google Earth Engine datasets}{search.Rul.datasets}
%
\begin{Description}
Search for Google Earth Engine datasets
\end{Description}
%
\begin{Usage}
\begin{verbatim}
search_datasets(
  ...,
  title = TRUE,
  description = TRUE,
  operator = "and",
  refresh_cache = FALSE
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{...}] character arguments to search for within title and/or description

\item[\code{title}] logical. Whether should search within the title, default TRUE.

\item[\code{description}] logical. Whether should search within the description of the dataset, default TRUE.

\item[\code{operator}] character. Should be either "OR" or "AND" to tell if the search needs to include
all the queries "AND" or any of the queries "OR". Default "AND".

\item[\code{refresh\_cache}] flag indicating if the results cache should be refreshed, default FALSE.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
A \code{data.table} containing the id, title and description of the datasets that matched
the supplied query ordered by relevance.
\end{Value}
\HeaderA{seg\_ancillary\_extract}{Given a stack image raster from GEE retrieve the point geometry with values for the images}{seg.Rul.ancillary.Rul.extract}
%
\begin{Description}
Given a stack image raster from GEE
retrieve the point geometry with values for the images
\end{Description}
%
\begin{Usage}
\begin{verbatim}
seg_ancillary_extract(stack, geom, scale = 10, chunk_size = 1000)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{stack}] A single image or a vector/list of images from Earth Engine.

\item[\code{geom}] A geometry from \code{\LinkA{terra::SpatVector}{terra::SpatVector}} read with \code{\LinkA{terra::vect}{terra::vect}}.

\item[\code{scale}] The scale in meters for the extraction (image resolution).

\item[\code{chunk\_size}] If the number of observations is greater than 1000, it is recommended
to chunk the results for not running out of memory within GEE server, default is chunk by
1000.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
A \LinkA{data.table::data.table}{data.table::data.table} with the properties extracted
from the ee images.
\end{Value}
\HeaderA{slope}{Compute terrain slope (degrees) from a DEM image}{slope}
%
\begin{Description}
Computes the terrain \emph{slope} in degrees for each pixel of an Earth Engine
\code{ee\$Image} representing a digital elevation model (DEM).

This method is a thin wrapper around \code{ee\$Terrain\$slope()} and returns the
same output structure. Slope is computed using Earth Engineâ€™s internal
gradient operator, which relies on the 4-connected neighborhood around each
pixel. As a result, edge pixels may contain missing values depending on the
input DEM.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
slope(x)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] An \code{ee\$Image} representing a DEM from which slope will be derived.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
An \code{ee\$Image} with one band named \code{"slope"} containing terrain
slope values in degrees.
\end{Value}
%
\begin{Examples}
\begin{ExampleCode}
## Not run: 
  ee <- reticulate::import("ee")
  dem <- ee$Image("NASA/NASADEM_HGT/001")
  slp <- slope(dem)

## End(Not run)

\end{ExampleCode}
\end{Examples}
\HeaderA{spacedSampling}{Get observations given a minimum radius distance between samples}{spacedSampling}
%
\begin{Description}
Get observations given a minimum radius distance between samples
\end{Description}
%
\begin{Usage}
\begin{verbatim}
spacedSampling(size, radius, spatialIndex = NULL, chainSampling = NULL)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{size}] the sample size. Either an integer of absolute number of samples or
if it is between (0, 1) it will sample a percentage relative to the number of
available observations within the group.

\item[\code{radius}] the minimum radius between samples.

\item[\code{spatialIndex}] optional parameter. You can create a spatial index for accelerating
the search space with \code{\LinkA{ANNIndex}{ANNIndex}} and reuse that if needed elsewhere. It will create
one automatically everytime if you don't specify one.

\item[\code{chainSampling}] chains different methods of sampling by providing the result
of another samplingMethod \code{\LinkA{randomSampling()}{randomSampling}}, \code{\LinkA{spacedSampling()}{spacedSampling}}, \code{\LinkA{stratifiedSampling()}{stratifiedSampling}}.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
A \code{\LinkA{icesat2\_sampling\_method}{icesat2.Rul.sampling.Rul.method.Rdash.class}} for defining the method used in \code{\LinkA{sample()}{sample}}
\end{Value}
\HeaderA{stratifiedSampling}{Get samples stratified by a variable binning histogram}{stratifiedSampling}
%
\begin{Description}
Get samples stratified by a variable binning histogram
\end{Description}
%
\begin{Usage}
\begin{verbatim}
stratifiedSampling(size, variable, chainSampling = NULL, ...)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{size}] the sample size. Either an integer of absolute number of samples or
if it is between (0, 1) it will sample a percentage relative to the number of
available observations within the group.

\item[\code{variable}] Variable name used for the stratification

\item[\code{chainSampling}] chains different methods of sampling by providing the result
of another samplingMethod \code{\LinkA{randomSampling()}{randomSampling}}, \code{\LinkA{spacedSampling()}{spacedSampling}}, \code{\LinkA{stratifiedSampling()}{stratifiedSampling}}.

\item[\code{...}] forward to the \code{\LinkA{graphics::hist()}{graphics::hist()}}, where you can manually define the breaks.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
A \code{\LinkA{icesat2\_sampling\_method}{icesat2.Rul.sampling.Rul.method.Rdash.class}} for defining the method used in \code{\LinkA{sample()}{sample}}
\end{Value}
\HeaderA{to\_vect}{Generic function to convert icesat2 classes and sf to \code{\LinkA{terra::SpatVector}{terra::SpatVector}}}{to.Rul.vect}
%
\begin{Description}
Generic function to convert icesat2 classes and sf to \code{\LinkA{terra::SpatVector}{terra::SpatVector}}
\end{Description}
%
\begin{Usage}
\begin{verbatim}
to_vect(x, ...)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] The icesat2 or sf object to convert to \code{\LinkA{terra::SpatVector}{terra::SpatVector}}

\item[\code{...}] other potential parameters needed.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
The icesat2 or sf object as the appropriate \code{\LinkA{terra::SpatVector}{terra::SpatVector}}
\end{Value}
%
\begin{Examples}
\begin{ExampleCode}
# Get path to ATL03 h5 file
atl03_path <- system.file("extdata",
  "atl03_clip.h5",
  package = "ICESat2VegR"
)
# Reading ATL03 data (h5 file)
atl03_h5 <- ATL03_read(atl03_path = atl03_path)
# Extracting ATL03 segment attributes
atl03_segment_dt <- ATL03_seg_metadata_dt(atl03_h5 = atl03_h5)

# Extract vector
atl03_segment_vect <- to_vect(atl03_segment_dt)

# Terra plot
terra::plot(atl03_segment_vect, col = atl03_segment_vect$segment_ph_cnt)

# Export as temp gpkg
temp_vect <- tempfile(fileext = ".gpkg")
terra::writeVector(atl03_segment_vect, temp_vect)

head(atl03_segment_dt)
close(atl03_h5)
\end{ExampleCode}
\end{Examples}
\HeaderA{varSel}{Random Forest Variable Selection (Breiman-only)}{varSel}
%
\begin{Description}
Implements the Random Forest model selection approach of Murphy et al. (2010),
using Breiman's original \pkg{randomForest} implementation. This is a simplified
adaptation of \code{rfUtilities::rf.modelSel}, restricted to the Breiman
implementation and modified for the ICESat2VegR package.

It returns the selected variables and importance metrics, but does not fit
a final model.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
varSel(
  xdata,
  ydata,
  imp.scale = c("mir", "se"),
  r = c(0.25, 0.5, 0.75),
  min.imp = NULL,
  seed = NULL,
  parsimony = NULL,
  kappa = FALSE,
  ...
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{xdata}] Matrix or data.frame of predictor variables (columns = predictors).

\item[\code{ydata}] Response vector. For classification, \code{ydata} must be a factor;
otherwise the model is fit in regression mode.

\item[\code{imp.scale}] Character; type of scaling for importance values, either
\code{"mir"} or \code{"se"}. Default is \code{"mir"}.

\item[\code{r}] Numeric vector of importance percentiles to test, e.g.,
\code{c(0.25, 0.50, 0.75)}. These percentiles are used to define thresholds
for building nested models during selection.

\item[\code{min.imp}] Optional numeric in \eqn{[0,1]}{} used as a minimum scaled
importance cutoff (in MIR or SE scale) to filter the final set of variables.
Variables whose scaled importance is below this threshold are dropped from
the selected set \code{selvars}. If \code{NULL} (default), no cutoff is
applied after the Murphy-style model selection.

\item[\code{seed}] Optional integer; sets the random seed in the global R environment.
This is strongly recommended for reproducibility.

\item[\code{parsimony}] Numeric in (0,1); threshold for selecting among competing
models. If specified, models whose errors are within \code{parsimony} of
the best model (OOB / class error for classification, variance explained /
MSE for regression) are considered, and the one with the fewest parameters
is chosen.

\item[\code{kappa}] Logical; use the chance-corrected \eqn{\kappa}{} statistic as the
primary optimization criterion for classification instead of percent
correctly classified (PCC). This corrects PCC for random agreement.

\item[\code{...}] Additional arguments passed to \code{\LinkA{randomForest}{randomForest}},
e.g. \code{ntree = 1000}, \code{replace = TRUE}, \code{proximity = TRUE}.
\end{ldescription}
\end{Arguments}
%
\begin{Details}
For classification, ensure that \code{ydata} is a factor; otherwise the model
is fit in regression mode.

\strong{Selection strategy:}

\begin{itemize}

\item{} For classification, candidate models are compared using OOB PCC (or
\eqn{\kappa}{}, if \code{kappa = TRUE}) and maximum within-class error,
with preference for more parsimonious models.
\item{} For regression, candidate models are compared using percent variance
explained and MSE, with preference for more parsimonious models.
\item{} After the best model is chosen, the optional \code{min.imp} cutoff is
applied to the scaled importance (MIR/SE) from the full model to remove
weak predictors from the final set \code{selvars}.

\end{itemize}


Typical choices for \code{min.imp}:
\begin{itemize}

\item{} MIR: \code{min.imp} in \eqn{[0.1, 0.3]}{} (e.g., keep variables with
at least 20\bsl{}
\item{} SE: \code{min.imp} in \eqn{[0.01, 0.05]}{}, remembering that SE-scaled
importance values sum to 1.

\end{itemize}

\end{Details}
%
\begin{Value}
An object of class \code{"varSel"} (a list) with components:
\begin{itemize}

\item{} \code{selvars} Character vector of selected variable names (after
applying \code{min.imp}, if provided).
\item{} \code{test} Data.frame of model-selection diagnostics, containing
error metrics, threshold, number of parameters, and the variables used
in each candidate model (for inspection only).
\item{} \code{importance} Data.frame of scaled importance values for all
variables in the full model (columns \code{parameter}, \code{importance}).
\item{} \code{sel.importance} Data.frame of scaled importance values for the
selected variables.
\item{} \code{parameters} List of variables used in each candidate model.
\item{} \code{scaling} Character; the importance scaling used (\code{"mir"}
or \code{"se"}).

\end{itemize}

\end{Value}
%
\begin{SeeAlso}
\code{\LinkA{randomForest}{randomForest}} and \code{\LinkA{plot.varSel}{plot.varSel}}.
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}

  require(randomForest)

  data(airquality)
  airquality <- na.omit(airquality)

  xdata <- airquality[, 2:6]
  ydata <- airquality[, 1]

  ## Regression example with MIR scaling and importance cutoff
  vs.regress <- varSel(
    xdata     = xdata,
    ydata     = ydata,
    imp.scale = "mir",
    ntree     = 500,
    min.imp   = 0.2
  )

  vs.regress$selvars

  ## Plot all variables, highlighting selected ones
  plot(vs.regress, which = "importance")


\end{ExampleCode}
\end{Examples}
\HeaderA{vect\_as\_ee}{Convert vector data to Google Earth Engine FeatureCollection (no rgee)}{vect.Rul.as.Rul.ee}
%
\begin{Description}
\code{vect\_as\_ee()} converts vector data to a Google Earth Engine
\code{ee\$FeatureCollection} using \strong{reticulate} to call the official Python
Earth Engine API-\strong{without} relying on \strong{rgee}. It accepts \code{sf}/\code{sfc}/\code{sfg}
objects or \code{\LinkA{terra::SpatVector}{terra::SpatVector}}, validates and reprojects geometries, and
either returns an in-memory FeatureCollection or exports to an EE Asset.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
vect_as_ee(
  x,
  via = c("getInfo", "getInfo_to_asset"),
  assetId = NULL,
  overwrite = TRUE,
  proj = "EPSG:4326",
  make_valid = TRUE,
  quiet = FALSE,
  monitoring = TRUE,
  poll_interval_sec = 5,
  poll_timeout_sec = 3600
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] An input vector object: an \code{sf}, \code{sfc}, or \code{sfg} object, or a
\code{\LinkA{terra::SpatVector}{terra::SpatVector}}. For \code{sfg}/\code{sfc}, a simple point/line/polygon geometry
is accepted; for \code{SpatVector}, it will be converted to \code{sf}.

\item[\code{via}] Character; one of \code{c("getInfo","getInfo\_to\_asset")}.
\begin{itemize}

\item{} \code{"getInfo"} returns an in-memory \code{ee\$FeatureCollection} built from the
GeoJSON of \code{x}.
\item{} \code{"getInfo\_to\_asset"} creates an EE export task to save the collection to
an Earth Engine \strong{Asset} (requires \code{assetId}).

\end{itemize}


\item[\code{assetId}] Character; EE asset id (e.g., \code{"users/you/my\_fc"}). \strong{Required}
when \code{via = "getInfo\_to\_asset"}.

\item[\code{overwrite}] Logical; if \code{TRUE}, attempt to delete an existing EE asset at
\code{assetId} before export.

\item[\code{proj}] Character CRS string (e.g., \code{"EPSG:4326"}). Input will be
transformed to this CRS before conversion. Default is \code{"EPSG:4326"}.

\item[\code{make\_valid}] Logical; if \code{TRUE}, attempt to repair invalid geometries
(\code{sf::st\_make\_valid()} / \code{terra::makeValid()}).

\item[\code{quiet}] Logical; if \code{FALSE}, print progress messages (e.g., task state).

\item[\code{monitoring}] Logical; when exporting to asset, if \code{TRUE} poll the task
until completion or timeout, otherwise return immediately after starting.

\item[\code{poll\_interval\_sec}] Numeric; seconds to wait between task status checks
when \code{monitoring = TRUE}. Default \code{5}.

\item[\code{poll\_timeout\_sec}] Numeric; maximum seconds to keep polling before
timing out. Default \code{3600} (1 hour).
\end{ldescription}
\end{Arguments}
%
\begin{Details}
\begin{itemize}

\item{} The function converts \code{x} to \code{sf}, enforces a defined CRS, optionally fixes
invalid geometries, and transforms to \code{proj} (default WGS84).
\item{} Properties are carried alongside geometry; however, Earth Engine does not
accept \AsIs{\texttt{POSIX*}} timestamp columns or property names containing \code{'.'}. The
function stops with a clear error if such columns are found-convert them to
character or rename before calling.
\item{} GeoJSON is built in-memory (via \strong{geojsonsf} when available) or via a
temporary \code{.geojson} file as a fallback, then parsed to a list for
\code{ee\$FeatureCollection}.
\item{} Requires a properly initialized EE Python environment (\code{ee.Initialize()}
in the active Python session used by \strong{reticulate}).

\end{itemize}

\end{Details}
%
\begin{Value}
If \code{via = "getInfo"}, returns an in-memory \code{ee\$FeatureCollection} object
(reticulate Python object). If \code{via = "getInfo\_to\_asset"}, returns an
\code{ee\$FeatureCollection} \strong{referencing} \code{assetId} (after successful export),
or returns immediately if \code{monitoring = FALSE}.
\end{Value}
%
\begin{Section}{Errors \& Constraints}

\begin{itemize}

\item{} Undefined CRS: the function stops if \code{x} has no CRS set.
\item{} Unsupported columns: the function stops if any property is \AsIs{\texttt{POSIX*}} or if
names contain dots (\code{.}).
\item{} Export failures: if \code{via = "getInfo\_to\_asset"} and the EE task fails or is
cancelled, an error is thrown when \code{monitoring = TRUE}.

\end{itemize}

\end{Section}
%
\begin{SeeAlso}
\begin{itemize}

\item{} Earth Engine Python API docs: \code{ee\$FeatureCollection}
\item{} Geometry repair: \code{\LinkA{sf::st\_make\_valid()}{sf::st.Rul.make.Rul.valid()}}, \code{\LinkA{terra::makeValid()}{terra::makeValid()}}
\item{} GeoJSON helpers: \strong{geojsonsf}, \code{\LinkA{sf::st\_write()}{sf::st.Rul.write()}}

\end{itemize}

\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}
## Not run: 
# -- Prerequisites (Python side):
# import ee; ee.Initialize()
#
# Example with sf POINTS
library(sf)
pts <- st_as_sf(data.frame(
  id = 1:3,
  x  = c(-84.02171, -84.02025, -84.02026),
  y  = c(31.29891, 31.31945, 31.31938)
), coords = c("x","y"), crs = "EPSG:4326")

# In-memory FeatureCollection:
fc <- vect_as_ee(pts, via = "getInfo")

# Export to an EE asset (monitor until done):
# fc_asset <- vect_as_ee(
#   pts,
#   via = "getInfo_to_asset",
#   assetId = "users/you/demo_points",
#   overwrite = TRUE,
#   monitoring = TRUE
# )

## End(Not run)

\end{ExampleCode}
\end{Examples}
\HeaderA{write\_geojson}{Safely write a GeoJSON file from a lon/lat table}{write.Rul.geojson}
%
\begin{Description}
Converts a data frame or similar tabular object with longitude/latitude
columns into a point layer and writes it to disk as a GeoJSON file.
The function first attempts to use \pkg{terra} via
\code{ICESat2VegR::to\_vect()}, and falls back to \pkg{sf} if available.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
write_geojson(
  dt,
  path,
  xcol = "lon",
  ycol = "lat",
  crs = "EPSG:4326",
  overwrite = TRUE
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{dt}] A data frame, \code{data.table}, or similar object containing at
least two numeric columns for coordinates.

\item[\code{path}] Character. Path to the output GeoJSON file.

\item[\code{xcol}, \code{ycol}] Character. Names of the longitude and latitude columns in
\code{dt}. Defaults are \code{"lon"} and \code{"lat"}.

\item[\code{crs}] Character. Coordinate reference system of the input coordinates.
Default is \code{"EPSG:4326"} (longitude/latitude in WGS84).

\item[\code{overwrite}] Logical. If \code{TRUE} (default), allow overwriting an
existing file.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
Invisibly returns \code{TRUE} on success. An error is thrown if both the
\pkg{terra}-based and \pkg{sf}-based write attempts fail.
\end{Value}
%
\begin{Examples}
\begin{ExampleCode}
## Not run: 
  pts <- data.frame(
    id  = 1:3,
    lon = c(-82.35, -82.34, -82.33),
    lat = c( 29.65,  29.66,  29.67)
  )

  write_geojson_safe(pts, "points.geojson")

## End(Not run)

\end{ExampleCode}
\end{Examples}
\printindex{}
\end{document}
